{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lWcsyrn6cqe0",
        "outputId": "0116f7bf-0a14-464a-930c-ad1e65b9d7c5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting datasets\n",
            "  Downloading datasets-3.1.0-py3-none-any.whl.metadata (20 kB)\n",
            "Requirement already satisfied: tokenizers in /usr/local/lib/python3.10/dist-packages (0.20.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.16.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.26.4)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (17.0.0)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.6)\n",
            "Collecting xxhash (from datasets)\n",
            "  Downloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting multiprocess<0.70.17 (from datasets)\n",
            "  Downloading multiprocess-0.70.16-py310-none-any.whl.metadata (7.2 kB)\n",
            "Collecting fsspec<=2024.9.0,>=2023.1.0 (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets)\n",
            "  Downloading fsspec-2024.9.0-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.10.10)\n",
            "Requirement already satisfied: huggingface-hub>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.26.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.4.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.1.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.17.1)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.23.0->datasets) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2024.8.30)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from yarl<2.0,>=1.12.0->aiohttp->datasets) (0.2.0)\n",
            "Downloading datasets-3.1.0-py3-none-any.whl (480 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m480.6/480.6 kB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fsspec-2024.9.0-py3-none-any.whl (179 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m179.3/179.3 kB\u001b[0m \u001b[31m12.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: xxhash, fsspec, dill, multiprocess, datasets\n",
            "  Attempting uninstall: fsspec\n",
            "    Found existing installation: fsspec 2024.10.0\n",
            "    Uninstalling fsspec-2024.10.0:\n",
            "      Successfully uninstalled fsspec-2024.10.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "gcsfs 2024.10.0 requires fsspec==2024.10.0, but you have fsspec 2024.9.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed datasets-3.1.0 dill-0.3.8 fsspec-2024.9.0 multiprocess-0.70.16 xxhash-3.5.0\n"
          ]
        }
      ],
      "source": [
        "# imports\n",
        "!pip install datasets tokenizers\n",
        "import os\n",
        "import math\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader, random_split\n",
        "from pathlib import Path\n",
        "from datasets import load_dataset\n",
        "from tqdm import tqdm\n",
        "from tokenizers import Tokenizer\n",
        "from tokenizers.models import BPE\n",
        "from tokenizers.trainers import BpeTrainer\n",
        "from tokenizers.pre_tokenizers import Whitespace"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dirs = [\"./malaygpt\", \"./tokenizer_en\", \"./tokenizer_my\"]\n",
        "for dir in dirs:\n",
        "  if os.path.exists(dir):\n",
        "    continue\n",
        "  os.mkdir(dir)"
      ],
      "metadata": {
        "id": "YUFT0-ZXvKtx"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YpgcofHKc1lv",
        "outputId": "ab8a2813-f1f0-43a8-cba4-9f27178ca92a"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Download Dataset"
      ],
      "metadata": {
        "id": "ccNZOJ8SczVN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# English/Malay pairs from HuggingFace\n",
        "train_dataset = load_dataset(\"Helsinki-NLP/opus-100\", \"en-ms\", split='train')\n",
        "validation_dataset = load_dataset(\"Helsinki-NLP/opus-100\", \"en-ms\", split='validation')\n",
        "\n",
        "# Limit the amount of data for training purposes\n",
        "raw_train_dataset, rt_to_skip = random_split(train_dataset, [1500, len(train_dataset) - 1500])\n",
        "raw_validation_dataset, vt_to_skip = random_split(validation_dataset, [50, len(validation_dataset) - 50])"
      ],
      "metadata": {
        "id": "YbPjMyoVc0Vj",
        "outputId": "bc715950-3fe5-4d25-a688-cb391d650ec7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 368,
          "referenced_widgets": [
            "dbda485d349b4ef592ce5acac3918797",
            "ce60ac885256423ebf7f2483fda6e144",
            "4d3f70fcb88244c7a05e27269c633d19",
            "bab22e3d52314fb789d2e0e3389ffa86",
            "4466f31cd61f4ead8a96825db51128fe",
            "e335bfeaa278453b827780e96c71506b",
            "c1cdbd8267a64a578a78226298943752",
            "644fac3530114cd6ae209cdca3f167a3",
            "896a23bd9a9b41ad9fe783fd15e61abc",
            "c145064e5cc74b88a534da1f94f8a8e3",
            "228c5cee5d5d44c18298e7b98195f91b",
            "040719411de94d4299ddbdc48c373eaf",
            "6bb91c751e4b45d99234710af65bf428",
            "0e75ef2e55f047f8a2fc72ee55d060f5",
            "0e377399630a4a0f8edae328f3135221",
            "52fa29db26ac4b3ba1d57971b5e0eb17",
            "f8e02ce75c02440db9b6cffbd4c39170",
            "9167ea1dff6441f98c93eefc1c040343",
            "267c7e21fa3e430080449637b7980f03",
            "1fe90ed4d8d94568a29035991b3c5ef5",
            "386459fb15ae4eb685994a9918e55e11",
            "6f5a6445be90419eb5e1e2cec2b56fad",
            "7c6d884f7c614aa29b0135786941a536",
            "f79b61b10e8046cdb6f89441a1e972b7",
            "2e03bc9b56ed46d18b3d386faaa0a79e",
            "3c1dc3078b0148099e6157c3adccb133",
            "3800b68e593e47e9963ff98333c4df22",
            "c6c95ab49b6b42f4851d8dd3c201ff84",
            "db639ec831b94b98bca0fc6a2d9f7d7a",
            "3529507942f741a8aeb150e73c31bd88",
            "cc9e3ee3a2a1443185321afd0c7305ee",
            "971fb421f71a4432828327a79cac7cca",
            "404504562a484106bd1cad8defca1aee",
            "63b09c880d554b56a7892e2fa232f91a",
            "65ad3205aff64f99ac7cd6fc79d2c1d2",
            "e0258cfa2c9f4e13aa97354e8bffcd85",
            "12f6039ad39b40a1b571e10eae89f0b3",
            "b2091e7e4a814e7f84a4c5dee5dcdb63",
            "75954f766d2145b7bbba15158efc3609",
            "65d108ad5f2d4e3fa1328adebda057e7",
            "53b1b247af674879b5fab9d97f7073d9",
            "44b739aafe364c4483910c90b9834b84",
            "fc500e1254d543fab4010f566b1c43f1",
            "fb1df1c03af54136aed93f15ff62b042",
            "35667e9f2a004794be9d95fa4043b08f",
            "141f88a5a6c544bd920e7801d7778874",
            "c635b8d0db554bb3998e53e6be6cfb2d",
            "84c36051a16f4e13a7b77ef32d425eb0",
            "ee8b073de78a48c99e66621513e48854",
            "02e138ad5e0a42f6ae0542afb00d4340",
            "3ea5ca70c440469eaecb44a443901b15",
            "24b356aefb6646a09666e78955ca267f",
            "b9e42c39237d4ff89ec298e47d01f102",
            "60cea90805544275990ccaee40a6cbff",
            "544948e742e74d73a57c8a0e7b9b30b3",
            "791caa307e874acd90952acaf4c3a852",
            "0ee20e2f562f45329aeb62c2e446dace",
            "7f218d16110541ad8f3e8edbfde5992c",
            "f8c743c9c47a44248787bd83ea4f181c",
            "1d3664a845e44aabad810743be4b2d9b",
            "382a3d4e2e0846679c3b9fb2be70eea0",
            "fdf1e39e8be0487bade47b2cad9ca1b4",
            "23d903c072a741d1b83c62dc00a71957",
            "1de48e1fd8224a8c985c852795c315e0",
            "9e865868bfc549fbb1296935ba3127e0",
            "9f1d7be3829949e6a3d44e815b2da6d4",
            "819e5b07e8ed43ecb7033d7da1c07280",
            "0c2c570229c24856b3c746b07ffc8982",
            "297540475170458cbcd2ad43c9adbff9",
            "e949b3c43bf14d41a5411a394ae6a4e2",
            "613518c0e39342a69dacb8381884260e",
            "75828e69a1f24c8f8dc04e00cf332725",
            "925e4fa416394183b81d1090c9ea415e",
            "265b0db3763f4893a796fd55cba3cab1",
            "f4fa93dedce8485580729383c4e7ee6c",
            "9b9f4111ac0347ef80957bb6a936a38a",
            "2317ea91697c416e8979435ea71ac3ad"
          ]
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "README.md:   0%|          | 0.00/65.4k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "dbda485d349b4ef592ce5acac3918797"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "test-00000-of-00001.parquet:   0%|          | 0.00/132k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "040719411de94d4299ddbdc48c373eaf"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "train-00000-of-00001.parquet:   0%|          | 0.00/57.1M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7c6d884f7c614aa29b0135786941a536"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "validation-00000-of-00001.parquet:   0%|          | 0.00/132k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "63b09c880d554b56a7892e2fa232f91a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating test split:   0%|          | 0/2000 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "35667e9f2a004794be9d95fa4043b08f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating train split:   0%|          | 0/1000000 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "791caa307e874acd90952acaf4c3a852"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating validation split:   0%|          | 0/2000 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "819e5b07e8ed43ecb7033d7da1c07280"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tokenizer"
      ],
      "metadata": {
        "id": "AGssMfD0dqOf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Returns a generator list from a dataset of the given language\n",
        "def get_ds_iterator(raw_train_dataset, lang):\n",
        "  for data in raw_train_dataset:\n",
        "    yield data[\"translation\"][lang]\n",
        "\n",
        "# Create English source tokenizer\n",
        "tokenizer_en = Tokenizer(BPE(unk_token=\"[UNK]\"))\n",
        "trainer_en = BpeTrainer(min_frequency=2, special_tokens=[\"[PAD]\", \"[UNK]\", \"[CLS]\", \"[SEP]\", \"[MASK]\"])\n",
        "# Pre-tokenizer to split input into words\n",
        "tokenizer_en.pre_tokenizer = Whitespace()\n",
        "tokenizer_en.train_from_iterator(get_ds_iterator(raw_train_dataset, \"en\"), trainer=trainer_en)\n",
        "tokenizer_en.save(\"./tokenizer_en/tokenizer_en.json\")\n",
        "\n",
        "# Create Malay source tokenizer\n",
        "tokenizer_my = Tokenizer(BPE(unk_token=\"[UNK]\"))\n",
        "trainer_my = BpeTrainer(min_frequency=2, special_tokens=[\"[PAD]\", \"[UNK]\", \"[CLS]\", \"[SEP]\", \"[MASK]\"])\n",
        "# Pre-tokenizer to split input into words\n",
        "tokenizer_my.pre_tokenizer = Whitespace()\n",
        "tokenizer_my.train_from_iterator(get_ds_iterator(raw_train_dataset, \"ms\"), trainer=trainer_my)\n",
        "tokenizer_my.save(\"./tokenizer_my/tokenizer_my.json\")"
      ],
      "metadata": {
        "id": "S90CfWtFdwLd"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Retrieve tokenizers we made\n",
        "tokenizer_en = Tokenizer.from_file(\"./tokenizer_en/tokenizer_en.json\")\n",
        "tokenizer_my = Tokenizer.from_file(\"./tokenizer_my/tokenizer_my.json\")\n",
        "\n",
        "# Get the vocab sizes\n",
        "source_vocab_size = tokenizer_en.get_vocab_size()\n",
        "target_vocab_size = tokenizer_my.get_vocab_size()"
      ],
      "metadata": {
        "id": "v_QXS5hYg77_"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max_seq_len_source = 0\n",
        "max_seq_len_target = 0\n",
        "\n",
        "# Calculate the max sequence length in the training dataset for source/target\n",
        "for data in raw_train_dataset:\n",
        "  enc_ids = tokenizer_en.encode(data[\"translation\"][\"en\"]).ids\n",
        "  dec_ids = tokenizer_my.encode(data[\"translation\"][\"ms\"]).ids\n",
        "  max_seq_len_source = max(max_seq_len_source, len(enc_ids))\n",
        "  max_seq_len_target = max(max_seq_len_target, len(dec_ids))\n",
        "\n",
        "print(\"Source vocab max sequence length:\", max_seq_len_source)\n",
        "print(\"Target vocab max sequence length:\", max_seq_len_target)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Voe9Sjhwsgl7",
        "outputId": "3fddbcf6-49ca-4e3d-9935-14066768a7a7"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Source vocab max sequence length: 80\n",
            "Target vocab max sequence length: 127\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Standard max sequence length for training, with buffer for padding, the classification token, unknown tokens, separator tokens, etc.\n",
        "max_seq_len = 155"
      ],
      "metadata": {
        "id": "MshZzC_HtnDJ"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dataset and Dataloader"
      ],
      "metadata": {
        "id": "ccMVO_M1zK6e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Causal mask to hide future tokens\n",
        "def causal_mask(size):\n",
        "  # Square matrix with ones in the lower triangle: size x size\n",
        "  mask = torch.triu(torch.ones(1, size, size), diagonal=1).type(torch.int)\n",
        "  return mask == 0"
      ],
      "metadata": {
        "id": "3jeluc5ScAEt"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Encode raw dataset to be processed by the model\n",
        "class EncodeDataset(Dataset):\n",
        "  def __init__(self, raw_dataset, max_seq_len):\n",
        "    super().__init__()\n",
        "    self.raw_dataset = raw_dataset\n",
        "    self.max_seq_len = max_seq_len\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.raw_dataset)\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "    # Fetch data (in both English and Malay) for the given index\n",
        "    raw_text = self.raw_dataset[index]\n",
        "\n",
        "    # Separate text into source and target\n",
        "    source_text = raw_text[\"translation\"][\"en\"]\n",
        "    target_text = raw_text[\"translation\"][\"ms\"]\n",
        "\n",
        "    # Encode text\n",
        "    source_text_encoded = tokenizer_en.encode(source_text).ids\n",
        "    target_text_encoded = tokenizer_my.encode(target_text).ids\n",
        "\n",
        "    # Convert CLS, SEP, and PAD to their vocab index id using the tokenizer\n",
        "    # Start of sentence token\n",
        "    CLS_ID = torch.tensor([tokenizer_my.token_to_id(\"[CLS]\")], dtype=torch.int64)\n",
        "    # End of sentence token\n",
        "    SEP_ID = torch.tensor([tokenizer_my.token_to_id(\"[SEP]\")], dtype=torch.int64)\n",
        "    # Padding token\n",
        "    PAD_ID = torch.tensor([tokenizer_my.token_to_id(\"[PAD]\")], dtype=torch.int64)\n",
        "\n",
        "    # Amount to pad the encoded text\n",
        "    num_source_padding = self.max_seq_len - len(source_text_encoded) - 2\n",
        "    num_target_padding = self.max_seq_len - len(target_text_encoded) - 1\n",
        "    encoder_padding = torch.tensor([PAD_ID] * num_source_padding, dtype=torch.int64)\n",
        "    decoder_padding = torch.tensor([PAD_ID] * num_target_padding, dtype=torch.int64)\n",
        "\n",
        "    # CLS + source encoding + SEP + padding\n",
        "    encoder_input = torch.cat([CLS_ID, torch.tensor(source_text_encoded, dtype=torch.int64), SEP_ID, encoder_padding], dim=0)\n",
        "    # CLS + target encoding + padding\n",
        "    decoder_input = torch.cat([CLS_ID, torch.tensor(target_text_encoded, dtype=torch.int64), decoder_padding], dim=0)\n",
        "\n",
        "    # target encoding + SEP + padding\n",
        "    target_label = torch.cat([torch.tensor(target_text_encoded, dtype=torch.int64), SEP_ID, decoder_padding], dim=0)\n",
        "\n",
        "    # Masks to ignore padding\n",
        "    encoder_mask = (encoder_input != PAD_ID).unsqueeze(0).unsqueeze(0).int()\n",
        "    # Apply causal mask to decoder mask, so that the decoder can't see future tokens when predicting the next token\n",
        "    decoder_mask = (decoder_input != PAD_ID).unsqueeze(0).unsqueeze(0).int() & causal_mask(decoder_input.size(0))\n",
        "\n",
        "    return {\n",
        "        \"encoder_input\": encoder_input,\n",
        "        \"decoder_input\": decoder_input,\n",
        "        \"target_label\": target_label,\n",
        "        \"encoder_mask\": encoder_mask,\n",
        "        \"decoder_mask\": decoder_mask,\n",
        "        \"source_text\": source_text,\n",
        "        \"target_text\": target_text\n",
        "    }"
      ],
      "metadata": {
        "id": "05HQMYeJXGE7"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create encoded datasets\n",
        "train_ds = EncodeDataset(raw_train_dataset, max_seq_len)\n",
        "val_ds = EncodeDataset(raw_validation_dataset, max_seq_len)\n",
        "\n",
        "# Create dataloaders to use in the model\n",
        "train_dataloader = DataLoader(train_ds, batch_size=5, shuffle=True)\n",
        "val_dataloader = DataLoader(val_ds, batch_size=1, shuffle=True)"
      ],
      "metadata": {
        "id": "KJ6AwuEXEcS3"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "encoder_input: Encoded source text with start and end of sentence tokens and padding\n",
        "decoder_input: Encoded target text with start of sentence token and padding\n",
        "target_label: Encoded target text with padding\n",
        "encoder_mask: Mask to ignore padding in the encoder input\n",
        "decoder_mask: (Causal) mask to ignore padding in the decoder input\n",
        "source_text: Original source text\n",
        "target_text: Original target text\n",
        "'''\n",
        "train_ds.__getitem__(0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0xfTHRbueAmi",
        "outputId": "1f4f855a-da02-47e7-a1aa-bb3961990977"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'encoder_input': tensor([  2, 660,  31,   3,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "           0]),\n",
              " 'decoder_input': tensor([  2, 901,  30,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "           0]),\n",
              " 'target_label': tensor([901,  30,   3,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "           0]),\n",
              " 'encoder_mask': tensor([[[1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "           0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "           0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "           0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "           0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "           0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "           0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]],\n",
              "        dtype=torch.int32),\n",
              " 'decoder_mask': tensor([[[1, 0, 0,  ..., 0, 0, 0],\n",
              "          [1, 1, 0,  ..., 0, 0, 0],\n",
              "          [1, 1, 1,  ..., 0, 0, 0],\n",
              "          ...,\n",
              "          [1, 1, 1,  ..., 0, 0, 0],\n",
              "          [1, 1, 1,  ..., 0, 0, 0],\n",
              "          [1, 1, 1,  ..., 0, 0, 0]]], dtype=torch.int32),\n",
              " 'source_text': 'When?',\n",
              " 'target_text': 'Bila?'}"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Input Embedding and Positional Encoding"
      ],
      "metadata": {
        "id": "UD2iPLMjfo3V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Embedding layer with normalized embeddings\n",
        "class EmbeddingLayer(nn.Module):\n",
        "  def __init__(self, d_model: int, vocab_size: int):\n",
        "    super().__init__()\n",
        "    self.d_model = d_model\n",
        "    # Embedding layer to map token ids to embeddings (vocab_size x d_model)\n",
        "    self.embedding = nn.Embedding(vocab_size, d_model)\n",
        "\n",
        "  def forward(self, input):\n",
        "    # Multiply embedding by the sqrt(d_model) to normalize the output\n",
        "    embedding_output = self.embedding(input) * math.sqrt(self.d_model)\n",
        "    return embedding_output"
      ],
      "metadata": {
        "id": "sVPnN5q5fqeL"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Positional encoding layer\n",
        "class PositionalEncoding(nn.Module):\n",
        "  def __init__(self, d_model: int, max_seq_len: int, dropout_rate: float):\n",
        "    super().__init__()\n",
        "    self.dropout = nn.Dropout(dropout_rate)\n",
        "\n",
        "    # Init positional encodings, positions\n",
        "    pe = torch.zeros(max_seq_len, d_model)\n",
        "    pos = torch.arange(0, max_seq_len, dtype=torch.float).unsqueeze(1)\n",
        "    # 1 / (10000 ** (2 * i / d_model))\n",
        "    div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
        "\n",
        "    # Apply div term to positional encodings, with sin/cos depending on even/odd dimensions\n",
        "    pe[:, 0::2] = torch.sin(pos * div_term)\n",
        "    pe[:, 1::2] = torch.cos(pos * div_term)\n",
        "\n",
        "    # Add batch dimension\n",
        "    # pe: 1 x seq_len x d_model\n",
        "    pe = pe.unsqueeze(0)\n",
        "    # Ensure that the positional encodings are a part of the model, but not trainable\n",
        "    self.register_buffer(\"pe\", pe)\n",
        "\n",
        "  def forward(self, input_embedding):\n",
        "    # input_embedding: batch_size x seq_len x d_model\n",
        "    input_embedding = input_embedding + (self.pe[:, :input_embedding.shape[1], :]).requires_grad_(False)\n",
        "    return self.dropout(input_embedding)"
      ],
      "metadata": {
        "id": "eTBhskyJhcQ-"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Multi-Head Attention"
      ],
      "metadata": {
        "id": "xbsFakYnswg-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Multihead attention block to get context\n",
        "class MultiHeadAttention(nn.Module):\n",
        "  def __init__(self, d_model: int, num_heads: int, dropout_rate: float):\n",
        "    super().__init__()\n",
        "    self.dropout = nn.Dropout(dropout_rate)\n",
        "    self.num_heads = num_heads\n",
        "\n",
        "    # d_model must be divisible by the number of heads\n",
        "    assert d_model % num_heads == 0\n",
        "\n",
        "    # Dimension of each self attention head\n",
        "    self.d_k = d_model // num_heads\n",
        "\n",
        "    # Init weight matrices\n",
        "    self.W_q = nn.Linear(d_model, d_model, bias=False)\n",
        "    self.W_k = nn.Linear(d_model, d_model, bias=False)\n",
        "    self.W_v = nn.Linear(d_model, d_model, bias=False)\n",
        "    self.W_o = nn.Linear(d_model, d_model, bias=False)\n",
        "\n",
        "  def forward(self, q, k, v, encoder_mask):\n",
        "    # q, k, v: batch_size x seq_len x d_model\n",
        "\n",
        "    # Multiply input embeddings by weights\n",
        "    query = self.W_q(q)\n",
        "    key = self.W_k(k)\n",
        "    value = self.W_v(v)\n",
        "\n",
        "    # Divide query, key, and value into the number of heads\n",
        "    # query, key, value: batch_size x num_heads x seq_len x d_k\n",
        "    query = query.view(query.shape[0], query.shape[1], self.num_heads, self.d_k).transpose(1, 2)\n",
        "    key = key.view(key.shape[0], key.shape[1], self.num_heads, self.d_k).transpose(1, 2)\n",
        "    value = value.view(value.shape[0], value.shape[1], self.num_heads, self.d_k).transpose(1, 2)\n",
        "\n",
        "    # SELF ATTENTION BLOCK\n",
        "    # -------------------------\n",
        "\n",
        "    # Attention score based on the similarity between the query and key\n",
        "    # attention_score: batch_size x num_heads x seq_len x seq_len\n",
        "    attention_score = (query @ key.transpose(-2, -1)) / math.sqrt(self.d_k)\n",
        "\n",
        "    # Apply encoder/causal mask\n",
        "    if encoder_mask is not None:\n",
        "      attention_score.masked_fill_(encoder_mask == 0, -1e9)\n",
        "\n",
        "    # Apply softmax\n",
        "    attention_score = attention_score.softmax(dim=-1)\n",
        "\n",
        "    # Apply dropout\n",
        "    if self.dropout is not None:\n",
        "      attention_score = self.dropout(attention_score)\n",
        "\n",
        "    # Multiply attention score with the value\n",
        "    # attention_output: batch_size x num_heads x seq_len x d_k\n",
        "    attention_output = attention_score @ value\n",
        "\n",
        "    # -------------------------\n",
        "\n",
        "    # Concatenate all the output heads\n",
        "    # attention_output: batch_size x seq_len x d_model\n",
        "    attention_output = attention_output.transpose(1, 2).contiguous().view(attention_output.shape[0], -1, self.num_heads * self.d_k)\n",
        "\n",
        "    # Multiply attention output by output weights\n",
        "    multihead_output = self.W_o(attention_output)\n",
        "\n",
        "    return multihead_output"
      ],
      "metadata": {
        "id": "KL3cSgHDswAJ"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Feedforward, Layer Normalization, and AddAndNorm"
      ],
      "metadata": {
        "id": "GJsZAsL9z7YP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Two linear layers, with dropout and ReLU activation\n",
        "class FeedForward(nn.Module):\n",
        "  def __init__(self, d_model: int, d_ff: int, dropout_rate: float):\n",
        "    super().__init__()\n",
        "    self.dropout = nn.Dropout(dropout_rate)\n",
        "    self.layer_1 = nn.Linear(d_model, d_ff)\n",
        "    self.layer_2 = nn.Linear(d_ff, d_model)\n",
        "\n",
        "  def forward(self, input):\n",
        "    return self.layer_2(self.dropout(torch.relu(self.layer_1(input))))"
      ],
      "metadata": {
        "id": "yfilODjF0AEB"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Layer normalization with scaling (gamma) and shifting (beta)\n",
        "class LayerNorm(nn.Module):\n",
        "  def __init__(self, eps: float = 1e-5):\n",
        "    super().__init__()\n",
        "    # Epsilon is for divide-by-zero errors\n",
        "    self.eps = eps\n",
        "    # Extra learning params to scale and shift embedding values; same number of weights as d_model\n",
        "    self.gamma = nn.Parameter(torch.ones(512))\n",
        "    self.beta = nn.Parameter(torch.zeros(512))\n",
        "\n",
        "  def forward(self, input):\n",
        "    mean = input.mean(dim=-1, keepdim=True)\n",
        "    std = input.std(dim=-1, keepdim=True)\n",
        "    return self.gamma * (input - mean) / (std + self.eps) + self.beta"
      ],
      "metadata": {
        "id": "iOLDlOav0em-"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Layer normalization and skip connection\n",
        "class AddAndNorm(nn.Module):\n",
        "  def __init__(self, dropout_rate: float):\n",
        "    super().__init__()\n",
        "    self.dropout = nn.Dropout(dropout_rate)\n",
        "    self.layer_norm = LayerNorm()\n",
        "\n",
        "  def forward(self, input, sub_layer):\n",
        "    return input + self.dropout(sub_layer(self.layer_norm(input)))"
      ],
      "metadata": {
        "id": "W22oPP8F2Kfq"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Encoder Block and Encoder"
      ],
      "metadata": {
        "id": "5WkmqUqY36LR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Multihead attention and feed forward blocks, with add-and-norm\n",
        "class EncoderBlock(nn.Module):\n",
        "  def __init__(self, multihead_attention: MultiHeadAttention, feed_forward: FeedForward, dropout_rate: float) -> None:\n",
        "    super().__init__()\n",
        "    self.multihead_attention = multihead_attention\n",
        "    self.feed_forward = feed_forward\n",
        "    self.addnorm_1 = AddAndNorm(dropout_rate)\n",
        "    self.addnorm_2 = AddAndNorm(dropout_rate)\n",
        "\n",
        "  def forward(self, encoder_input, encoder_mask):\n",
        "    # Encoder input from skip connection and Multihead Attention block\n",
        "    encoder_input = self.addnorm_1(encoder_input, lambda encoder_input: self.multihead_attention(encoder_input, encoder_input, encoder_input, encoder_mask))\n",
        "    # Multihead Attention output from skip connection and Feed Forward block\n",
        "    encoder_input = self.addnorm_2(encoder_input, self.feed_forward)\n",
        "\n",
        "    return encoder_input"
      ],
      "metadata": {
        "id": "05xfP24BBnAx"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Multiple encoder blocks and layer normalization\n",
        "class Encoder(nn.Module):\n",
        "  def __init__(self, encoderblocklist: nn.ModuleList) -> None:\n",
        "    super().__init__()\n",
        "    self.encoderblocklist = encoderblocklist\n",
        "    self.layer_norm = LayerNorm()\n",
        "\n",
        "  def forward(self, encoder_input, encoder_mask):\n",
        "    # Loop input through all encoder blocks\n",
        "    for encoderblock in self.encoderblocklist:\n",
        "      encoder_input = encoderblock(encoder_input, encoder_mask)\n",
        "    # Normalize the final encoder block output\n",
        "    encoder_output = self.layer_norm(encoder_input)\n",
        "    return encoder_output"
      ],
      "metadata": {
        "id": "tghbeybhEYP4"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Decoder Block, Decoder, and Projection Layer"
      ],
      "metadata": {
        "id": "2dY7dD5kFP9i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Masked multihead attention, cross multihead attention from encoder output, and feed forward blocks, with add-and-norm\n",
        "class DecoderBlock(nn.Module):\n",
        "  def __init__(self, masked_multihead_attention: MultiHeadAttention, cross_multihead_attention: MultiHeadAttention, feed_forward: FeedForward, dropout_rate: float) -> None:\n",
        "    super().__init__()\n",
        "    # Uses a causal mask\n",
        "    self.masked_multihead_attention = masked_multihead_attention\n",
        "    # Uses multihead attention from the output of the encoder\n",
        "    self.cross_multihead_attention = cross_multihead_attention\n",
        "    self.feed_forward = feed_forward\n",
        "    self.addnorm_1 = AddAndNorm(dropout_rate)\n",
        "    self.addnorm_2 = AddAndNorm(dropout_rate)\n",
        "    self.addnorm_3 = AddAndNorm(dropout_rate)\n",
        "\n",
        "  def forward(self, decoder_input, encoder_output, encoder_mask, decoder_mask):\n",
        "    # Decoder input from skip connection and Masked Multihead Attention block\n",
        "    decoder_input = self.addnorm_1(decoder_input, lambda decoder_input: self.masked_multihead_attention(decoder_input, decoder_input, decoder_input, decoder_mask))\n",
        "    # Masked Multihead Attention output from skip connection and Cross Multihead Attention block\n",
        "    decoder_input = self.addnorm_2(decoder_input, lambda decoder_input: self.cross_multihead_attention(decoder_input, encoder_output, encoder_output, encoder_mask))\n",
        "    # Cross Multihead Attention output from skip connection and Feed Forward block\n",
        "    decoder_input = self.addnorm_3(decoder_input, self.feed_forward)\n",
        "    return decoder_input"
      ],
      "metadata": {
        "id": "5Y0T2hWWFS6z"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Multiple decoder blocks and layer normalization\n",
        "class Decoder(nn.Module):\n",
        "  def __init__(self, decoderblocklist: nn.ModuleList) -> None:\n",
        "    super().__init__()\n",
        "    self.decoderblocklist = decoderblocklist\n",
        "    self.layer_norm = LayerNorm()\n",
        "\n",
        "  def forward(self, decoder_input, encoder_output, encoder_mask, decoder_mask):\n",
        "    # Loop input through all decoder blocks\n",
        "    for decoderblock in self.decoderblocklist:\n",
        "      decoder_input = decoderblock(decoder_input, encoder_output, encoder_mask, decoder_mask)\n",
        "    # Normalize the final decoder block output\n",
        "    decoder_output = self.layer_norm(decoder_input)\n",
        "    return decoder_output"
      ],
      "metadata": {
        "id": "y2Zcl1xiHzWw"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Linear layer and softmax activation\n",
        "class ProjectionLayer(nn.Module):\n",
        "  def __init__(self, d_model: int, vocab_size: int) -> None:\n",
        "    super().__init__()\n",
        "    self.projection_layer = nn.Linear(d_model, vocab_size)\n",
        "\n",
        "  def forward(self, decoder_output):\n",
        "    # output: batch_size x seq_len x vocab_size\n",
        "    output = self.projection_layer(decoder_output)\n",
        "    return output"
      ],
      "metadata": {
        "id": "a7KyqoUlIrYJ"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Transformer"
      ],
      "metadata": {
        "id": "v5rlc7mPKKVl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Full transformer model; encodes embeddings, decodes outputs, and projects predictions\n",
        "class Transformer(nn.Module):\n",
        "  def __init__(self, encoder: Encoder, decoder: Decoder, source_embed: EmbeddingLayer, target_embed: EmbeddingLayer, source_pos: PositionalEncoding, target_pos: PositionalEncoding, projection_layer: ProjectionLayer) -> None:\n",
        "    super().__init__()\n",
        "    # Encode\n",
        "    self.source_embed = source_embed\n",
        "    self.source_pos = source_pos\n",
        "    self.encoder = encoder\n",
        "\n",
        "    # Decode\n",
        "    self.target_embed = target_embed\n",
        "    self.target_pos = target_pos\n",
        "    self.decoder = decoder\n",
        "\n",
        "    # Maps decoder output to vocabulary\n",
        "    self.projection_layer = projection_layer\n",
        "\n",
        "  def encode(self, encoder_input, encoder_mask):\n",
        "    encoder_input = self.source_embed(encoder_input)\n",
        "    encoder_input = self.source_pos(encoder_input)\n",
        "    encoder_output = self.encoder(encoder_input, encoder_mask)\n",
        "    return encoder_output\n",
        "\n",
        "  def decode(self, encoder_output, encoder_mask, decoder_input, decoder_mask):\n",
        "    decoder_input = self.target_embed(decoder_input)\n",
        "    decoder_input = self.target_pos(decoder_input)\n",
        "    decoder_output = self.decoder(decoder_input, encoder_output, encoder_mask, decoder_mask)\n",
        "    return decoder_output\n",
        "\n",
        "  def project(self, decoder_output):\n",
        "    return self.projection_layer(decoder_output)"
      ],
      "metadata": {
        "id": "U-aAhfIsKLRI"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_model(source_vocab_size, target_vocab_size, source_seq_len, target_seq_len, d_model=512, num_blocks=6, num_heads=8, dropout_rate=0.1, d_ff=2048):\n",
        "  # Embedding layers\n",
        "  source_embed = EmbeddingLayer(d_model, source_vocab_size)\n",
        "  target_embed = EmbeddingLayer(d_model, target_vocab_size)\n",
        "\n",
        "  # Positional encoding layers\n",
        "  source_pos = PositionalEncoding(d_model, source_seq_len, dropout_rate)\n",
        "  target_pos = PositionalEncoding(d_model, target_seq_len, dropout_rate)\n",
        "\n",
        "  # Encoder block list\n",
        "  encoderblocklist = []\n",
        "  for _ in range(num_blocks):\n",
        "    multihead_attention = MultiHeadAttention(d_model, num_heads, dropout_rate)\n",
        "    feed_forward = FeedForward(d_model, d_ff, dropout_rate)\n",
        "    encoder_block = EncoderBlock(multihead_attention, feed_forward, dropout_rate)\n",
        "    encoderblocklist.append(encoder_block)\n",
        "  # Encoder\n",
        "  encoder = Encoder(nn.ModuleList(encoderblocklist))\n",
        "\n",
        "  # Decoder block list\n",
        "  decoderblocklist = []\n",
        "  for _ in range(num_blocks):\n",
        "    masked_multihead_attention = MultiHeadAttention(d_model, num_heads, dropout_rate)\n",
        "    cross_multihead_attention = MultiHeadAttention(d_model, num_heads, dropout_rate)\n",
        "    feed_forward = FeedForward(d_model, d_ff, dropout_rate)\n",
        "    decoder_block = DecoderBlock(masked_multihead_attention, cross_multihead_attention, feed_forward, dropout_rate)\n",
        "    decoderblocklist.append(decoder_block)\n",
        "  # Decoder\n",
        "  decoder = Decoder(nn.ModuleList(decoderblocklist))\n",
        "\n",
        "  # Projection layer\n",
        "  projection_layer = ProjectionLayer(d_model, target_vocab_size)\n",
        "\n",
        "  # Transformer\n",
        "  model = Transformer(encoder, decoder, source_embed, target_embed, source_pos, target_pos, projection_layer)\n",
        "\n",
        "  # Init model params\n",
        "  for p in model.parameters():\n",
        "    if p.dim() > 1:\n",
        "      nn.init.xavier_uniform_(p)\n",
        "\n",
        "  return model"
      ],
      "metadata": {
        "id": "ZWi_S5RuLwEY"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create model\n",
        "model = build_model(tokenizer_en.get_vocab_size(), tokenizer_my.get_vocab_size(), max_seq_len, max_seq_len, d_model=512).to(device)\n",
        "\n",
        "print(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kWUzQoyZNeUE",
        "outputId": "451e83f3-b5b6-4464-c271-9a44c3e803c5"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Transformer(\n",
            "  (source_embed): EmbeddingLayer(\n",
            "    (embedding): Embedding(1939, 512)\n",
            "  )\n",
            "  (source_pos): PositionalEncoding(\n",
            "    (dropout): Dropout(p=0.1, inplace=False)\n",
            "  )\n",
            "  (encoder): Encoder(\n",
            "    (encoderblocklist): ModuleList(\n",
            "      (0-5): 6 x EncoderBlock(\n",
            "        (multihead_attention): MultiHeadAttention(\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "          (W_q): Linear(in_features=512, out_features=512, bias=False)\n",
            "          (W_k): Linear(in_features=512, out_features=512, bias=False)\n",
            "          (W_v): Linear(in_features=512, out_features=512, bias=False)\n",
            "          (W_o): Linear(in_features=512, out_features=512, bias=False)\n",
            "        )\n",
            "        (feed_forward): FeedForward(\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "          (layer_1): Linear(in_features=512, out_features=2048, bias=True)\n",
            "          (layer_2): Linear(in_features=2048, out_features=512, bias=True)\n",
            "        )\n",
            "        (addnorm_1): AddAndNorm(\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "          (layer_norm): LayerNorm()\n",
            "        )\n",
            "        (addnorm_2): AddAndNorm(\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "          (layer_norm): LayerNorm()\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (layer_norm): LayerNorm()\n",
            "  )\n",
            "  (target_embed): EmbeddingLayer(\n",
            "    (embedding): Embedding(2210, 512)\n",
            "  )\n",
            "  (target_pos): PositionalEncoding(\n",
            "    (dropout): Dropout(p=0.1, inplace=False)\n",
            "  )\n",
            "  (decoder): Decoder(\n",
            "    (decoderblocklist): ModuleList(\n",
            "      (0-5): 6 x DecoderBlock(\n",
            "        (masked_multihead_attention): MultiHeadAttention(\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "          (W_q): Linear(in_features=512, out_features=512, bias=False)\n",
            "          (W_k): Linear(in_features=512, out_features=512, bias=False)\n",
            "          (W_v): Linear(in_features=512, out_features=512, bias=False)\n",
            "          (W_o): Linear(in_features=512, out_features=512, bias=False)\n",
            "        )\n",
            "        (cross_multihead_attention): MultiHeadAttention(\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "          (W_q): Linear(in_features=512, out_features=512, bias=False)\n",
            "          (W_k): Linear(in_features=512, out_features=512, bias=False)\n",
            "          (W_v): Linear(in_features=512, out_features=512, bias=False)\n",
            "          (W_o): Linear(in_features=512, out_features=512, bias=False)\n",
            "        )\n",
            "        (feed_forward): FeedForward(\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "          (layer_1): Linear(in_features=512, out_features=2048, bias=True)\n",
            "          (layer_2): Linear(in_features=2048, out_features=512, bias=True)\n",
            "        )\n",
            "        (addnorm_1): AddAndNorm(\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "          (layer_norm): LayerNorm()\n",
            "        )\n",
            "        (addnorm_2): AddAndNorm(\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "          (layer_norm): LayerNorm()\n",
            "        )\n",
            "        (addnorm_3): AddAndNorm(\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "          (layer_norm): LayerNorm()\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (layer_norm): LayerNorm()\n",
            "  )\n",
            "  (projection_layer): ProjectionLayer(\n",
            "    (projection_layer): Linear(in_features=512, out_features=2210, bias=True)\n",
            "  )\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Validation"
      ],
      "metadata": {
        "id": "DQW533JSN9Vy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def run_validation(model, validation_ds, tokenizer_en, tokenizer_my, max_seq_len, device, print_msg, global_step):\n",
        "  # Change model to only evaluate\n",
        "  model.eval()\n",
        "  count = 0\n",
        "\n",
        "  # Don\"t calculate gradients during evaluation\n",
        "  with torch.no_grad():\n",
        "    for batch in validation_ds:\n",
        "      count += 1\n",
        "\n",
        "      # Get input and mask\n",
        "      encoder_input = batch[\"encoder_input\"].to(device)\n",
        "      encoder_mask = batch[\"encoder_mask\"].to(device)\n",
        "\n",
        "      # Begin and end of sentence tokens\n",
        "      cls_id = tokenizer_my.token_to_id(\"[CLS]\")\n",
        "      sep_id = tokenizer_my.token_to_id(\"[SEP]\")\n",
        "\n",
        "      # Calculate output of the encoder from the val sequence\n",
        "      encoder_output = model.encode(encoder_input, encoder_mask)\n",
        "\n",
        "      # Decoder input first token is the beginning of sentence token\n",
        "      decoder_input = torch.empty(1, 1).fill_(cls_id).type_as(encoder_input).to(device)\n",
        "\n",
        "      # Iteratively add tokens\n",
        "      while True:\n",
        "        # Decoder input is the max length\n",
        "        if decoder_input.size(1) == max_seq_len:\n",
        "          break\n",
        "\n",
        "        # Recreate causal mask for token prediction with a new decoder input\n",
        "        decoder_mask = causal_mask(decoder_input.size(1)).type_as(encoder_mask).to(device)\n",
        "\n",
        "        # Get probabilities for the next token\n",
        "        out = model.decode(encoder_output, encoder_mask, decoder_input, decoder_mask)\n",
        "        prob = model.project(out[:, -1])\n",
        "\n",
        "        # Greedily get the next token with the highest probability\n",
        "        _, next_word = torch.max(prob, dim=1)\n",
        "\n",
        "        # Add predicted token to the decoder input\n",
        "        decoder_input = torch.cat([decoder_input, torch.empty(1, 1).type_as(encoder_input).fill_(next_word.item()).to(device)], dim=1)\n",
        "\n",
        "        # Next token is the end of sentence token\n",
        "        if next_word == sep_id:\n",
        "          break\n",
        "\n",
        "      model_out = decoder_input.squeeze(0)\n",
        "\n",
        "      # Get source text, target text, and predicted text\n",
        "      source_text = batch[\"source_text\"][0]\n",
        "      target_text = batch[\"target_text\"][0]\n",
        "      model_out_text = tokenizer_my.decode(model_out.detach().cpu().numpy())\n",
        "\n",
        "      print_msg(\"-\" * 55)\n",
        "      print_msg(f\"Source Text: {source_text}\")\n",
        "      print_msg(f\"Target Text: {target_text}\")\n",
        "      print_msg(f\"Predicted by MalayGPT: {model_out_text}\")\n",
        "\n",
        "      if count == 2:\n",
        "        break"
      ],
      "metadata": {
        "id": "kBzBcKuON-VV"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training"
      ],
      "metadata": {
        "id": "BmfPR3f3VyZF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(preload_epoch=None):\n",
        "  EPOCHS = 100\n",
        "  initial_epoch = 0\n",
        "  global_step = 0\n",
        "\n",
        "  optimizer = torch.optim.Adam(model.parameters(), lr=1e-4, eps=1e-9)\n",
        "\n",
        "  # Start at preloaded epoch, weights, and optimizer\n",
        "  if preload_epoch is not None:\n",
        "    # Load model\n",
        "    model_filename = f\"./malaygpt/model_{preload_epoch}.pth\"\n",
        "    state = torch.load(model_filename)\n",
        "    model.load_state_dict(state[\"model_state_dict\"])\n",
        "    # Get initial epoch\n",
        "    initial_epoch = state[\"epoch\"] + 1\n",
        "    # Get initial optimizer\n",
        "    optimizer.load_state_dict(state[\"optimizer_state_dict\"])\n",
        "    global_step = state[\"global_step\"]\n",
        "\n",
        "  loss_fn = nn.CrossEntropyLoss(ignore_index=tokenizer_en.token_to_id(\"[PAD]\"), label_smoothing=0.1).to(device)\n",
        "\n",
        "  for epoch in range(initial_epoch, EPOCHS):\n",
        "    # Change model to train\n",
        "    model.train()\n",
        "    # Load dataset batches\n",
        "    batch_iterator = tqdm(train_dataloader, desc=f\"Processing Epoch {epoch:02d}\")\n",
        "    for batch in batch_iterator:\n",
        "      # batch_size x seq_len\n",
        "      encoder_input = batch[\"encoder_input\"].to(device)\n",
        "      # batch_size x seq_len\n",
        "      decoder_input = batch[\"decoder_input\"].to(device)\n",
        "      # batch_size x 1 x 1 x seq_len\n",
        "      encoder_mask = batch[\"encoder_mask\"].to(device)\n",
        "      # batch_size x 1 x seq_len x seq_len\n",
        "      decoder_mask = batch[\"decoder_mask\"].to(device)\n",
        "      # batch_size x seq_len\n",
        "      target_label = batch[\"target_label\"].to(device)\n",
        "\n",
        "      # batch_size x seq_len x d_model\n",
        "      encoder_output = model.encode(encoder_input, encoder_mask)\n",
        "      decoder_output = model.decode(encoder_output, encoder_mask, decoder_input, decoder_mask)\n",
        "      # batch_size x seq_len x vocab_size\n",
        "      projection_output = model.project(decoder_output)\n",
        "\n",
        "      # Calculate loss of the batch\n",
        "      loss = loss_fn(projection_output.view(-1, tokenizer_my.get_vocab_size()), target_label.view(-1))\n",
        "      batch_iterator.set_postfix({\"loss\": f\"{loss.item():6.3f}\"})\n",
        "      loss.backward()\n",
        "\n",
        "      optimizer.step()\n",
        "      optimizer.zero_grad(set_to_none=True)\n",
        "\n",
        "      global_step += 1\n",
        "\n",
        "    # Run validation after every epoch\n",
        "    run_validation(model, val_dataloader, tokenizer_en, tokenizer_my, max_seq_len, device, lambda msg: batch_iterator.write(msg), global_step)\n",
        "\n",
        "    model_filename = f\"./malaygpt/model_{epoch}.pt\"\n",
        "    torch.save({\n",
        "        \"epoch\": epoch,\n",
        "        \"model_state_dict\": model.state_dict(),\n",
        "        \"optimizer_state_dict\": optimizer.state_dict(),\n",
        "        \"global_step\": global_step\n",
        "    }, model_filename)"
      ],
      "metadata": {
        "id": "7wVXGox5Nrdf"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_model(preload_epoch=None)"
      ],
      "metadata": {
        "id": "Z0W0tmreV2kt",
        "outputId": "7c3e9a1d-5c8b-4194-dae9-71f24bac7bc6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing Epoch 00: 100%|██████████| 300/300 [00:31<00:00,  9.41it/s, loss=1.514]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------------------------------------------------\n",
            "Source Text: Case Sens\n",
            "Target Text: Sensi Kata\n",
            "Predicted by MalayGPT: C anti\n",
            "-------------------------------------------------------\n",
            "Source Text: Some kid gave to me.\n",
            "Target Text: Ada budak berikannya pada saya.\n",
            "Predicted by MalayGPT: - Siapa punya ini .\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing Epoch 01: 100%|██████████| 300/300 [00:30<00:00,  9.70it/s, loss=1.544]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------------------------------------------------\n",
            "Source Text: WOMAN: There's a mix-up with my reservation.\n",
            "Target Text: Ada kesilapan dalam tempahan saya.\n",
            "Predicted by MalayGPT: Aku akan menembak nya ! tapi pen cu I di sini .\n",
            "-------------------------------------------------------\n",
            "Source Text: How is Young Do doing?\n",
            "Target Text: Yeong Do. okeykah?\n",
            "Predicted by MalayGPT: Bagaimana dengan An dy ?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing Epoch 02: 100%|██████████| 300/300 [00:31<00:00,  9.66it/s, loss=1.365]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------------------------------------------------\n",
            "Source Text: Too bad I'm not younger, or I'd lend you a hand.\n",
            "Target Text: Aku tak akan menolong kamu\n",
            "Predicted by MalayGPT: Aku tak nampak kamu mati di sini utk memas tikan awak .\n",
            "-------------------------------------------------------\n",
            "Source Text: I'll kill him, the useless little sewer rat!\n",
            "Target Text: Aku akan bunuh dia!\n",
            "Predicted by MalayGPT: Aku dah sedia , aku takkan berharap pada O re os hi m yang men el efon nya .\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing Epoch 03: 100%|██████████| 300/300 [00:31<00:00,  9.57it/s, loss=1.387]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------------------------------------------------\n",
            "Source Text: -Hey, Angela.\n",
            "Target Text: - Hei, Angela.\n",
            "Predicted by MalayGPT: Oh , baw akan en am .\n",
            "-------------------------------------------------------\n",
            "Source Text: How is Young Do doing?\n",
            "Target Text: Yeong Do. okeykah?\n",
            "Predicted by MalayGPT: Adakah peguam nya membuat apa - apa ke ma juan ?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing Epoch 04: 100%|██████████| 300/300 [00:31<00:00,  9.64it/s, loss=1.252]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------------------------------------------------\n",
            "Source Text: What do you mean?\n",
            "Target Text: Apa maksud kamu?\n",
            "Predicted by MalayGPT: Apa yang awak maksudkan dengan L ana ?\n",
            "-------------------------------------------------------\n",
            "Source Text: You don't have to write anything down to be a poet.\n",
            "Target Text: [Arthur] Anda dont mempunyai untuk menulis sesuatu bawah menjadi seorang penyair.\n",
            "Predicted by MalayGPT: Anda tidak boleh meletakkan ia dalam minuman .\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing Epoch 05: 100%|██████████| 300/300 [00:31<00:00,  9.64it/s, loss=1.300]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------------------------------------------------\n",
            "Source Text: Your condolences are appreciated but your help is unnecessary unless you can name the Americans responsible.\n",
            "Target Text: Takziah kamu dihargai tetapi bantuan kamu tidak perlu melainkan kamu boleh menamakan rakyat Amerika yang bertanggungjawab.\n",
            "Predicted by MalayGPT: Hanya beberapa lelaki yang membunuh untuk yang masuk ke per ga d uhan bar hidup .\n",
            "-------------------------------------------------------\n",
            "Source Text: Password _type:\n",
            "Target Text: _Katalaluan:\n",
            "Predicted by MalayGPT: P eg awai par k ing hanya ber tugas di bahagian barat s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing Epoch 06: 100%|██████████| 300/300 [00:31<00:00,  9.62it/s, loss=1.603]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------------------------------------------------\n",
            "Source Text: There are leafs in the way.\n",
            "Target Text: Ada reranting dan daun.\n",
            "Predicted by MalayGPT: - Ada yang mau beli makanan .\n",
            "-------------------------------------------------------\n",
            "Source Text: You don't have to write anything down to be a poet.\n",
            "Target Text: [Arthur] Anda dont mempunyai untuk menulis sesuatu bawah menjadi seorang penyair.\n",
            "Predicted by MalayGPT: Kau tak buat salah .\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing Epoch 07: 100%|██████████| 300/300 [00:31<00:00,  9.64it/s, loss=1.323]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------------------------------------------------\n",
            "Source Text: #There is a budding flower And I'm mad for her#\n",
            "Target Text: # Terdapat bunga tunas dan saya gila padanya #\n",
            "Predicted by MalayGPT: G el in tar pemacu pen cetak untuk di muat turun\n",
            "-------------------------------------------------------\n",
            "Source Text: You're pulling my leg, aren't you?\n",
            "Target Text: Kau nak menentang aku?\n",
            "Predicted by MalayGPT: Kau katakan pada mereka aku melakukan ini , okey ?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing Epoch 08: 100%|██████████| 300/300 [00:31<00:00,  9.67it/s, loss=1.359]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------------------------------------------------\n",
            "Source Text: Then stop right now!\n",
            "Target Text: Dah, berhenti...\n",
            "Predicted by MalayGPT: Sekarang kau nak sekarang !\n",
            "-------------------------------------------------------\n",
            "Source Text: -Hey, Angela.\n",
            "Target Text: - Hei, Angela.\n",
            "Predicted by MalayGPT: - Dia juga cuba tengok .\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing Epoch 09: 100%|██████████| 300/300 [00:31<00:00,  9.53it/s, loss=1.285]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------------------------------------------------\n",
            "Source Text: This guy is going to have a lot of surveillance.\n",
            "Target Text: This guy is going to have a lot of surveillance.\n",
            "Predicted by MalayGPT: Orang ini mempunyai pulau dan j et sendiri , he bat sekali .\n",
            "-------------------------------------------------------\n",
            "Source Text: Chris Ryan instead opts to take a knee.\n",
            "Target Text: Chris Ryan malah melutut.\n",
            "Predicted by MalayGPT: F le k si bil iti M ini mal di laluan pen dekat an .\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing Epoch 10: 100%|██████████| 300/300 [00:31<00:00,  9.66it/s, loss=1.249]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------------------------------------------------\n",
            "Source Text: But the past few days.. ...we've been doing rounds of the visa and passport office.\n",
            "Target Text: Tapi sejak beberapa hari... ..kami sibuk mengurus visa dan passport.\n",
            "Predicted by MalayGPT: Tapi k ini , kami mem an dang ke hada pan bahawa sebagai rak ya t kita tidak tunduk .\n",
            "-------------------------------------------------------\n",
            "Source Text: Mr Raj, folks I like can call me Chutki\n",
            "Target Text: Raj, orang yang saya suka boleh panggil saya Chutki\n",
            "Predicted by MalayGPT: U ni ah aku nak be benang carian CD\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing Epoch 11: 100%|██████████| 300/300 [00:31<00:00,  9.62it/s, loss=1.245]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------------------------------------------------\n",
            "Source Text: Too bad I'm not younger, or I'd lend you a hand.\n",
            "Target Text: Aku tak akan menolong kamu\n",
            "Predicted by MalayGPT: Aku tak tahu macam mana kau , tapi takkan bertanya tentang awak .\n",
            "-------------------------------------------------------\n",
            "Source Text: Mr Raj, folks I like can call me Chutki\n",
            "Target Text: Raj, orang yang saya suka boleh panggil saya Chutki\n",
            "Predicted by MalayGPT: U ni , In di i put nya .\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing Epoch 12: 100%|██████████| 300/300 [00:31<00:00,  9.62it/s, loss=1.260]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------------------------------------------------\n",
            "Source Text: Who are you? I am Genus.\n",
            "Target Text: Baiklah.\n",
            "Predicted by MalayGPT: Siapakah kamu tahu macam mana ?\n",
            "-------------------------------------------------------\n",
            "Source Text: Take their statement.\n",
            "Target Text: Ambil kenyataan mereka.\n",
            "Predicted by MalayGPT: L en ny .\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing Epoch 13: 100%|██████████| 300/300 [00:31<00:00,  9.60it/s, loss=1.326]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------------------------------------------------\n",
            "Source Text: The black queen.\n",
            "Target Text: Ratu hitam.\n",
            "Predicted by MalayGPT: Ser onok tengok dua orang ni berg om o i lagi .\n",
            "-------------------------------------------------------\n",
            "Source Text: I'll kill him, the useless little sewer rat!\n",
            "Target Text: Aku akan bunuh dia!\n",
            "Predicted by MalayGPT: Aku dah sedia untuk kembali ber kerja .\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing Epoch 14: 100%|██████████| 300/300 [00:31<00:00,  9.65it/s, loss=1.374]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------------------------------------------------\n",
            "Source Text: Case Sens\n",
            "Target Text: Sensi Kata\n",
            "Predicted by MalayGPT: C os s\n",
            "-------------------------------------------------------\n",
            "Source Text: WOMAN: There's a mix-up with my reservation.\n",
            "Target Text: Ada kesilapan dalam tempahan saya.\n",
            "Predicted by MalayGPT: ( ME N G E L U H ) s untuk hal yang akan menyak it iku .\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing Epoch 15: 100%|██████████| 300/300 [00:31<00:00,  9.62it/s, loss=1.267]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------------------------------------------------\n",
            "Source Text: Man, hold the bag, stupid.\n",
            "Target Text: Pegang beg itu, bodoh.\n",
            "Predicted by MalayGPT: En . Ye ag er , saya James Sa v o y .\n",
            "-------------------------------------------------------\n",
            "Source Text: I drive the squirrel!\n",
            "Target Text: Aku mengendarai tupai.\n",
            "Predicted by MalayGPT: S ana !\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing Epoch 16: 100%|██████████| 300/300 [00:31<00:00,  9.64it/s, loss=1.237]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------------------------------------------------\n",
            "Source Text: Man, hold the bag, stupid.\n",
            "Target Text: Pegang beg itu, bodoh.\n",
            "Predicted by MalayGPT: G a ben or , Rick , sesiapa yang memerlukan bal di Kencing mereka dik osong kan dan anda .\n",
            "-------------------------------------------------------\n",
            "Source Text: Case Sens\n",
            "Target Text: Sensi Kata\n",
            "Predicted by MalayGPT: C as s .\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing Epoch 17: 100%|██████████| 300/300 [00:31<00:00,  9.63it/s, loss=1.211]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------------------------------------------------\n",
            "Source Text: Some kid gave to me.\n",
            "Target Text: Ada budak berikannya pada saya.\n",
            "Predicted by MalayGPT: Awak selamat sekarang .\n",
            "-------------------------------------------------------\n",
            "Source Text: This guy is going to have a lot of surveillance.\n",
            "Target Text: This guy is going to have a lot of surveillance.\n",
            "Predicted by MalayGPT: Orang ini mempunyai pulau dan j et sendiri , he bat sekali .\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing Epoch 18: 100%|██████████| 300/300 [00:31<00:00,  9.63it/s, loss=1.276]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------------------------------------------------\n",
            "Source Text: If it's after school hours, you're just gonna lay there all night until 7:00 a.m., when I'll come and save your life.\n",
            "Target Text: Kalau selepas waktu sekolah kau perlu teruskan sehingga 7:00 pagi. Ketika itu, baru aku datang selamatkan kau.\n",
            "Predicted by MalayGPT: Jika itu tak kau suka i , tapi akan pastikan dan betul .\n",
            "-------------------------------------------------------\n",
            "Source Text: I've never seen John Stockton smile so much.\n",
            "Target Text: Aku tak pernah Lihat John Stockton segembira sebegini.\n",
            "Predicted by MalayGPT: Aku tak pernah melihat v am pir baru berada p tasi sungguh cepat\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing Epoch 19: 100%|██████████| 300/300 [00:31<00:00,  9.68it/s, loss=1.224]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------------------------------------------------\n",
            "Source Text: Small\n",
            "Target Text: Kecil\n",
            "Predicted by MalayGPT: S ir\n",
            "-------------------------------------------------------\n",
            "Source Text: He gives victory to whom He wills, and He is the Exalted in Might, the Merciful.\n",
            "Target Text: Ia memberi kemenangan kepada sesiapa yang dikehendakiNya, dan Dia lah jua yang Maha Kuasa, lagi Maha Mengasihani.\n",
            "Predicted by MalayGPT: Dia pernah member inya , tapi saya tidak menerimanya ..\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing Epoch 20: 100%|██████████| 300/300 [00:31<00:00,  9.61it/s, loss=1.202]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------------------------------------------------\n",
            "Source Text: But the past few days.. ...we've been doing rounds of the visa and passport office.\n",
            "Target Text: Tapi sejak beberapa hari... ..kami sibuk mengurus visa dan passport.\n",
            "Predicted by MalayGPT: Tapi saya dengar ada beberapa kedai yang masih terima selepas tamat tem p oh .\n",
            "-------------------------------------------------------\n",
            "Source Text: Some kid gave to me.\n",
            "Target Text: Ada budak berikannya pada saya.\n",
            "Predicted by MalayGPT: Budak p anda i .\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing Epoch 21: 100%|██████████| 300/300 [00:30<00:00,  9.69it/s, loss=1.317]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------------------------------------------------\n",
            "Source Text: Who are you? I am Genus.\n",
            "Target Text: Baiklah.\n",
            "Predicted by MalayGPT: Siapakah kamu sar apan .\n",
            "-------------------------------------------------------\n",
            "Source Text: But the past few days.. ...we've been doing rounds of the visa and passport office.\n",
            "Target Text: Tapi sejak beberapa hari... ..kami sibuk mengurus visa dan passport.\n",
            "Predicted by MalayGPT: Tapi cuma ada satu au to dok .\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing Epoch 22: 100%|██████████| 300/300 [00:31<00:00,  9.66it/s, loss=1.195]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------------------------------------------------\n",
            "Source Text: He's gone, Barry.\n",
            "Target Text: Dia sudah pergi, Barry.\n",
            "Predicted by MalayGPT: Beliau telah .\n",
            "-------------------------------------------------------\n",
            "Source Text: You're pulling my leg, aren't you?\n",
            "Target Text: Kau nak menentang aku?\n",
            "Predicted by MalayGPT: Kau tak tahu apa yang kau hada p i .\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing Epoch 23: 100%|██████████| 300/300 [00:31<00:00,  9.59it/s, loss=1.201]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------------------------------------------------\n",
            "Source Text: The special names @DEFAULT_SINK@, @DEFAULT_SOURCE@ and @DEFAULT_MONITOR@ can be used to specify the default sink, source and monitor.\n",
            "Target Text: Nama khas @DEFAULT_SINK@, @DEFAULT_SOURCE@ and @DEFAULT_MONITOR@ boleh digunakan untuk nyatakan sinki, sumber dan monitor lalai.\n",
            "Predicted by MalayGPT: Di sini kom an der ( Be c ker ) ber bi cara\n",
            "-------------------------------------------------------\n",
            "Source Text: - This isn't the moon!\n",
            "Target Text: - Kita tak tinggal di Bulan!\n",
            "Predicted by MalayGPT: - Ini dapat membuat perasa anmu !\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing Epoch 24: 100%|██████████| 300/300 [00:31<00:00,  9.63it/s, loss=1.209]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------------------------------------------------\n",
            "Source Text: Take their statement.\n",
            "Target Text: Ambil kenyataan mereka.\n",
            "Predicted by MalayGPT: Mem perlahan kan denyutan jantung sehingga se denyutan per - minit .\n",
            "-------------------------------------------------------\n",
            "Source Text: WOMAN: There's a mix-up with my reservation.\n",
            "Target Text: Ada kesilapan dalam tempahan saya.\n",
            "Predicted by MalayGPT: L eka s , cepat lakukan , Bar b .\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing Epoch 25: 100%|██████████| 300/300 [00:30<00:00,  9.68it/s, loss=1.259]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------------------------------------------------\n",
            "Source Text: Some kid gave to me.\n",
            "Target Text: Ada budak berikannya pada saya.\n",
            "Predicted by MalayGPT: Bukan per iba di\n",
            "-------------------------------------------------------\n",
            "Source Text: WOMAN: There's a mix-up with my reservation.\n",
            "Target Text: Ada kesilapan dalam tempahan saya.\n",
            "Predicted by MalayGPT: G aya bing ka i sudah mempunyai butang untuk f ung si % s keadaan % s keadaan\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing Epoch 26: 100%|██████████| 300/300 [00:31<00:00,  9.66it/s, loss=1.203]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------------------------------------------------\n",
            "Source Text: What do you mean?\n",
            "Target Text: Apa maksud kamu?\n",
            "Predicted by MalayGPT: Apa yang kamu semua lakukan ?\n",
            "-------------------------------------------------------\n",
            "Source Text: The black queen.\n",
            "Target Text: Ratu hitam.\n",
            "Predicted by MalayGPT: Mak hluk an eh membawa\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing Epoch 27: 100%|██████████| 300/300 [00:31<00:00,  9.65it/s, loss=1.193]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------------------------------------------------\n",
            "Source Text: \"So we went to my room, and guess what he showed me?\"\n",
            "Target Text: \"Jadi kami pergi ke bilik saya, dan teka apa yang dia tunjukkan kepada saya?\"\n",
            "Predicted by MalayGPT: Dan apa jua perintah yang dibawa oleh Ras u lu l lah ( s . a . w ) kepada kamu maka ter im alah serta amal kan , dan apa jua yang di larang Nya kamu melakukannya maka patuh ilah lar angan Nya .\n",
            "-------------------------------------------------------\n",
            "Source Text: Case Sens\n",
            "Target Text: Sensi Kata\n",
            "Predicted by MalayGPT: K al en dar\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing Epoch 28: 100%|██████████| 300/300 [00:31<00:00,  9.66it/s, loss=1.219]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------------------------------------------------\n",
            "Source Text: Some kid gave to me.\n",
            "Target Text: Ada budak berikannya pada saya.\n",
            "Predicted by MalayGPT: Entah bagaimana saya tidak merasa selamat seperti sebelum ini .\n",
            "-------------------------------------------------------\n",
            "Source Text: Who are you? I am Genus.\n",
            "Target Text: Baiklah.\n",
            "Predicted by MalayGPT: Siapakah kamu tahu bahawa aku ni ?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing Epoch 29: 100%|██████████| 300/300 [00:31<00:00,  9.61it/s, loss=1.253]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------------------------------------------------\n",
            "Source Text: I'll tell you like I tell them...\n",
            "Target Text: Saya akan beritahu kamu seperti saya beritahu yg lain.\n",
            "Predicted by MalayGPT: Saya m amal ia akan te saya ...\n",
            "-------------------------------------------------------\n",
            "Source Text: Too bad I'm not younger, or I'd lend you a hand.\n",
            "Target Text: Aku tak akan menolong kamu\n",
            "Predicted by MalayGPT: Aku tak tahu macam mana tang g apan kau , tapi ban d yang aku ken da li kan untuk J V C , pem a in d rum aku tak se su ai .\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing Epoch 30: 100%|██████████| 300/300 [00:31<00:00,  9.66it/s, loss=1.211]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------------------------------------------------\n",
            "Source Text: Then stop right now!\n",
            "Target Text: Dah, berhenti...\n",
            "Predicted by MalayGPT: Sekarang dia kembali ke P agar Tiga !\n",
            "-------------------------------------------------------\n",
            "Source Text: The crowds are very enthusiastic about this contest.\n",
            "Target Text: Penonton sekali teruja dengan pertandingan ini.\n",
            "Predicted by MalayGPT: Jadi bawa turun ping gan m ang ku k dan mula mem bas uh .\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing Epoch 31: 100%|██████████| 300/300 [00:31<00:00,  9.67it/s, loss=1.260]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------------------------------------------------\n",
            "Source Text: Mr Raj, folks I like can call me Chutki\n",
            "Target Text: Raj, orang yang saya suka boleh panggil saya Chutki\n",
            "Predicted by MalayGPT: En . Ye ag er , saya James Sa v o y .\n",
            "-------------------------------------------------------\n",
            "Source Text: What do you mean?\n",
            "Target Text: Apa maksud kamu?\n",
            "Predicted by MalayGPT: Apa pandangan kamu ?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing Epoch 32: 100%|██████████| 300/300 [00:31<00:00,  9.67it/s, loss=1.190]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------------------------------------------------\n",
            "Source Text: Gopi, listen to me!\n",
            "Target Text: GoPi, dengarkan aku!\n",
            "Predicted by MalayGPT: Pergi , pergi ke saya !\n",
            "-------------------------------------------------------\n",
            "Source Text: Picked up a tail.\n",
            "Target Text: Mengambil ekor.\n",
            "Predicted by MalayGPT: R upa - rupanya be g ini .\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing Epoch 33: 100%|██████████| 300/300 [00:31<00:00,  9.66it/s, loss=1.193]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------------------------------------------------\n",
            "Source Text: The black queen.\n",
            "Target Text: Ratu hitam.\n",
            "Predicted by MalayGPT: The F o ur Se as ons of n d .\n",
            "-------------------------------------------------------\n",
            "Source Text: Password _type:\n",
            "Target Text: _Katalaluan:\n",
            "Predicted by MalayGPT: P indah atau salin fail yang dipilih oleh arahan P ot ong Fail atau Salin Fail sebelum ini\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing Epoch 34: 100%|██████████| 300/300 [00:31<00:00,  9.66it/s, loss=1.227]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------------------------------------------------\n",
            "Source Text: WOMAN: There's a mix-up with my reservation.\n",
            "Target Text: Ada kesilapan dalam tempahan saya.\n",
            "Predicted by MalayGPT: ( ME N G E L U H )\n",
            "-------------------------------------------------------\n",
            "Source Text: I didn't say anything, but I can talk to him if you want.\n",
            "Target Text: Saya tak ada cakap apa-apa. Tapi saya boleh cakap dengan dia kalau kamu mahu.\n",
            "Predicted by MalayGPT: Saya tak tanya apa yang awak cakap , .. tapi awak tidak di rumah kamu .\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing Epoch 35: 100%|██████████| 300/300 [00:30<00:00,  9.68it/s, loss=1.208]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------------------------------------------------\n",
            "Source Text: There are leafs in the way.\n",
            "Target Text: Ada reranting dan daun.\n",
            "Predicted by MalayGPT: S au dara selam anya !\n",
            "-------------------------------------------------------\n",
            "Source Text: You don't have to write anything down to be a poet.\n",
            "Target Text: [Arthur] Anda dont mempunyai untuk menulis sesuatu bawah menjadi seorang penyair.\n",
            "Predicted by MalayGPT: Anda tidak boleh meletakkan ia dalam minuman .\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing Epoch 36: 100%|██████████| 300/300 [00:30<00:00,  9.68it/s, loss=1.217]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------------------------------------------------\n",
            "Source Text: I've never seen John Stockton smile so much.\n",
            "Target Text: Aku tak pernah Lihat John Stockton segembira sebegini.\n",
            "Predicted by MalayGPT: Aku tak pernah melihat v am pir baru berada p tasi sungguh cepat\n",
            "-------------------------------------------------------\n",
            "Source Text: I'll tell you like I tell them...\n",
            "Target Text: Saya akan beritahu kamu seperti saya beritahu yg lain.\n",
            "Predicted by MalayGPT: Saya beritahu pesan an itu , \" saya cin takan awak .\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing Epoch 37: 100%|██████████| 300/300 [00:31<00:00,  9.62it/s, loss=1.221]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------------------------------------------------\n",
            "Source Text: I didn't say anything, but I can talk to him if you want.\n",
            "Target Text: Saya tak ada cakap apa-apa. Tapi saya boleh cakap dengan dia kalau kamu mahu.\n",
            "Predicted by MalayGPT: Saya tak tahu , tapi awak tahu , saya akan cari tahu esok .. saya akan men el efon nya .\n",
            "-------------------------------------------------------\n",
            "Source Text: I've never seen John Stockton smile so much.\n",
            "Target Text: Aku tak pernah Lihat John Stockton segembira sebegini.\n",
            "Predicted by MalayGPT: Aku pernah melihat v am pir baru berada p tasi sungguh cepat\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing Epoch 38: 100%|██████████| 300/300 [00:31<00:00,  9.65it/s, loss=1.200]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------------------------------------------------\n",
            "Source Text: -Hey, Angela.\n",
            "Target Text: - Hei, Angela.\n",
            "Predicted by MalayGPT: - Hey , lebih baik .\n",
            "-------------------------------------------------------\n",
            "Source Text: Some kid gave to me.\n",
            "Target Text: Ada budak berikannya pada saya.\n",
            "Predicted by MalayGPT: Entah bagaimana saya tidak merasa selamat seperti sebelum ini untuk bersama .\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing Epoch 39: 100%|██████████| 300/300 [00:31<00:00,  9.63it/s, loss=1.194]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------------------------------------------------\n",
            "Source Text: - This isn't the moon!\n",
            "Target Text: - Kita tak tinggal di Bulan!\n",
            "Predicted by MalayGPT: - Ini satu arahan !\n",
            "-------------------------------------------------------\n",
            "Source Text: Case Sens\n",
            "Target Text: Sensi Kata\n",
            "Predicted by MalayGPT: C a se y .\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing Epoch 40: 100%|██████████| 300/300 [00:31<00:00,  9.67it/s, loss=1.242]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------------------------------------------------\n",
            "Source Text: Animatable\n",
            "Target Text: Animatable\n",
            "Predicted by MalayGPT: A ni mas i\n",
            "-------------------------------------------------------\n",
            "Source Text: How is Young Do doing?\n",
            "Target Text: Yeong Do. okeykah?\n",
            "Predicted by MalayGPT: Adakah anda benar - benar mahu pada mkan .\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing Epoch 41: 100%|██████████| 300/300 [00:31<00:00,  9.67it/s, loss=1.210]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------------------------------------------------\n",
            "Source Text: He gives victory to whom He wills, and He is the Exalted in Might, the Merciful.\n",
            "Target Text: Ia memberi kemenangan kepada sesiapa yang dikehendakiNya, dan Dia lah jua yang Maha Kuasa, lagi Maha Mengasihani.\n",
            "Predicted by MalayGPT: Dia curi h alam an upacara ter larang itu .\n",
            "-------------------------------------------------------\n",
            "Source Text: He's gone, Barry.\n",
            "Target Text: Dia sudah pergi, Barry.\n",
            "Predicted by MalayGPT: Dia curi h alam an .\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing Epoch 42: 100%|██████████| 300/300 [00:31<00:00,  9.62it/s, loss=1.163]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------------------------------------------------\n",
            "Source Text: Some kid gave to me.\n",
            "Target Text: Ada budak berikannya pada saya.\n",
            "Predicted by MalayGPT: Awak ambil risiko ini ... ketika awak mula tidur dengan orang lain .\n",
            "-------------------------------------------------------\n",
            "Source Text: I'll tell aunt that you went to Masakei with colleague last week.\n",
            "Target Text: Aku akan memberitahu bibi bahawa anda pergi ke Masakei dengan rakan minggu lalu.\n",
            "Predicted by MalayGPT: Aku dah sedia untuk kembali ber kerja .\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing Epoch 43: 100%|██████████| 300/300 [00:31<00:00,  9.64it/s, loss=1.185]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------------------------------------------------\n",
            "Source Text: Good news, Caroline.\n",
            "Target Text: Berita baik, Caroline.\n",
            "Predicted by MalayGPT: S um p ah , C 1 , 2 un di ...\n",
            "-------------------------------------------------------\n",
            "Source Text: Too bad I'm not younger, or I'd lend you a hand.\n",
            "Target Text: Aku tak akan menolong kamu\n",
            "Predicted by MalayGPT: Aku tak tahu macam mana tang g apan kau , tapi ban d yang aku ken da li kan untuk J V C , pem a in d rum aku tak se su ai .\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing Epoch 44: 100%|██████████| 300/300 [00:31<00:00,  9.59it/s, loss=1.209]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------------------------------------------------\n",
            "Source Text: I'll tell you like I tell them...\n",
            "Target Text: Saya akan beritahu kamu seperti saya beritahu yg lain.\n",
            "Predicted by MalayGPT: Saya beritahu pesan an itu , \" saya cin takan awak .\"\n",
            "-------------------------------------------------------\n",
            "Source Text: Picked up a tail.\n",
            "Target Text: Mengambil ekor.\n",
            "Predicted by MalayGPT: Di sini kom an der ( Be c ker ) ber bi cara\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing Epoch 45: 100%|██████████| 300/300 [00:31<00:00,  9.60it/s, loss=1.248]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------------------------------------------------\n",
            "Source Text: I drive the squirrel!\n",
            "Target Text: Aku mengendarai tupai.\n",
            "Predicted by MalayGPT: S um p ah !\n",
            "-------------------------------------------------------\n",
            "Source Text: I'll tell you like I tell them...\n",
            "Target Text: Saya akan beritahu kamu seperti saya beritahu yg lain.\n",
            "Predicted by MalayGPT: Saya beritahu pesan an itu , \" saya cin takan awak .\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing Epoch 46: 100%|██████████| 300/300 [00:31<00:00,  9.59it/s, loss=1.209]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------------------------------------------------\n",
            "Source Text: The special names @DEFAULT_SINK@, @DEFAULT_SOURCE@ and @DEFAULT_MONITOR@ can be used to specify the default sink, source and monitor.\n",
            "Target Text: Nama khas @DEFAULT_SINK@, @DEFAULT_SOURCE@ and @DEFAULT_MONITOR@ boleh digunakan untuk nyatakan sinki, sumber dan monitor lalai.\n",
            "Predicted by MalayGPT: W ish \" Be bo la D ag ing P is s ing \" lebih berjaya !\n",
            "-------------------------------------------------------\n",
            "Source Text: Then stop right now!\n",
            "Target Text: Dah, berhenti...\n",
            "Predicted by MalayGPT: Sekarang !\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing Epoch 47: 100%|██████████| 300/300 [00:31<00:00,  9.61it/s, loss=1.163]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------------------------------------------------\n",
            "Source Text: There are leafs in the way.\n",
            "Target Text: Ada reranting dan daun.\n",
            "Predicted by MalayGPT: Tidak ada pak saan dalam ugama .\n",
            "-------------------------------------------------------\n",
            "Source Text: He gives victory to whom He wills, and He is the Exalted in Might, the Merciful.\n",
            "Target Text: Ia memberi kemenangan kepada sesiapa yang dikehendakiNya, dan Dia lah jua yang Maha Kuasa, lagi Maha Mengasihani.\n",
            "Predicted by MalayGPT: Ia mempunyai S an ta , s ku ter di curi dan gu dang ter beng kal ai .\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing Epoch 48: 100%|██████████| 300/300 [00:31<00:00,  9.65it/s, loss=1.171]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------------------------------------------------\n",
            "Source Text: This guy is going to have a lot of surveillance.\n",
            "Target Text: This guy is going to have a lot of surveillance.\n",
            "Predicted by MalayGPT: Orang - orang ini harus mati .\n",
            "-------------------------------------------------------\n",
            "Source Text: -Hey, Angela.\n",
            "Target Text: - Hei, Angela.\n",
            "Predicted by MalayGPT: Hei , perik sa jalan ini .\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing Epoch 49: 100%|██████████| 300/300 [00:31<00:00,  9.51it/s, loss=1.163]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------------------------------------------------\n",
            "Source Text: How is Young Do doing?\n",
            "Target Text: Yeong Do. okeykah?\n",
            "Predicted by MalayGPT: Awak kenal dia atau cuma ?\n",
            "-------------------------------------------------------\n",
            "Source Text: I'll tell you like I tell them...\n",
            "Target Text: Saya akan beritahu kamu seperti saya beritahu yg lain.\n",
            "Predicted by MalayGPT: Saya beritahu pesan an itu , \" saya cin takan awak .\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing Epoch 50: 100%|██████████| 300/300 [00:31<00:00,  9.65it/s, loss=1.191]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------------------------------------------------\n",
            "Source Text: Too bad I'm not younger, or I'd lend you a hand.\n",
            "Target Text: Aku tak akan menolong kamu\n",
            "Predicted by MalayGPT: Aku tak tahu macam mana tang g apan kau , tapi ban d yang aku ken da li kan untuk J V C , pem a in d rum aku tak se su ai .\n",
            "-------------------------------------------------------\n",
            "Source Text: Take their statement.\n",
            "Target Text: Ambil kenyataan mereka.\n",
            "Predicted by MalayGPT: Ma gu ir e .\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing Epoch 51: 100%|██████████| 300/300 [00:31<00:00,  9.62it/s, loss=1.165]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------------------------------------------------\n",
            "Source Text: Come on!\n",
            "Target Text: Ayuh!\n",
            "Predicted by MalayGPT: Ayuh !\n",
            "-------------------------------------------------------\n",
            "Source Text: The black queen.\n",
            "Target Text: Ratu hitam.\n",
            "Predicted by MalayGPT: Mak hluk an eh membawa T angan Putih .\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing Epoch 52: 100%|██████████| 300/300 [00:31<00:00,  9.62it/s, loss=1.161]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------------------------------------------------\n",
            "Source Text: But the past few days.. ...we've been doing rounds of the visa and passport office.\n",
            "Target Text: Tapi sejak beberapa hari... ..kami sibuk mengurus visa dan passport.\n",
            "Predicted by MalayGPT: Tapi cuma ada satu au to dok .\n",
            "-------------------------------------------------------\n",
            "Source Text: Gopi, listen to me!\n",
            "Target Text: GoPi, dengarkan aku!\n",
            "Predicted by MalayGPT: D en yutan jantung se mak in perlahan Pergi kepada me dik dengan Segera .\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing Epoch 53: 100%|██████████| 300/300 [00:31<00:00,  9.67it/s, loss=1.205]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------------------------------------------------\n",
            "Source Text: KID ZONE\n",
            "Target Text: ZON KANAK-KANAK\n",
            "Predicted by MalayGPT: S E M U A Ro ar\n",
            "-------------------------------------------------------\n",
            "Source Text: Too bad I'm not younger, or I'd lend you a hand.\n",
            "Target Text: Aku tak akan menolong kamu\n",
            "Predicted by MalayGPT: Aku tak tahu macam mana tang g apan kau , tapi ban d yang aku ken da li kan untuk J V C , pem a in d rum aku tak se su ai .\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing Epoch 54: 100%|██████████| 300/300 [00:31<00:00,  9.67it/s, loss=1.166]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------------------------------------------------\n",
            "Source Text: Take their statement.\n",
            "Target Text: Ambil kenyataan mereka.\n",
            "Predicted by MalayGPT: Encik P ick les , saya rasa sudah cukup untuk hari ini , bos .\n",
            "-------------------------------------------------------\n",
            "Source Text: The crowds are very enthusiastic about this contest.\n",
            "Target Text: Penonton sekali teruja dengan pertandingan ini.\n",
            "Predicted by MalayGPT: Orang - orang ini harus mati .\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing Epoch 55: 100%|██████████| 300/300 [00:31<00:00,  9.64it/s, loss=1.176]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------------------------------------------------\n",
            "Source Text: Your condolences are appreciated but your help is unnecessary unless you can name the Americans responsible.\n",
            "Target Text: Takziah kamu dihargai tetapi bantuan kamu tidak perlu melainkan kamu boleh menamakan rakyat Amerika yang bertanggungjawab.\n",
            "Predicted by MalayGPT: Hanya s anya orang - orang yang meny ahu t seru anmu itu ialah mereka yang mendengar ( yang mahu menurut kebenaran ); sedang orang - orang yang mati Allah bangkit kan mereka semula ( pada hari kiamat kel ak ), kemudian mereka dikembalikan kepadaNya untuk menerima balasan .\n",
            "-------------------------------------------------------\n",
            "Source Text: - But I think you already know that.\n",
            "Target Text: - Tapi, tentu awak sudah tahu.\n",
            "Predicted by MalayGPT: - Tapi awak perlukan bantuan .\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing Epoch 56: 100%|██████████| 300/300 [00:31<00:00,  9.63it/s, loss=1.166]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------------------------------------------------\n",
            "Source Text: WOMAN: There's a mix-up with my reservation.\n",
            "Target Text: Ada kesilapan dalam tempahan saya.\n",
            "Predicted by MalayGPT: W ah ... yang ber nasib baik ..\n",
            "-------------------------------------------------------\n",
            "Source Text: The special names @DEFAULT_SINK@, @DEFAULT_SOURCE@ and @DEFAULT_MONITOR@ can be used to specify the default sink, source and monitor.\n",
            "Target Text: Nama khas @DEFAULT_SINK@, @DEFAULT_SOURCE@ and @DEFAULT_MONITOR@ boleh digunakan untuk nyatakan sinki, sumber dan monitor lalai.\n",
            "Predicted by MalayGPT: or ton , H Jeff re e 8 7 4 27 39 9 3 p ra ju rit .\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing Epoch 57: 100%|██████████| 300/300 [00:30<00:00,  9.69it/s, loss=1.165]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------------------------------------------------\n",
            "Source Text: If it's after school hours, you're just gonna lay there all night until 7:00 a.m., when I'll come and save your life.\n",
            "Target Text: Kalau selepas waktu sekolah kau perlu teruskan sehingga 7:00 pagi. Ketika itu, baru aku datang selamatkan kau.\n",
            "Predicted by MalayGPT: Jika itu tak kau suka i , berdo alah\n",
            "-------------------------------------------------------\n",
            "Source Text: I didn't say anything, but I can talk to him if you want.\n",
            "Target Text: Saya tak ada cakap apa-apa. Tapi saya boleh cakap dengan dia kalau kamu mahu.\n",
            "Predicted by MalayGPT: Saya tak tahu , tapi awak tahu , saya akan cari tahu esok .. saya akan men el efon nya .\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing Epoch 58: 100%|██████████| 300/300 [00:31<00:00,  9.59it/s, loss=1.176]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------------------------------------------------\n",
            "Source Text: If it's after school hours, you're just gonna lay there all night until 7:00 a.m., when I'll come and save your life.\n",
            "Target Text: Kalau selepas waktu sekolah kau perlu teruskan sehingga 7:00 pagi. Ketika itu, baru aku datang selamatkan kau.\n",
            "Predicted by MalayGPT: Jika itu tak kau suka i , berdo alah\n",
            "-------------------------------------------------------\n",
            "Source Text: I've never seen John Stockton smile so much.\n",
            "Target Text: Aku tak pernah Lihat John Stockton segembira sebegini.\n",
            "Predicted by MalayGPT: Aku tak pernah melihat v am pir baru berada p tasi sungguh cepat\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing Epoch 59: 100%|██████████| 300/300 [00:31<00:00,  9.61it/s, loss=1.183]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------------------------------------------------\n",
            "Source Text: Then stop right now!\n",
            "Target Text: Dah, berhenti...\n",
            "Predicted by MalayGPT: Lakukan sekarang !\n",
            "-------------------------------------------------------\n",
            "Source Text: & View\n",
            "Target Text: & Lihat\n",
            "Predicted by MalayGPT: & Ok\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing Epoch 60: 100%|██████████| 300/300 [00:31<00:00,  9.64it/s, loss=1.181]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------------------------------------------------\n",
            "Source Text: -Hey, Angela.\n",
            "Target Text: - Hei, Angela.\n",
            "Predicted by MalayGPT: - Hey , dan lebih dulu .\n",
            "-------------------------------------------------------\n",
            "Source Text: WOMAN: There's a mix-up with my reservation.\n",
            "Target Text: Ada kesilapan dalam tempahan saya.\n",
            "Predicted by MalayGPT: RO ME : budak anda .\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing Epoch 61: 100%|██████████| 300/300 [00:31<00:00,  9.48it/s, loss=1.168]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------------------------------------------------\n",
            "Source Text: I've never seen John Stockton smile so much.\n",
            "Target Text: Aku tak pernah Lihat John Stockton segembira sebegini.\n",
            "Predicted by MalayGPT: Aku tak pernah melihat v am pir baru berada p tasi sungguh cepat\n",
            "-------------------------------------------------------\n",
            "Source Text: cannot create DHCP BPF socket: %s\n",
            "Target Text: tidak dapat cipta soket DHCP BPF: %s\n",
            "Predicted by MalayGPT: % s telah mem bat alkan tugas .\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing Epoch 62: 100%|██████████| 300/300 [00:30<00:00,  9.68it/s, loss=1.196]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------------------------------------------------\n",
            "Source Text: I didn't say anything, but I can talk to him if you want.\n",
            "Target Text: Saya tak ada cakap apa-apa. Tapi saya boleh cakap dengan dia kalau kamu mahu.\n",
            "Predicted by MalayGPT: Saya tak tahu , tapi awak tahu , saya akan cari tahu esok .. saya akan men el efon nya .\n",
            "-------------------------------------------------------\n",
            "Source Text: Too bad I'm not younger, or I'd lend you a hand.\n",
            "Target Text: Aku tak akan menolong kamu\n",
            "Predicted by MalayGPT: Aku tak tahu macam mana tang g apan kau , tapi ban d yang aku ken da li kan untuk J V C , pem a in d rum aku tak se su ai .\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing Epoch 63: 100%|██████████| 300/300 [00:31<00:00,  9.67it/s, loss=1.157]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------------------------------------------------\n",
            "Source Text: I'll tell aunt that you went to Masakei with colleague last week.\n",
            "Target Text: Aku akan memberitahu bibi bahawa anda pergi ke Masakei dengan rakan minggu lalu.\n",
            "Predicted by MalayGPT: Aku dah sedia untuk kembali ber kerja di V er dan tidak yang menikam kedu anya .\n",
            "-------------------------------------------------------\n",
            "Source Text: I didn't say anything, but I can talk to him if you want.\n",
            "Target Text: Saya tak ada cakap apa-apa. Tapi saya boleh cakap dengan dia kalau kamu mahu.\n",
            "Predicted by MalayGPT: saya tak tahu , apa yang awak cakap .\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing Epoch 64: 100%|██████████| 300/300 [00:31<00:00,  9.65it/s, loss=1.172]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------------------------------------------------\n",
            "Source Text: Animatable\n",
            "Target Text: Animatable\n",
            "Predicted by MalayGPT: A ni mas i\n",
            "-------------------------------------------------------\n",
            "Source Text: I didn't say anything, but I can talk to him if you want.\n",
            "Target Text: Saya tak ada cakap apa-apa. Tapi saya boleh cakap dengan dia kalau kamu mahu.\n",
            "Predicted by MalayGPT: saya tak tahu , tapi awak tahu , saya akan cari tahu esok .. saya akan men el efon nya .\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing Epoch 65: 100%|██████████| 300/300 [00:31<00:00,  9.67it/s, loss=1.153]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------------------------------------------------\n",
            "Source Text: Gopi, listen to me!\n",
            "Target Text: GoPi, dengarkan aku!\n",
            "Predicted by MalayGPT: G e org e , kalau kau boleh .\n",
            "-------------------------------------------------------\n",
            "Source Text: Take their statement.\n",
            "Target Text: Ambil kenyataan mereka.\n",
            "Predicted by MalayGPT: Kamu memiliki 39 yen .\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing Epoch 66: 100%|██████████| 300/300 [00:31<00:00,  9.67it/s, loss=1.162]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------------------------------------------------\n",
            "Source Text: The special names @DEFAULT_SINK@, @DEFAULT_SOURCE@ and @DEFAULT_MONITOR@ can be used to specify the default sink, source and monitor.\n",
            "Target Text: Nama khas @DEFAULT_SINK@, @DEFAULT_SOURCE@ and @DEFAULT_MONITOR@ boleh digunakan untuk nyatakan sinki, sumber dan monitor lalai.\n",
            "Predicted by MalayGPT: Jadi men ag apa aku harus melihat gambar orang - orang yang tidak aku kenal ?\n",
            "-------------------------------------------------------\n",
            "Source Text: I didn't say anything, but I can talk to him if you want.\n",
            "Target Text: Saya tak ada cakap apa-apa. Tapi saya boleh cakap dengan dia kalau kamu mahu.\n",
            "Predicted by MalayGPT: Saya tak jika aku beritahu kau sekarang .\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing Epoch 67: 100%|██████████| 300/300 [00:30<00:00,  9.68it/s, loss=1.154]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------------------------------------------------\n",
            "Source Text: Ang Lee is a mentor to me and my family\n",
            "Target Text: Ang Lee adalah mentor saya dan juga keluarga saya\n",
            "Predicted by MalayGPT: Lit erasi pel bagai daripada p rim itif untuk ke dok tor an .\n",
            "-------------------------------------------------------\n",
            "Source Text: - This isn't the moon!\n",
            "Target Text: - Kita tak tinggal di Bulan!\n",
            "Predicted by MalayGPT: - Jangan sentuh itu !\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing Epoch 68: 100%|██████████| 300/300 [00:31<00:00,  9.67it/s, loss=1.160]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------------------------------------------------\n",
            "Source Text: Animatable\n",
            "Target Text: Animatable\n",
            "Predicted by MalayGPT: A ni mas i\n",
            "-------------------------------------------------------\n",
            "Source Text: Your condolences are appreciated but your help is unnecessary unless you can name the Americans responsible.\n",
            "Target Text: Takziah kamu dihargai tetapi bantuan kamu tidak perlu melainkan kamu boleh menamakan rakyat Amerika yang bertanggungjawab.\n",
            "Predicted by MalayGPT: Hanya s anya orang - orang yang meny ahu t seru anmu itu ialah mereka yang mendengar ( yang mahu menurut kebenaran ); sedang orang - orang yang mati Allah bangkit kan mereka semula ( pada hari kiamat kel ak ), kemudian mereka dikembalikan kepadaNya untuk menerima balasan .\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing Epoch 69: 100%|██████████| 300/300 [00:30<00:00,  9.68it/s, loss=1.166]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------------------------------------------------\n",
            "Source Text: #There is a budding flower And I'm mad for her#\n",
            "Target Text: # Terdapat bunga tunas dan saya gila padanya #\n",
            "Predicted by MalayGPT: Se bagai seorang Jen dr al , tidak harus selalu menggunakan m il it er di ban ding tak tik , menggunakan org harus lo ya l .\n",
            "-------------------------------------------------------\n",
            "Source Text: \"So we went to my room, and guess what he showed me?\"\n",
            "Target Text: \"Jadi kami pergi ke bilik saya, dan teka apa yang dia tunjukkan kepada saya?\"\n",
            "Predicted by MalayGPT: Jadi ke selur uhan nya .\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing Epoch 70: 100%|██████████| 300/300 [00:31<00:00,  9.64it/s, loss=1.161]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------------------------------------------------\n",
            "Source Text: WOMAN: There's a mix-up with my reservation.\n",
            "Target Text: Ada kesilapan dalam tempahan saya.\n",
            "Predicted by MalayGPT: G a ben or , Rick , sesiapa yang memerlukan bal di Kencing mereka dik osong kan dan anda datang berjalan .\n",
            "-------------------------------------------------------\n",
            "Source Text: You don't have to write anything down to be a poet.\n",
            "Target Text: [Arthur] Anda dont mempunyai untuk menulis sesuatu bawah menjadi seorang penyair.\n",
            "Predicted by MalayGPT: Anda tidak boleh meletakkan ia dalam minuman .\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing Epoch 71: 100%|██████████| 300/300 [00:31<00:00,  9.68it/s, loss=1.166]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------------------------------------------------\n",
            "Source Text: \"So we went to my room, and guess what he showed me?\"\n",
            "Target Text: \"Jadi kami pergi ke bilik saya, dan teka apa yang dia tunjukkan kepada saya?\"\n",
            "Predicted by MalayGPT: Jadi men ag apa aku harus melihat gambar orang - orang yang tidak aku kenal ?\n",
            "-------------------------------------------------------\n",
            "Source Text: Ang Lee is a mentor to me and my family\n",
            "Target Text: Ang Lee adalah mentor saya dan juga keluarga saya\n",
            "Predicted by MalayGPT: Aku punya perminta an bagi yang men on ton video ini .\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing Epoch 72: 100%|██████████| 300/300 [00:31<00:00,  9.67it/s, loss=1.174]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------------------------------------------------\n",
            "Source Text: I'll tell you like I tell them...\n",
            "Target Text: Saya akan beritahu kamu seperti saya beritahu yg lain.\n",
            "Predicted by MalayGPT: Saya beritahu pesan an itu , \" saya cin takan awak .\"\n",
            "-------------------------------------------------------\n",
            "Source Text: - This isn't the moon!\n",
            "Target Text: - Kita tak tinggal di Bulan!\n",
            "Predicted by MalayGPT: - P om pe i i !\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing Epoch 73: 100%|██████████| 300/300 [00:31<00:00,  9.59it/s, loss=1.176]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------------------------------------------------\n",
            "Source Text: I've never seen John Stockton smile so much.\n",
            "Target Text: Aku tak pernah Lihat John Stockton segembira sebegini.\n",
            "Predicted by MalayGPT: Tak pernah aku tengok perkara macam ini .\n",
            "-------------------------------------------------------\n",
            "Source Text: Tried something new?\n",
            "Target Text: Mencuba sesuatu yang baru?\n",
            "Predicted by MalayGPT: S ut Gro u p war e\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing Epoch 74: 100%|██████████| 300/300 [00:31<00:00,  9.65it/s, loss=1.157]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------------------------------------------------\n",
            "Source Text: He gives victory to whom He wills, and He is the Exalted in Might, the Merciful.\n",
            "Target Text: Ia memberi kemenangan kepada sesiapa yang dikehendakiNya, dan Dia lah jua yang Maha Kuasa, lagi Maha Mengasihani.\n",
            "Predicted by MalayGPT: Dia pernah member inya , tapi saya tidak menerimanya ..\n",
            "-------------------------------------------------------\n",
            "Source Text: How is Young Do doing?\n",
            "Target Text: Yeong Do. okeykah?\n",
            "Predicted by MalayGPT: Adakah peguam nya membuat apa - apa ?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing Epoch 75: 100%|██████████| 300/300 [00:31<00:00,  9.64it/s, loss=1.178]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------------------------------------------------\n",
            "Source Text: Good news, Caroline.\n",
            "Target Text: Berita baik, Caroline.\n",
            "Predicted by MalayGPT: P in ky , P amma , Bu bb ly , Lo vel y , S we et .\n",
            "-------------------------------------------------------\n",
            "Source Text: I'll kill him, the useless little sewer rat!\n",
            "Target Text: Aku akan bunuh dia!\n",
            "Predicted by MalayGPT: Aku dah sedia untuk kembali ber kerja .\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing Epoch 76: 100%|██████████| 300/300 [00:31<00:00,  9.66it/s, loss=1.162]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------------------------------------------------\n",
            "Source Text: Come on!\n",
            "Target Text: Ayuh!\n",
            "Predicted by MalayGPT: Ayuh !\n",
            "-------------------------------------------------------\n",
            "Source Text: Animatable\n",
            "Target Text: Animatable\n",
            "Predicted by MalayGPT: A ni mas i\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing Epoch 77: 100%|██████████| 300/300 [00:31<00:00,  9.64it/s, loss=1.164]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------------------------------------------------\n",
            "Source Text: Small\n",
            "Target Text: Kecil\n",
            "Predicted by MalayGPT: Peng is ih\n",
            "-------------------------------------------------------\n",
            "Source Text: Take their statement.\n",
            "Target Text: Ambil kenyataan mereka.\n",
            "Predicted by MalayGPT: Orang juga hilang .\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing Epoch 78: 100%|██████████| 300/300 [00:31<00:00,  9.65it/s, loss=1.159]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------------------------------------------------\n",
            "Source Text: I drive the squirrel!\n",
            "Target Text: Aku mengendarai tupai.\n",
            "Predicted by MalayGPT: S um p ah !\n",
            "-------------------------------------------------------\n",
            "Source Text: Gopi, listen to me!\n",
            "Target Text: GoPi, dengarkan aku!\n",
            "Predicted by MalayGPT: G aya bing ka i sudah mempunyai !\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing Epoch 79: 100%|██████████| 300/300 [00:30<00:00,  9.70it/s, loss=1.154]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------------------------------------------------\n",
            "Source Text: Small\n",
            "Target Text: Kecil\n",
            "Predicted by MalayGPT: Peng is ih\n",
            "-------------------------------------------------------\n",
            "Source Text: You're pulling my leg, aren't you?\n",
            "Target Text: Kau nak menentang aku?\n",
            "Predicted by MalayGPT: Kau tak tahu apa yang akan kau hada p i .\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing Epoch 80: 100%|██████████| 300/300 [00:31<00:00,  9.64it/s, loss=1.156]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------------------------------------------------\n",
            "Source Text: I'll tell aunt that you went to Masakei with colleague last week.\n",
            "Target Text: Aku akan memberitahu bibi bahawa anda pergi ke Masakei dengan rakan minggu lalu.\n",
            "Predicted by MalayGPT: Aku tak tahu macam mana tang g apan kau , tapi ban d yang aku ken da li kan untuk J V C , pem a in d rum aku tak se su ai .\n",
            "-------------------------------------------------------\n",
            "Source Text: The crowds are very enthusiastic about this contest.\n",
            "Target Text: Penonton sekali teruja dengan pertandingan ini.\n",
            "Predicted by MalayGPT: Orang - orang ini harus mati .\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing Epoch 81: 100%|██████████| 300/300 [00:30<00:00,  9.69it/s, loss=1.156]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------------------------------------------------\n",
            "Source Text: You're pulling my leg, aren't you?\n",
            "Target Text: Kau nak menentang aku?\n",
            "Predicted by MalayGPT: Kau sedang membaca kemudian j at uh ter tidur .\n",
            "-------------------------------------------------------\n",
            "Source Text: I've never seen John Stockton smile so much.\n",
            "Target Text: Aku tak pernah Lihat John Stockton segembira sebegini.\n",
            "Predicted by MalayGPT: Tak pernah aku tengok perkara macam ini .\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing Epoch 82: 100%|██████████| 300/300 [00:30<00:00,  9.71it/s, loss=1.160]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------------------------------------------------\n",
            "Source Text: So where's it been hiding the last 60 million years?\n",
            "Target Text: Dimana dia bersembunyi selama 60 juta tahun terakhir?\n",
            "Predicted by MalayGPT: Jadi ianya ke utara , dalam erti kata lain .\n",
            "-------------------------------------------------------\n",
            "Source Text: I've never seen John Stockton smile so much.\n",
            "Target Text: Aku tak pernah Lihat John Stockton segembira sebegini.\n",
            "Predicted by MalayGPT: Tak pernah aku tengok perkara macam ini .\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing Epoch 83: 100%|██████████| 300/300 [00:31<00:00,  9.59it/s, loss=1.159]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------------------------------------------------\n",
            "Source Text: Chris Ryan instead opts to take a knee.\n",
            "Target Text: Chris Ryan malah melutut.\n",
            "Predicted by MalayGPT: R 4 \" is the ab bre vi ation for \" Re gi s ter 4\n",
            "-------------------------------------------------------\n",
            "Source Text: The special names @DEFAULT_SINK@, @DEFAULT_SOURCE@ and @DEFAULT_MONITOR@ can be used to specify the default sink, source and monitor.\n",
            "Target Text: Nama khas @DEFAULT_SINK@, @DEFAULT_SOURCE@ and @DEFAULT_MONITOR@ boleh digunakan untuk nyatakan sinki, sumber dan monitor lalai.\n",
            "Predicted by MalayGPT: Dengan nama B apa , Anak dan Ro h Ku du s , A min .\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing Epoch 84: 100%|██████████| 300/300 [00:31<00:00,  9.67it/s, loss=1.164]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------------------------------------------------\n",
            "Source Text: cannot create DHCP BPF socket: %s\n",
            "Target Text: tidak dapat cipta soket DHCP BPF: %s\n",
            "Predicted by MalayGPT: % s telah mem bat alkan tugas .\n",
            "-------------------------------------------------------\n",
            "Source Text: If it's after school hours, you're just gonna lay there all night until 7:00 a.m., when I'll come and save your life.\n",
            "Target Text: Kalau selepas waktu sekolah kau perlu teruskan sehingga 7:00 pagi. Ketika itu, baru aku datang selamatkan kau.\n",
            "Predicted by MalayGPT: Jika kita tak melawan hari ini , akan ada lagi gen erasi peng an as , dan para De wa akan melepaskan k eng er ian dengan lama .\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing Epoch 85: 100%|██████████| 300/300 [00:31<00:00,  9.64it/s, loss=1.161]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------------------------------------------------\n",
            "Source Text: Take their statement.\n",
            "Target Text: Ambil kenyataan mereka.\n",
            "Predicted by MalayGPT: Mem perlahan kan denyutan jantung sehingga se denyutan per - minit .\n",
            "-------------------------------------------------------\n",
            "Source Text: - This isn't the moon!\n",
            "Target Text: - Kita tak tinggal di Bulan!\n",
            "Predicted by MalayGPT: - Ini adalah ke empat - empat .\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing Epoch 86: 100%|██████████| 300/300 [00:31<00:00,  9.66it/s, loss=1.157]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------------------------------------------------\n",
            "Source Text: Take their statement.\n",
            "Target Text: Ambil kenyataan mereka.\n",
            "Predicted by MalayGPT: Mem anfaatkan tenaga dari angkasa lepas .\n",
            "-------------------------------------------------------\n",
            "Source Text: cannot create DHCP BPF socket: %s\n",
            "Target Text: tidak dapat cipta soket DHCP BPF: %s\n",
            "Predicted by MalayGPT: dapat cari perintah '% s '\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing Epoch 87: 100%|██████████| 300/300 [00:31<00:00,  9.65it/s, loss=1.169]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------------------------------------------------\n",
            "Source Text: The crowds are very enthusiastic about this contest.\n",
            "Target Text: Penonton sekali teruja dengan pertandingan ini.\n",
            "Predicted by MalayGPT: Yang dis ak sikan oleh se kumpulan mal aik at , yang di dampingkan Tuhan di sis inya .\n",
            "-------------------------------------------------------\n",
            "Source Text: I'll tell aunt that you went to Masakei with colleague last week.\n",
            "Target Text: Aku akan memberitahu bibi bahawa anda pergi ke Masakei dengan rakan minggu lalu.\n",
            "Predicted by MalayGPT: Aku tak tahu macam mana tang g apan kau , tapi ban d yang aku ken da li kan untuk J V C , pem a in d rum aku tak se su ai .\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing Epoch 88: 100%|██████████| 300/300 [00:31<00:00,  9.58it/s, loss=1.146]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------------------------------------------------\n",
            "Source Text: There are leafs in the way.\n",
            "Target Text: Ada reranting dan daun.\n",
            "Predicted by MalayGPT: Ada yang mau beli makanan .\n",
            "-------------------------------------------------------\n",
            "Source Text: Your condolences are appreciated but your help is unnecessary unless you can name the Americans responsible.\n",
            "Target Text: Takziah kamu dihargai tetapi bantuan kamu tidak perlu melainkan kamu boleh menamakan rakyat Amerika yang bertanggungjawab.\n",
            "Predicted by MalayGPT: Hanya s anya orang - orang yang meny ahu t seru anmu itu ialah mereka yang mendengar ( yang mahu menurut kebenaran ); sedang orang - orang yang mati Allah bangkit kan mereka semula ( pada hari kiamat kel ak ), kemudian mereka dikembalikan kepadaNya untuk menerima balasan .\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing Epoch 89: 100%|██████████| 300/300 [00:31<00:00,  9.61it/s, loss=1.163]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------------------------------------------------\n",
            "Source Text: There are leafs in the way.\n",
            "Target Text: Ada reranting dan daun.\n",
            "Predicted by MalayGPT: Ada apa yang bi jak juga .\n",
            "-------------------------------------------------------\n",
            "Source Text: \"So we went to my room, and guess what he showed me?\"\n",
            "Target Text: \"Jadi kami pergi ke bilik saya, dan teka apa yang dia tunjukkan kepada saya?\"\n",
            "Predicted by MalayGPT: Jadi kita akan keluar melalui Ar men ia .\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing Epoch 90:  99%|█████████▊| 296/300 [00:30<00:00,  8.93it/s, loss=1.146]"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Testing"
      ],
      "metadata": {
        "id": "oDjMszf7wcJB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def malaygpt(user_input_text):\n",
        "\n",
        "    # validation using input text\n",
        "    user_input_text = str(user_input_text).strip()\n",
        "\n",
        "    # Let's get the model Define the device, tokenizers, and model\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    tokenizer_en = Tokenizer.from_file(\"./tokenizer_en/tokenizer_en.json\")\n",
        "    tokenizer_my = Tokenizer.from_file(\"./tokenizer_my/tokenizer_my.json\")\n",
        "\n",
        "    # Build our model\n",
        "    # model = build_model(tokenizer_en.get_vocab_size(), tokenizer_my.get_vocab_size(), max_seq_len, max_seq_len, d_model=512).to(device)\n",
        "    # model = get_model(tokenizer_en.get_vocab_size(), tokenizer_my.get_vocab_size()).to(device)\n",
        "    model = build_model(tokenizer_en.get_vocab_size(), tokenizer_my.get_vocab_size(),max_seq_len, max_seq_len, d_model=512).to(device)\n",
        "\n",
        "    # Load the specific checkpoint of the model that you've saved during training.\n",
        "    checkpoint_number = 19    # for this test, I am taking checkpoint number 10\n",
        "    model_filename = f\"./malaygpt/model_{checkpoint_number}.pt\"\n",
        "    state = torch.load(model_filename)\n",
        "    model.load_state_dict(state['model_state_dict'])\n",
        "\n",
        "    # Lets beging the inferencing\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        # Precompute the encoder output and reuse it for every generation step\n",
        "        source_text_encoding = tokenizer_en.encode(user_input_text)\n",
        "        source_text_encoding = torch.cat([\n",
        "            torch.tensor([tokenizer_en.token_to_id('[CLS]')], dtype=torch.int64),\n",
        "            torch.tensor(source_text_encoding.ids, dtype=torch.int64),\n",
        "            torch.tensor([tokenizer_en.token_to_id('[SEP]')], dtype=torch.int64),\n",
        "            torch.tensor([tokenizer_en.token_to_id('[PAD]')] * (max_seq_len - len(source_text_encoding.ids) - 2), dtype=torch.int64)\n",
        "        ], dim=0).to(device)\n",
        "        source_mask = (source_text_encoding != tokenizer_en.token_to_id('[PAD]')).unsqueeze(0).unsqueeze(0).int().to(device)\n",
        "        encoder_output = model.encode(source_text_encoding, source_mask)\n",
        "\n",
        "        # Initialize the decoder input with the sos token\n",
        "        decoder_input = torch.empty(1, 1).fill_(tokenizer_my.token_to_id('[CLS]')).type_as(source_text_encoding).to(device)\n",
        "\n",
        "        # Generate the translation word by word\n",
        "        while decoder_input.size(1) < max_seq_len:\n",
        "            # build mask for target and calculate output\n",
        "            decoder_mask = torch.triu(torch.ones((1, decoder_input.size(1), decoder_input.size(1))), diagonal=1).type(torch.int).type_as(source_mask).to(device)\n",
        "            out = model.decode(encoder_output, source_mask, decoder_input, decoder_mask)\n",
        "\n",
        "            # project next token\n",
        "            prob = model.project(out[:, -1])\n",
        "            _, next_word = torch.max(prob, dim=1)\n",
        "            decoder_input = torch.cat([decoder_input, torch.empty(1, 1).type_as(source_text_encoding).fill_(next_word.item()).to(device)], dim=1)\n",
        "\n",
        "            # print the translated word\n",
        "            # print(f\"{tokenizer_my.decode([next_word.item()])}\", end=' ')\n",
        "\n",
        "            # break if we predict the end of sentence token\n",
        "            if next_word == tokenizer_my.token_to_id('[SEP]'):\n",
        "                break\n",
        "\n",
        "    # convert ids to tokens\n",
        "    return tokenizer_my.decode(decoder_input[0].tolist())"
      ],
      "metadata": {
        "id": "nGV6NnZYwdBy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "user_input_text = \"Good Morning.\"\n",
        "translated_text = malaygpt(user_input_text)\n",
        "\n",
        "print(\"English input:\", user_input_text)\n",
        "print(\"Malay translation:\", translated_text)"
      ],
      "metadata": {
        "id": "IsJc2bebwiHV"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "dbda485d349b4ef592ce5acac3918797": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ce60ac885256423ebf7f2483fda6e144",
              "IPY_MODEL_4d3f70fcb88244c7a05e27269c633d19",
              "IPY_MODEL_bab22e3d52314fb789d2e0e3389ffa86"
            ],
            "layout": "IPY_MODEL_4466f31cd61f4ead8a96825db51128fe"
          }
        },
        "ce60ac885256423ebf7f2483fda6e144": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e335bfeaa278453b827780e96c71506b",
            "placeholder": "​",
            "style": "IPY_MODEL_c1cdbd8267a64a578a78226298943752",
            "value": "README.md: 100%"
          }
        },
        "4d3f70fcb88244c7a05e27269c633d19": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_644fac3530114cd6ae209cdca3f167a3",
            "max": 65391,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_896a23bd9a9b41ad9fe783fd15e61abc",
            "value": 65391
          }
        },
        "bab22e3d52314fb789d2e0e3389ffa86": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c145064e5cc74b88a534da1f94f8a8e3",
            "placeholder": "​",
            "style": "IPY_MODEL_228c5cee5d5d44c18298e7b98195f91b",
            "value": " 65.4k/65.4k [00:00&lt;00:00, 520kB/s]"
          }
        },
        "4466f31cd61f4ead8a96825db51128fe": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e335bfeaa278453b827780e96c71506b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c1cdbd8267a64a578a78226298943752": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "644fac3530114cd6ae209cdca3f167a3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "896a23bd9a9b41ad9fe783fd15e61abc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c145064e5cc74b88a534da1f94f8a8e3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "228c5cee5d5d44c18298e7b98195f91b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "040719411de94d4299ddbdc48c373eaf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6bb91c751e4b45d99234710af65bf428",
              "IPY_MODEL_0e75ef2e55f047f8a2fc72ee55d060f5",
              "IPY_MODEL_0e377399630a4a0f8edae328f3135221"
            ],
            "layout": "IPY_MODEL_52fa29db26ac4b3ba1d57971b5e0eb17"
          }
        },
        "6bb91c751e4b45d99234710af65bf428": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f8e02ce75c02440db9b6cffbd4c39170",
            "placeholder": "​",
            "style": "IPY_MODEL_9167ea1dff6441f98c93eefc1c040343",
            "value": "test-00000-of-00001.parquet: 100%"
          }
        },
        "0e75ef2e55f047f8a2fc72ee55d060f5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_267c7e21fa3e430080449637b7980f03",
            "max": 131945,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1fe90ed4d8d94568a29035991b3c5ef5",
            "value": 131945
          }
        },
        "0e377399630a4a0f8edae328f3135221": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_386459fb15ae4eb685994a9918e55e11",
            "placeholder": "​",
            "style": "IPY_MODEL_6f5a6445be90419eb5e1e2cec2b56fad",
            "value": " 132k/132k [00:00&lt;00:00, 1.07MB/s]"
          }
        },
        "52fa29db26ac4b3ba1d57971b5e0eb17": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f8e02ce75c02440db9b6cffbd4c39170": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9167ea1dff6441f98c93eefc1c040343": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "267c7e21fa3e430080449637b7980f03": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1fe90ed4d8d94568a29035991b3c5ef5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "386459fb15ae4eb685994a9918e55e11": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6f5a6445be90419eb5e1e2cec2b56fad": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7c6d884f7c614aa29b0135786941a536": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f79b61b10e8046cdb6f89441a1e972b7",
              "IPY_MODEL_2e03bc9b56ed46d18b3d386faaa0a79e",
              "IPY_MODEL_3c1dc3078b0148099e6157c3adccb133"
            ],
            "layout": "IPY_MODEL_3800b68e593e47e9963ff98333c4df22"
          }
        },
        "f79b61b10e8046cdb6f89441a1e972b7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c6c95ab49b6b42f4851d8dd3c201ff84",
            "placeholder": "​",
            "style": "IPY_MODEL_db639ec831b94b98bca0fc6a2d9f7d7a",
            "value": "train-00000-of-00001.parquet: 100%"
          }
        },
        "2e03bc9b56ed46d18b3d386faaa0a79e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3529507942f741a8aeb150e73c31bd88",
            "max": 57148882,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_cc9e3ee3a2a1443185321afd0c7305ee",
            "value": 57148882
          }
        },
        "3c1dc3078b0148099e6157c3adccb133": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_971fb421f71a4432828327a79cac7cca",
            "placeholder": "​",
            "style": "IPY_MODEL_404504562a484106bd1cad8defca1aee",
            "value": " 57.1M/57.1M [00:00&lt;00:00, 74.4MB/s]"
          }
        },
        "3800b68e593e47e9963ff98333c4df22": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c6c95ab49b6b42f4851d8dd3c201ff84": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "db639ec831b94b98bca0fc6a2d9f7d7a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3529507942f741a8aeb150e73c31bd88": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cc9e3ee3a2a1443185321afd0c7305ee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "971fb421f71a4432828327a79cac7cca": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "404504562a484106bd1cad8defca1aee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "63b09c880d554b56a7892e2fa232f91a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_65ad3205aff64f99ac7cd6fc79d2c1d2",
              "IPY_MODEL_e0258cfa2c9f4e13aa97354e8bffcd85",
              "IPY_MODEL_12f6039ad39b40a1b571e10eae89f0b3"
            ],
            "layout": "IPY_MODEL_b2091e7e4a814e7f84a4c5dee5dcdb63"
          }
        },
        "65ad3205aff64f99ac7cd6fc79d2c1d2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_75954f766d2145b7bbba15158efc3609",
            "placeholder": "​",
            "style": "IPY_MODEL_65d108ad5f2d4e3fa1328adebda057e7",
            "value": "validation-00000-of-00001.parquet: 100%"
          }
        },
        "e0258cfa2c9f4e13aa97354e8bffcd85": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_53b1b247af674879b5fab9d97f7073d9",
            "max": 132009,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_44b739aafe364c4483910c90b9834b84",
            "value": 132009
          }
        },
        "12f6039ad39b40a1b571e10eae89f0b3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fc500e1254d543fab4010f566b1c43f1",
            "placeholder": "​",
            "style": "IPY_MODEL_fb1df1c03af54136aed93f15ff62b042",
            "value": " 132k/132k [00:00&lt;00:00, 3.04MB/s]"
          }
        },
        "b2091e7e4a814e7f84a4c5dee5dcdb63": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "75954f766d2145b7bbba15158efc3609": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "65d108ad5f2d4e3fa1328adebda057e7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "53b1b247af674879b5fab9d97f7073d9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "44b739aafe364c4483910c90b9834b84": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "fc500e1254d543fab4010f566b1c43f1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fb1df1c03af54136aed93f15ff62b042": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "35667e9f2a004794be9d95fa4043b08f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_141f88a5a6c544bd920e7801d7778874",
              "IPY_MODEL_c635b8d0db554bb3998e53e6be6cfb2d",
              "IPY_MODEL_84c36051a16f4e13a7b77ef32d425eb0"
            ],
            "layout": "IPY_MODEL_ee8b073de78a48c99e66621513e48854"
          }
        },
        "141f88a5a6c544bd920e7801d7778874": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_02e138ad5e0a42f6ae0542afb00d4340",
            "placeholder": "​",
            "style": "IPY_MODEL_3ea5ca70c440469eaecb44a443901b15",
            "value": "Generating test split: 100%"
          }
        },
        "c635b8d0db554bb3998e53e6be6cfb2d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_24b356aefb6646a09666e78955ca267f",
            "max": 2000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b9e42c39237d4ff89ec298e47d01f102",
            "value": 2000
          }
        },
        "84c36051a16f4e13a7b77ef32d425eb0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_60cea90805544275990ccaee40a6cbff",
            "placeholder": "​",
            "style": "IPY_MODEL_544948e742e74d73a57c8a0e7b9b30b3",
            "value": " 2000/2000 [00:00&lt;00:00, 18752.74 examples/s]"
          }
        },
        "ee8b073de78a48c99e66621513e48854": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "02e138ad5e0a42f6ae0542afb00d4340": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3ea5ca70c440469eaecb44a443901b15": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "24b356aefb6646a09666e78955ca267f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b9e42c39237d4ff89ec298e47d01f102": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "60cea90805544275990ccaee40a6cbff": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "544948e742e74d73a57c8a0e7b9b30b3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "791caa307e874acd90952acaf4c3a852": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0ee20e2f562f45329aeb62c2e446dace",
              "IPY_MODEL_7f218d16110541ad8f3e8edbfde5992c",
              "IPY_MODEL_f8c743c9c47a44248787bd83ea4f181c"
            ],
            "layout": "IPY_MODEL_1d3664a845e44aabad810743be4b2d9b"
          }
        },
        "0ee20e2f562f45329aeb62c2e446dace": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_382a3d4e2e0846679c3b9fb2be70eea0",
            "placeholder": "​",
            "style": "IPY_MODEL_fdf1e39e8be0487bade47b2cad9ca1b4",
            "value": "Generating train split: 100%"
          }
        },
        "7f218d16110541ad8f3e8edbfde5992c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_23d903c072a741d1b83c62dc00a71957",
            "max": 1000000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1de48e1fd8224a8c985c852795c315e0",
            "value": 1000000
          }
        },
        "f8c743c9c47a44248787bd83ea4f181c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9e865868bfc549fbb1296935ba3127e0",
            "placeholder": "​",
            "style": "IPY_MODEL_9f1d7be3829949e6a3d44e815b2da6d4",
            "value": " 1000000/1000000 [00:01&lt;00:00, 648753.43 examples/s]"
          }
        },
        "1d3664a845e44aabad810743be4b2d9b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "382a3d4e2e0846679c3b9fb2be70eea0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fdf1e39e8be0487bade47b2cad9ca1b4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "23d903c072a741d1b83c62dc00a71957": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1de48e1fd8224a8c985c852795c315e0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9e865868bfc549fbb1296935ba3127e0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9f1d7be3829949e6a3d44e815b2da6d4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "819e5b07e8ed43ecb7033d7da1c07280": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0c2c570229c24856b3c746b07ffc8982",
              "IPY_MODEL_297540475170458cbcd2ad43c9adbff9",
              "IPY_MODEL_e949b3c43bf14d41a5411a394ae6a4e2"
            ],
            "layout": "IPY_MODEL_613518c0e39342a69dacb8381884260e"
          }
        },
        "0c2c570229c24856b3c746b07ffc8982": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_75828e69a1f24c8f8dc04e00cf332725",
            "placeholder": "​",
            "style": "IPY_MODEL_925e4fa416394183b81d1090c9ea415e",
            "value": "Generating validation split: 100%"
          }
        },
        "297540475170458cbcd2ad43c9adbff9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_265b0db3763f4893a796fd55cba3cab1",
            "max": 2000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f4fa93dedce8485580729383c4e7ee6c",
            "value": 2000
          }
        },
        "e949b3c43bf14d41a5411a394ae6a4e2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9b9f4111ac0347ef80957bb6a936a38a",
            "placeholder": "​",
            "style": "IPY_MODEL_2317ea91697c416e8979435ea71ac3ad",
            "value": " 2000/2000 [00:00&lt;00:00, 41560.89 examples/s]"
          }
        },
        "613518c0e39342a69dacb8381884260e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "75828e69a1f24c8f8dc04e00cf332725": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "925e4fa416394183b81d1090c9ea415e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "265b0db3763f4893a796fd55cba3cab1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f4fa93dedce8485580729383c4e7ee6c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9b9f4111ac0347ef80957bb6a936a38a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2317ea91697c416e8979435ea71ac3ad": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}