{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lWcsyrn6cqe0",
        "outputId": "a922f50b-193b-4957-83d9-f5a082a7fb87"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting datasets\n",
            "  Downloading datasets-3.1.0-py3-none-any.whl.metadata (20 kB)\n",
            "Requirement already satisfied: tokenizers in /usr/local/lib/python3.10/dist-packages (0.20.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.16.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.26.4)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (17.0.0)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.6)\n",
            "Collecting xxhash (from datasets)\n",
            "  Downloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting multiprocess<0.70.17 (from datasets)\n",
            "  Downloading multiprocess-0.70.16-py310-none-any.whl.metadata (7.2 kB)\n",
            "Collecting fsspec<=2024.9.0,>=2023.1.0 (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets)\n",
            "  Downloading fsspec-2024.9.0-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.10.10)\n",
            "Requirement already satisfied: huggingface-hub>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.26.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.4.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.1.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.17.1)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.23.0->datasets) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2024.8.30)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from yarl<2.0,>=1.12.0->aiohttp->datasets) (0.2.0)\n",
            "Downloading datasets-3.1.0-py3-none-any.whl (480 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m480.6/480.6 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fsspec-2024.9.0-py3-none-any.whl (179 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m179.3/179.3 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: xxhash, fsspec, dill, multiprocess, datasets\n",
            "  Attempting uninstall: fsspec\n",
            "    Found existing installation: fsspec 2024.10.0\n",
            "    Uninstalling fsspec-2024.10.0:\n",
            "      Successfully uninstalled fsspec-2024.10.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "gcsfs 2024.10.0 requires fsspec==2024.10.0, but you have fsspec 2024.9.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed datasets-3.1.0 dill-0.3.8 fsspec-2024.9.0 multiprocess-0.70.16 xxhash-3.5.0\n"
          ]
        }
      ],
      "source": [
        "# imports\n",
        "!pip install datasets tokenizers\n",
        "import os\n",
        "import math\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader, random_split\n",
        "from pathlib import Path\n",
        "from datasets import load_dataset\n",
        "from tqdm import tqdm\n",
        "from tokenizers import Tokenizer\n",
        "from tokenizers.models import BPE\n",
        "from tokenizers.trainers import BpeTrainer\n",
        "from tokenizers.pre_tokenizers import Whitespace"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dirs = [\"./malaygpt\", \"./tokenizer_en\", \"./tokenizer_my\"]\n",
        "for dir in dirs:\n",
        "  if os.path.exists(dir):\n",
        "    continue\n",
        "  os.mkdir(dir)"
      ],
      "metadata": {
        "id": "YUFT0-ZXvKtx"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YpgcofHKc1lv",
        "outputId": "d701fdaf-7b67-4336-c42a-ed74e814d1da"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Download Dataset"
      ],
      "metadata": {
        "id": "ccNZOJ8SczVN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# English/Malay pairs from HuggingFace\n",
        "train_dataset = load_dataset(\"Helsinki-NLP/opus-100\", \"en-ms\", split='train')\n",
        "validation_dataset = load_dataset(\"Helsinki-NLP/opus-100\", \"en-ms\", split='validation')\n",
        "\n",
        "# Limit the amount of data for training purposes\n",
        "raw_train_dataset, rt_to_skip = random_split(train_dataset, [1500, len(train_dataset) - 1500])\n",
        "raw_validation_dataset, vt_to_skip = random_split(validation_dataset, [50, len(validation_dataset) - 50])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 368,
          "referenced_widgets": [
            "cee35b3f585645db8e6b46fe9bbacd3f",
            "9844b8c1dd454c34a53fa895276f225e",
            "51b11140569e452b8f5e6a38e0a7e863",
            "8d493b21b92e4d2ba3900f05f5ec5ce0",
            "17888453970a42fc8d02bc1d2f9f5f64",
            "6ef964c9a58645d7b71843ed6727102a",
            "f9d34ec0339045f7896ae968a7160e41",
            "4a722ea8af0e4af99584fa8698a9b104",
            "0c866ab26c574c39ac18022a599c6766",
            "6eb7356b8aac40878592c7fbfbe712f4",
            "46f7600025e74f179649b4ddd8cb6dfa",
            "0aaee2a23f934bc3ac1c1641cc1af1a2",
            "3030da96f177457089fcbf33907b72d0",
            "1a60c2bbde4943c39930dc65f8c1ee1e",
            "924e3fa666784cd1a3793d6d824bf2d5",
            "d819d19737e0408e9482e0f24b6aa6ff",
            "4d693b2c3b094b41acc937f54a7647f3",
            "56dac6dc56ea4a1c8d59a55d0d793979",
            "c1495fb65ed44242b06d4cfa0380ed8a",
            "570c11c5d9d8493d88997b52d833257c",
            "f4a8b717ddb94491868d1c559164e654",
            "b702b9f02bb3468895cdb566876b65b4",
            "e76665d0e9194830b5db2bfb0e583601",
            "62f8e6ce09824fcfbae61b7d827d2e9b",
            "eb46dac62f7147258c09145bd386f24f",
            "e468116b30494062867abc343b75ad41",
            "aecbfb72c6ea482f9563a297cf7fc5ff",
            "b3f21c9eb5214bc6bd977ac56c904583",
            "62ddc4a0c9014109be0181ebd5de37ab",
            "5d2f85f410ad4c45a8d9933d2821cc25",
            "bb3a302c0b304215adb8b46b5554b3cf",
            "25012e940b56494c8859791b79c4f5c7",
            "0e21b65a6a25477798cc9ccb556061d9",
            "21438547c4aa4554aa616e99ada33c7f",
            "f01cb1f3f5da4761aa9f94844db1ecec",
            "20d15494610a47208cf4ddedca775f56",
            "b2ef54daeebe48b08874591594ce8b6a",
            "1cf17fbbb57e4fe0bf0b0349fad9b992",
            "659d4fe6dcdf45d49137a12ef8a4e3e3",
            "252530efc4bb4e3289e57c5dd845412c",
            "2dfcaeeed8fd4545be5d1d2de8aab470",
            "cb4f3d328d154f8b9706c7d763e03b84",
            "84326cd447b648faa3e3ec67b6f90160",
            "b15d6dd4245647149bf16e59f31cf745",
            "1daf4485ea7d4f44bd70d0eb772d77f8",
            "fbefcd2415f54ae4b762fff1c4bd023a",
            "a1f5d60a52df4e56a9c22cdce3f27f6c",
            "ac7a451e9b9c44778d311944035e0c94",
            "15a7a7280f2e448f8fc0db52f6c69a5f",
            "bcf5133d7b7644ebbe3699c0b5f7497a",
            "8935e1bb8c49461fa812d872ef95119b",
            "618b4abdea57417d96bbc6f93c2ed8b3",
            "a8cfeb9c9df04cd0ae7f5758a7a2cb42",
            "fc2826d29e8c4d1999690195cc8927c9",
            "02d27c22d1b846b59cc40b69c49042d1",
            "ec49d9756f304c34aeb5730f481f7b13",
            "42b585c8d7d44f86bf2471e2a33881d2",
            "b5364f0983814e7282398218477985f2",
            "a7983c63f2c5447bbaa3df5ac2a58d6e",
            "5c0f605e938549378a74ee61403f5c93",
            "471c03ea9ff4466993f2e3ef46233e4c",
            "3ffb8ecdecb2456980886c90a86da87a",
            "1b5ae82f186c4669b5f5fe2cad904a6e",
            "44e03d350e1140d1898a758cc8dd0c9c",
            "d947b0bc464a4232933230d332df7ed2",
            "60771e332159486397854457778d9aa6",
            "2805fd551743426faf467ca119c6cc80",
            "e462637d11f9464b99778ed1ffd38a0c",
            "f2186b2abdae4615af9342875cbd1113",
            "88a6e64ff7c84bc1b002d17fc5ce7848",
            "a1e75b9cca824997bcfb63c8a0846536",
            "7b5858c52e0143a98152935128551d40",
            "21bab149ed314624814fa5d9f6012d6b",
            "c30da8167e164f30955ad40fc07cf282",
            "dc69c6a09c7a4e2db3ec76f458c2fa61",
            "472947bdefba4e0abb22fe846acc02e1",
            "0c05effb31014c61b23800268aff5b3e"
          ]
        },
        "id": "YbPjMyoVc0Vj",
        "outputId": "1aae1b9d-71a8-4212-bdca-253fcc2603cf"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "README.md:   0%|          | 0.00/65.4k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "cee35b3f585645db8e6b46fe9bbacd3f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "test-00000-of-00001.parquet:   0%|          | 0.00/132k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0aaee2a23f934bc3ac1c1641cc1af1a2"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "train-00000-of-00001.parquet:   0%|          | 0.00/57.1M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e76665d0e9194830b5db2bfb0e583601"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "validation-00000-of-00001.parquet:   0%|          | 0.00/132k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "21438547c4aa4554aa616e99ada33c7f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating test split:   0%|          | 0/2000 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1daf4485ea7d4f44bd70d0eb772d77f8"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating train split:   0%|          | 0/1000000 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ec49d9756f304c34aeb5730f481f7b13"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating validation split:   0%|          | 0/2000 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2805fd551743426faf467ca119c6cc80"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tokenizer"
      ],
      "metadata": {
        "id": "AGssMfD0dqOf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Returns a generator list from a dataset of the given language\n",
        "def get_ds_iterator(raw_train_dataset, lang):\n",
        "  for data in raw_train_dataset:\n",
        "    yield data[\"translation\"][lang]\n",
        "\n",
        "# Create English source tokenizer\n",
        "tokenizer_en = Tokenizer(BPE(unk_token=\"[UNK]\"))\n",
        "trainer_en = BpeTrainer(min_frequency=2, special_tokens=[\"[PAD]\", \"[UNK]\", \"[CLS]\", \"[SEP]\", \"[MASK]\"])\n",
        "# Pre-tokenizer to split input into words\n",
        "tokenizer_en.pre_tokenizer = Whitespace()\n",
        "tokenizer_en.train_from_iterator(get_ds_iterator(raw_train_dataset, \"en\"), trainer=trainer_en)\n",
        "tokenizer_en.save(\"./tokenizer_en/tokenizer_en.json\")\n",
        "\n",
        "# Create Malay source tokenizer\n",
        "tokenizer_my = Tokenizer(BPE(unk_token=\"[UNK]\"))\n",
        "trainer_my = BpeTrainer(min_frequency=2, special_tokens=[\"[PAD]\", \"[UNK]\", \"[CLS]\", \"[SEP]\", \"[MASK]\"])\n",
        "# Pre-tokenizer to split input into words\n",
        "tokenizer_my.pre_tokenizer = Whitespace()\n",
        "tokenizer_my.train_from_iterator(get_ds_iterator(raw_train_dataset, \"ms\"), trainer=trainer_my)\n",
        "tokenizer_my.save(\"./tokenizer_my/tokenizer_my.json\")"
      ],
      "metadata": {
        "id": "S90CfWtFdwLd"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Retrieve tokenizers we made\n",
        "tokenizer_en = Tokenizer.from_file(\"./tokenizer_en/tokenizer_en.json\")\n",
        "tokenizer_my = Tokenizer.from_file(\"./tokenizer_my/tokenizer_my.json\")\n",
        "\n",
        "# Get the vocab sizes\n",
        "source_vocab_size = tokenizer_en.get_vocab_size()\n",
        "target_vocab_size = tokenizer_my.get_vocab_size()"
      ],
      "metadata": {
        "id": "v_QXS5hYg77_"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max_seq_len_source = 0\n",
        "max_seq_len_target = 0\n",
        "\n",
        "# Calculate the max sequence length in the training dataset for source/target\n",
        "for data in raw_train_dataset:\n",
        "  enc_ids = tokenizer_en.encode(data[\"translation\"][\"en\"]).ids\n",
        "  dec_ids = tokenizer_my.encode(data[\"translation\"][\"ms\"]).ids\n",
        "  max_seq_len_source = max(max_seq_len_source, len(enc_ids))\n",
        "  max_seq_len_target = max(max_seq_len_target, len(dec_ids))\n",
        "\n",
        "print(\"Source vocab max sequence length:\", max_seq_len_source)\n",
        "print(\"Target vocab max sequence length:\", max_seq_len_target)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Voe9Sjhwsgl7",
        "outputId": "b941750d-b4b0-433c-a969-92abe2620ecf"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Source vocab max sequence length: 140\n",
            "Target vocab max sequence length: 132\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Standard max sequence length for training, with buffer for padding, the classification token, unknown tokens, separator tokens, etc.\n",
        "max_seq_len = 155"
      ],
      "metadata": {
        "id": "MshZzC_HtnDJ"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dataset and Dataloader"
      ],
      "metadata": {
        "id": "ccMVO_M1zK6e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Causal mask to hide future tokens\n",
        "def causal_mask(size):\n",
        "  # Square matrix with ones in the lower triangle: size x size\n",
        "  mask = torch.triu(torch.ones(1, size, size), diagonal=1).type(torch.int)\n",
        "  return mask == 0"
      ],
      "metadata": {
        "id": "3jeluc5ScAEt"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Encode raw dataset to be processed by the model\n",
        "class EncodeDataset(Dataset):\n",
        "  def __init__(self, raw_dataset, max_seq_len):\n",
        "    super().__init__()\n",
        "    self.raw_dataset = raw_dataset\n",
        "    self.max_seq_len = max_seq_len\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.raw_dataset)\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "    # Fetch data (in both English and Malay) for the given index\n",
        "    raw_text = self.raw_dataset[index]\n",
        "\n",
        "    # Separate text into source and target\n",
        "    source_text = raw_text[\"translation\"][\"en\"]\n",
        "    target_text = raw_text[\"translation\"][\"ms\"]\n",
        "\n",
        "    # Encode text\n",
        "    source_text_encoded = tokenizer_en.encode(source_text).ids\n",
        "    target_text_encoded = tokenizer_my.encode(target_text).ids\n",
        "\n",
        "    # Convert CLS, SEP, and PAD to their vocab index id using the tokenizer\n",
        "    # Start of sentence token\n",
        "    CLS_ID = torch.tensor([tokenizer_my.token_to_id(\"[CLS]\")], dtype=torch.int64)\n",
        "    # End of sentence token\n",
        "    SEP_ID = torch.tensor([tokenizer_my.token_to_id(\"[SEP]\")], dtype=torch.int64)\n",
        "    # Padding token\n",
        "    PAD_ID = torch.tensor([tokenizer_my.token_to_id(\"[PAD]\")], dtype=torch.int64)\n",
        "\n",
        "    # Amount to pad the encoded text\n",
        "    num_source_padding = self.max_seq_len - len(source_text_encoded) - 2\n",
        "    num_target_padding = self.max_seq_len - len(target_text_encoded) - 1\n",
        "    encoder_padding = torch.tensor([PAD_ID] * num_source_padding, dtype=torch.int64)\n",
        "    decoder_padding = torch.tensor([PAD_ID] * num_target_padding, dtype=torch.int64)\n",
        "\n",
        "    # CLS + source encoding + SEP + padding\n",
        "    encoder_input = torch.cat([CLS_ID, torch.tensor(source_text_encoded, dtype=torch.int64), SEP_ID, encoder_padding], dim=0)\n",
        "    # CLS + target encoding + padding\n",
        "    decoder_input = torch.cat([CLS_ID, torch.tensor(target_text_encoded, dtype=torch.int64), decoder_padding], dim=0)\n",
        "\n",
        "    # target encoding + SEP + padding\n",
        "    target_label = torch.cat([torch.tensor(target_text_encoded, dtype=torch.int64), SEP_ID, decoder_padding], dim=0)\n",
        "\n",
        "    # Masks to ignore padding\n",
        "    encoder_mask = (encoder_input != PAD_ID).unsqueeze(0).unsqueeze(0).int()\n",
        "    # Apply causal mask to decoder mask, so that the decoder can't see future tokens when predicting the next token\n",
        "    decoder_mask = (decoder_input != PAD_ID).unsqueeze(0).unsqueeze(0).int() & causal_mask(decoder_input.size(0))\n",
        "\n",
        "    return {\n",
        "        \"encoder_input\": encoder_input,\n",
        "        \"decoder_input\": decoder_input,\n",
        "        \"target_label\": target_label,\n",
        "        \"encoder_mask\": encoder_mask,\n",
        "        \"decoder_mask\": decoder_mask,\n",
        "        \"source_text\": source_text,\n",
        "        \"target_text\": target_text\n",
        "    }\n",
        "\n",
        "\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "\n",
        "        # fetching the single data for the given index value that consist of both english and malay language.\n",
        "        raw_text = self.raw_dataset[index]\n",
        "\n",
        "        # separating text by source and target lanaguage which will be later used for encoding.\n",
        "        source_text = raw_text['translation']['en']\n",
        "        target_text = raw_text['translation']['ms']\n",
        "\n",
        "        # Encoding source text with with english tokenizer and target text with malay tokenizer\n",
        "        source_text_encoded = tokenizer_en.encode(source_text).ids\n",
        "        target_text_encoded = tokenizer_my.encode(target_text).ids\n",
        "\n",
        "        # Convert the CLS, SEP and PAD tokens to their corresponding index id in vocabulary using tokenizer [the id would be same with either tokenizers]\n",
        "        CLS_ID = torch.tensor([tokenizer_my.token_to_id(\"[CLS]\")], dtype=torch.int64)\n",
        "        SEP_ID = torch.tensor([tokenizer_my.token_to_id(\"[SEP]\")], dtype=torch.int64)\n",
        "        PAD_ID = torch.tensor([tokenizer_my.token_to_id(\"[PAD]\")], dtype=torch.int64)\n",
        "\n",
        "        # To train the model, the sequence lenth of each input should be equal max seq length. Hence additional number of padding will be added to the input sequence if the lenth is not equal to the max seq length.\n",
        "        num_source_padding = self.max_seq_len - len(source_text_encoded) - 2\n",
        "        num_target_padding = self.max_seq_len - len(target_text_encoded) - 1\n",
        "\n",
        "        encoder_padding = torch.tensor([PAD_ID] * num_source_padding, dtype = torch.int64)\n",
        "        decoder_padding = torch.tensor([PAD_ID] * num_target_padding, dtype = torch.int64)\n",
        "\n",
        "        # encoder_input has the first token as start of senstence - CLS_ID, followed by source encoding which is then followed by the end of sentence token - SEP.\n",
        "        # To reach the required max_seq_len, addition PAD token will be added at the end.\n",
        "        encoder_input = torch.cat([CLS_ID, torch.tensor(source_text_encoded, dtype=torch.int64), SEP_ID, encoder_padding], dim=0)\n",
        "\n",
        "        # decoder_input has the first token as start of senstence - CLS_ID, followed by target encoding.\n",
        "        # To reach the required max_seq_len, addition PAD token will be added at the end. There is no end of sentence token - SEP in decoder input.\n",
        "        decoder_input = torch.cat([CLS_ID, torch.tensor(target_text_encoded, dtype=torch.int64), decoder_padding ], dim=0)\n",
        "\n",
        "        # target_label is required for the loss calculation during training to compare between the predicted and target label.\n",
        "        # target_label has the first token as target encoding followed by actual target encoding. There is no start of sentence token - CLS in target label.\n",
        "        # To reach the required max_seq_len, addition PAD token will be added at the end.\n",
        "        target_label = torch.cat([torch.tensor(target_text_encoded, dtype=torch.int64),SEP_ID,decoder_padding], dim=0)\n",
        "\n",
        "        # Since we've added extra padding token with input encoding, we don't want this token to be trained by model.\n",
        "        # So, we'll use encoder mask to nullify the padding value prior to producing output of self attention in encoder block\n",
        "        encoder_mask = (encoder_input != PAD_ID).unsqueeze(0).unsqueeze(0).int()\n",
        "\n",
        "        # We don't want any token to get influence the future token during the decoding stage. Hence, Causal mask is being implemented during masked multihead attention to handle this.\n",
        "        decoder_mask = (decoder_input != PAD_ID).unsqueeze(0).unsqueeze(0).int() & causal_mask(decoder_input.size(0))\n",
        "\n",
        "        return {\n",
        "            'encoder_input': encoder_input,\n",
        "            'decoder_input': decoder_input,\n",
        "            'target_label': target_label,\n",
        "            'encoder_mask': encoder_mask,\n",
        "            'decoder_mask': decoder_mask,\n",
        "            'source_text': source_text,\n",
        "            'target_text': target_text\n",
        "        }"
      ],
      "metadata": {
        "id": "05HQMYeJXGE7"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create encoded datasets\n",
        "train_ds = EncodeDataset(raw_train_dataset, max_seq_len)\n",
        "val_ds = EncodeDataset(raw_validation_dataset, max_seq_len)\n",
        "\n",
        "# Create dataloaders to use in the model\n",
        "train_dataloader = DataLoader(train_ds, batch_size=5, shuffle=True)\n",
        "val_dataloader = DataLoader(val_ds, batch_size=1, shuffle=True)"
      ],
      "metadata": {
        "id": "KJ6AwuEXEcS3"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "encoder_input: Encoded source text with start and end of sentence tokens and padding\n",
        "decoder_input: Encoded target text with start of sentence token and padding\n",
        "target_label: Encoded target text with padding\n",
        "encoder_mask: Mask to ignore padding in the encoder input\n",
        "decoder_mask: (Causal) mask to ignore padding in the decoder input\n",
        "source_text: Original source text\n",
        "target_text: Original target text\n",
        "'''\n",
        "train_ds.__getitem__(0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0xfTHRbueAmi",
        "outputId": "4c33103d-62fe-4906-e193-4d84c2cd50be"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'encoder_input': tensor([   2,  841,  228, 1715,    9,   79,  213,  139,  653,  228, 1617,    3,\n",
              "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0]),\n",
              " 'decoder_input': tensor([   2,  388,  715,   84, 1042, 1001,  758,  221,  489, 1713,  661,    0,\n",
              "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0]),\n",
              " 'target_label': tensor([ 388,  715,   84, 1042, 1001,  758,  221,  489, 1713,  661,    3,    0,\n",
              "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0]),\n",
              " 'encoder_mask': tensor([[[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "           0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "           0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "           0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "           0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "           0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "           0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]],\n",
              "        dtype=torch.int32),\n",
              " 'decoder_mask': tensor([[[1, 0, 0,  ..., 0, 0, 0],\n",
              "          [1, 1, 0,  ..., 0, 0, 0],\n",
              "          [1, 1, 1,  ..., 0, 0, 0],\n",
              "          ...,\n",
              "          [1, 1, 1,  ..., 0, 0, 0],\n",
              "          [1, 1, 1,  ..., 0, 0, 0],\n",
              "          [1, 1, 1,  ..., 0, 0, 0]]], dtype=torch.int32),\n",
              " 'source_text': \"At our mother's feet lay our heaven\",\n",
              " 'target_text': 'Di bawah tapak kaki ibu kita ialah syurga'}"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Input Embedding and Positional Encoding"
      ],
      "metadata": {
        "id": "UD2iPLMjfo3V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Embedding layer with normalized embeddings\n",
        "class EmbeddingLayer(nn.Module):\n",
        "  def __init__(self, d_model: int, vocab_size: int):\n",
        "    super().__init__()\n",
        "    self.d_model = d_model\n",
        "    # Embedding layer to map token ids to embeddings (vocab_size x d_model)\n",
        "    self.embedding = nn.Embedding(vocab_size, d_model)\n",
        "\n",
        "  def forward(self, input):\n",
        "    # Multiply embedding by the sqrt(d_model) to normalize the output\n",
        "    embedding_output = self.embedding(input) * math.sqrt(self.d_model)\n",
        "    return embedding_output"
      ],
      "metadata": {
        "id": "sVPnN5q5fqeL"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Positional encoding layer\n",
        "class PositionalEncoding(nn.Module):\n",
        "  def __init__(self, d_model: int, max_seq_len: int, dropout_rate: float):\n",
        "    super().__init__()\n",
        "    self.dropout = nn.Dropout(dropout_rate)\n",
        "\n",
        "    # Init positional encodings, positions\n",
        "    pe = torch.zeros(max_seq_len, d_model)\n",
        "    pos = torch.arange(0, max_seq_len, dtype=torch.float).unsqueeze(1)\n",
        "    # 1 / (10000 ** (2 * i / d_model))\n",
        "    div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
        "\n",
        "    # Apply div term to positional encodings, with sin/cos depending on even/odd dimensions\n",
        "    pe[:, 0::2] = torch.sin(pos * div_term)\n",
        "    pe[:, 1::2] = torch.cos(pos * div_term)\n",
        "\n",
        "    # Add batch dimension\n",
        "    # pe: 1 x seq_len x d_model\n",
        "    pe = pe.unsqueeze(0)\n",
        "    # Ensure that the positional encodings are a part of the model, but not trainable\n",
        "    self.register_buffer(\"pe\", pe)\n",
        "\n",
        "  def forward(self, input_embedding):\n",
        "    # input_embedding: batch_size x seq_len x d_model\n",
        "    input_embedding = input_embedding + (self.pe[:, :input_embedding.shape[1], :]).requires_grad_(False)\n",
        "    return self.dropout(input_embedding)"
      ],
      "metadata": {
        "id": "eTBhskyJhcQ-"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Multi-Head Attention"
      ],
      "metadata": {
        "id": "xbsFakYnswg-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Multihead attention block to get context\n",
        "class MultiHeadAttention(nn.Module):\n",
        "  def __init__(self, d_model: int, num_heads: int, dropout_rate: float):\n",
        "    super().__init__()\n",
        "    self.dropout = nn.Dropout(dropout_rate)\n",
        "    self.num_heads = num_heads\n",
        "\n",
        "    # d_model must be divisible by the number of heads\n",
        "    assert d_model % num_heads == 0\n",
        "\n",
        "    # Dimension of each self attention head\n",
        "    self.d_k = d_model // num_heads\n",
        "\n",
        "    # Init weight matrices\n",
        "    self.W_q = nn.Linear(d_model, d_model, bias=False)\n",
        "    self.W_k = nn.Linear(d_model, d_model, bias=False)\n",
        "    self.W_v = nn.Linear(d_model, d_model, bias=False)\n",
        "    self.W_o = nn.Linear(d_model, d_model, bias=False)\n",
        "\n",
        "  def forward(self, q, k, v, encoder_mask):\n",
        "    # q, k, v: batch_size x seq_len x d_model\n",
        "\n",
        "    # Multiply input embeddings by weights\n",
        "    query = self.W_q(q)\n",
        "    key = self.W_k(k)\n",
        "    value = self.W_v(v)\n",
        "\n",
        "    # Divide query, key, and value into the number of heads\n",
        "    # query, key, value: batch_size x num_heads x seq_len x d_k\n",
        "    query = query.view(query.shape[0], query.shape[1], self.num_heads, self.d_k).transpose(1, 2)\n",
        "    key = key.view(key.shape[0], key.shape[1], self.num_heads, self.d_k).transpose(1, 2)\n",
        "    value = value.view(value.shape[0], value.shape[1], self.num_heads, self.d_k).transpose(1, 2)\n",
        "\n",
        "    # SELF ATTENTION BLOCK\n",
        "    # -------------------------\n",
        "\n",
        "    # Attention score based on the similarity between the query and key\n",
        "    # attention_score: batch_size x num_heads x seq_len x seq_len\n",
        "    attention_score = (query @ key.transpose(-2, -1)) / math.sqrt(self.d_k)\n",
        "\n",
        "    # Apply encoder/causal mask\n",
        "    if encoder_mask is not None:\n",
        "      attention_score.masked_fill_(encoder_mask == 0, -1e9)\n",
        "\n",
        "    # Apply softmax\n",
        "    attention_score = attention_score.softmax(dim=-1)\n",
        "\n",
        "    # Apply dropout\n",
        "    if self.dropout is not None:\n",
        "      attention_score = self.dropout(attention_score)\n",
        "\n",
        "    # Multiply attention score with the value\n",
        "    # attention_output: batch_size x num_heads x seq_len x d_k\n",
        "    attention_output = attention_score @ value\n",
        "\n",
        "    # -------------------------\n",
        "\n",
        "    # Concatenate all the output heads\n",
        "    # attention_output: batch_size x seq_len x d_model\n",
        "    attention_output = attention_output.transpose(1, 2).contiguous().view(attention_output.shape[0], -1, self.num_heads * self.d_k)\n",
        "\n",
        "    # Multiply attention output by output weights\n",
        "    multihead_output = self.W_o(attention_output)\n",
        "\n",
        "    return multihead_output"
      ],
      "metadata": {
        "id": "KL3cSgHDswAJ"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Feedforward, Layer Normalization, and AddAndNorm"
      ],
      "metadata": {
        "id": "GJsZAsL9z7YP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Two linear layers, with dropout and ReLU activation\n",
        "class FeedForward(nn.Module):\n",
        "  def __init__(self, d_model: int, d_ff: int, dropout_rate: float):\n",
        "    super().__init__()\n",
        "    self.dropout = nn.Dropout(dropout_rate)\n",
        "    self.layer_1 = nn.Linear(d_model, d_ff)\n",
        "    self.layer_2 = nn.Linear(d_ff, d_model)\n",
        "\n",
        "  def forward(self, input):\n",
        "    return self.layer_2(self.dropout(torch.relu(self.layer_1(input))))"
      ],
      "metadata": {
        "id": "yfilODjF0AEB"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Layer normalization with scaling (gamma) and shifting (beta)\n",
        "class LayerNorm(nn.Module):\n",
        "  def __init__(self, eps: float = 1e-5):\n",
        "    super().__init__()\n",
        "    # Epsilon is for divide-by-zero errors\n",
        "    self.eps = eps\n",
        "    # Extra learning params to scale and shift embedding values; same number of weights as d_model\n",
        "    self.gamma = nn.Parameter(torch.ones(512))\n",
        "    self.beta = nn.Parameter(torch.zeros(512))\n",
        "\n",
        "  def forward(self, input):\n",
        "    mean = input.mean(dim=-1, keepdim=True)\n",
        "    std = input.std(dim=-1, keepdim=True)\n",
        "    return self.gamma * (input - mean) / (std + self.eps) + self.beta"
      ],
      "metadata": {
        "id": "iOLDlOav0em-"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Layer normalization and skip connection\n",
        "class AddAndNorm(nn.Module):\n",
        "  def __init__(self, dropout_rate: float):\n",
        "    super().__init__()\n",
        "    self.dropout = nn.Dropout(dropout_rate)\n",
        "    self.layer_norm = LayerNorm()\n",
        "\n",
        "  def forward(self, input, sub_layer):\n",
        "    return input + self.dropout(sub_layer(self.layer_norm(input)))"
      ],
      "metadata": {
        "id": "W22oPP8F2Kfq"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Encoder Block and Encoder"
      ],
      "metadata": {
        "id": "5WkmqUqY36LR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Multihead attention and feed forward blocks, with add-and-norm\n",
        "class EncoderBlock(nn.Module):\n",
        "  def __init__(self, multihead_attention: MultiHeadAttention, feed_forward: FeedForward, dropout_rate: float) -> None:\n",
        "    super().__init__()\n",
        "    self.multihead_attention = multihead_attention\n",
        "    self.feed_forward = feed_forward\n",
        "    self.addnorm_1 = AddAndNorm(dropout_rate)\n",
        "    self.addnorm_2 = AddAndNorm(dropout_rate)\n",
        "\n",
        "  def forward(self, encoder_input, encoder_mask):\n",
        "    # Encoder input from skip connection and Multihead Attention block\n",
        "    encoder_input = self.addnorm_1(encoder_input, lambda encoder_input: self.multihead_attention(encoder_input, encoder_input, encoder_input, encoder_mask))\n",
        "    # Multihead Attention output from skip connection and Feed Forward block\n",
        "    encoder_input = self.addnorm_2(encoder_input, self.feed_forward)\n",
        "\n",
        "    return encoder_input"
      ],
      "metadata": {
        "id": "05xfP24BBnAx"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Multiple encoder blocks and layer normalization\n",
        "class Encoder(nn.Module):\n",
        "  def __init__(self, encoderblocklist: nn.ModuleList) -> None:\n",
        "    super().__init__()\n",
        "    self.encoderblocklist = encoderblocklist\n",
        "    self.layer_norm = LayerNorm()\n",
        "\n",
        "  def forward(self, encoder_input, encoder_mask):\n",
        "    # Loop input through all encoder blocks\n",
        "    for encoderblock in self.encoderblocklist:\n",
        "      encoder_input = encoderblock(encoder_input, encoder_mask)\n",
        "    # Normalize the final encoder block output\n",
        "    encoder_output = self.layer_norm(encoder_input)\n",
        "    return encoder_output"
      ],
      "metadata": {
        "id": "tghbeybhEYP4"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Decoder Block, Decoder, and Projection Layer"
      ],
      "metadata": {
        "id": "2dY7dD5kFP9i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Masked multihead attention, cross multihead attention from encoder output, and feed forward blocks, with add-and-norm\n",
        "class DecoderBlock(nn.Module):\n",
        "  def __init__(self, masked_multihead_attention: MultiHeadAttention, cross_multihead_attention: MultiHeadAttention, feed_forward: FeedForward, dropout_rate: float) -> None:\n",
        "    super().__init__()\n",
        "    # Uses a causal mask\n",
        "    self.masked_multihead_attention = masked_multihead_attention\n",
        "    # Uses multihead attention from the output of the encoder\n",
        "    self.cross_multihead_attention = cross_multihead_attention\n",
        "    self.feed_forward = feed_forward\n",
        "    self.addnorm_1 = AddAndNorm(dropout_rate)\n",
        "    self.addnorm_2 = AddAndNorm(dropout_rate)\n",
        "    self.addnorm_3 = AddAndNorm(dropout_rate)\n",
        "\n",
        "  def forward(self, decoder_input, encoder_output, encoder_mask, decoder_mask):\n",
        "    # Decoder input from skip connection and Masked Multihead Attention block\n",
        "    decoder_input = self.addnorm_1(decoder_input, lambda decoder_input: self.masked_multihead_attention(decoder_input, decoder_input, decoder_input, decoder_mask))\n",
        "    # Masked Multihead Attention output from skip connection and Cross Multihead Attention block\n",
        "    decoder_input = self.addnorm_2(decoder_input, lambda decoder_input: self.cross_multihead_attention(decoder_input, encoder_output, encoder_output, encoder_mask))\n",
        "    # Cross Multihead Attention output from skip connection and Feed Forward block\n",
        "    decoder_input = self.addnorm_3(decoder_input, self.feed_forward)\n",
        "    return decoder_input"
      ],
      "metadata": {
        "id": "5Y0T2hWWFS6z"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Multiple decoder blocks and layer normalization\n",
        "class Decoder(nn.Module):\n",
        "  def __init__(self, decoderblocklist: nn.ModuleList) -> None:\n",
        "    super().__init__()\n",
        "    self.decoderblocklist = decoderblocklist\n",
        "    self.layer_norm = LayerNorm()\n",
        "\n",
        "  def forward(self, decoder_input, encoder_output, encoder_mask, decoder_mask):\n",
        "    # Loop input through all decoder blocks\n",
        "    for decoderblock in self.decoderblocklist:\n",
        "      decoder_input = decoderblock(decoder_input, encoder_output, encoder_mask, decoder_mask)\n",
        "    # Normalize the final decoder block output\n",
        "    decoder_output = self.layer_norm(decoder_input)\n",
        "    return decoder_output"
      ],
      "metadata": {
        "id": "y2Zcl1xiHzWw"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Linear layer and softmax activation\n",
        "class ProjectionLayer(nn.Module):\n",
        "  def __init__(self, d_model: int, vocab_size: int) -> None:\n",
        "    super().__init__()\n",
        "    self.projection_layer = nn.Linear(d_model, vocab_size)\n",
        "\n",
        "  def forward(self, decoder_output):\n",
        "    # output: batch_size x seq_len x vocab_size\n",
        "    output = self.projection_layer(decoder_output)\n",
        "    return output"
      ],
      "metadata": {
        "id": "a7KyqoUlIrYJ"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Transformer"
      ],
      "metadata": {
        "id": "v5rlc7mPKKVl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Full transformer model; encodes embeddings, decodes outputs, and projects predictions\n",
        "class Transformer(nn.Module):\n",
        "  def __init__(self, encoder: Encoder, decoder: Decoder, source_embed: EmbeddingLayer, target_embed: EmbeddingLayer, source_pos: PositionalEncoding, target_pos: PositionalEncoding, projection_layer: ProjectionLayer) -> None:\n",
        "    super().__init__()\n",
        "    # Encode\n",
        "    self.source_embed = source_embed\n",
        "    self.source_pos = source_pos\n",
        "    self.encoder = encoder\n",
        "\n",
        "    # Decode\n",
        "    self.target_embed = target_embed\n",
        "    self.target_pos = target_pos\n",
        "    self.decoder = decoder\n",
        "\n",
        "    # Maps decoder output to vocabulary\n",
        "    self.projection_layer = projection_layer\n",
        "\n",
        "  def encode(self, encoder_input, encoder_mask):\n",
        "    encoder_input = self.source_embed(encoder_input)\n",
        "    encoder_input = self.source_pos(encoder_input)\n",
        "    encoder_output = self.encoder(encoder_input, encoder_mask)\n",
        "    return encoder_output\n",
        "\n",
        "  def decode(self, encoder_output, encoder_mask, decoder_input, decoder_mask):\n",
        "    decoder_input = self.target_embed(decoder_input)\n",
        "    decoder_input = self.target_pos(decoder_input)\n",
        "    decoder_output = self.decoder(decoder_input, encoder_output, encoder_mask, decoder_mask)\n",
        "    return decoder_output\n",
        "\n",
        "  def project(self, decoder_output):\n",
        "    return self.projection_layer(decoder_output)"
      ],
      "metadata": {
        "id": "U-aAhfIsKLRI"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_model(source_vocab_size, target_vocab_size, source_seq_len, target_seq_len, d_model=512, num_blocks=6, num_heads=8, dropout_rate=0.1, d_ff=2048):\n",
        "  # Embedding layers\n",
        "  source_embed = EmbeddingLayer(d_model, source_vocab_size)\n",
        "  target_embed = EmbeddingLayer(d_model, target_vocab_size)\n",
        "\n",
        "  # Positional encoding layers\n",
        "  source_pos = PositionalEncoding(d_model, source_seq_len, dropout_rate)\n",
        "  target_pos = PositionalEncoding(d_model, target_seq_len, dropout_rate)\n",
        "\n",
        "  # Encoder block list\n",
        "  encoderblocklist = []\n",
        "  for _ in range(num_blocks):\n",
        "    multihead_attention = MultiHeadAttention(d_model, num_heads, dropout_rate)\n",
        "    feed_forward = FeedForward(d_model, d_ff, dropout_rate)\n",
        "    encoder_block = EncoderBlock(multihead_attention, feed_forward, dropout_rate)\n",
        "    encoderblocklist.append(encoder_block)\n",
        "  # Encoder\n",
        "  encoder = Encoder(nn.ModuleList(encoderblocklist))\n",
        "\n",
        "  # Decoder block list\n",
        "  decoderblocklist = []\n",
        "  for _ in range(num_blocks):\n",
        "    masked_multihead_attention = MultiHeadAttention(d_model, num_heads, dropout_rate)\n",
        "    cross_multihead_attention = MultiHeadAttention(d_model, num_heads, dropout_rate)\n",
        "    feed_forward = FeedForward(d_model, d_ff, dropout_rate)\n",
        "    decoder_block = DecoderBlock(masked_multihead_attention, cross_multihead_attention, feed_forward, dropout_rate)\n",
        "    decoderblocklist.append(decoder_block)\n",
        "  # Decoder\n",
        "  decoder = Decoder(nn.ModuleList(decoderblocklist))\n",
        "\n",
        "  # Projection layer\n",
        "  projection_layer = ProjectionLayer(d_model, target_vocab_size)\n",
        "\n",
        "  # Transformer\n",
        "  model = Transformer(encoder, decoder, source_embed, target_embed, source_pos, target_pos, projection_layer)\n",
        "\n",
        "  # Init model params\n",
        "  for p in model.parameters():\n",
        "    if p.dim() > 1:\n",
        "      nn.init.xavier_uniform_(p)\n",
        "\n",
        "  return model"
      ],
      "metadata": {
        "id": "ZWi_S5RuLwEY"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create model\n",
        "model = build_model(tokenizer_en.get_vocab_size(), tokenizer_my.get_vocab_size(), max_seq_len, max_seq_len, d_model=512).to(device)\n",
        "\n",
        "print(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kWUzQoyZNeUE",
        "outputId": "be20bbea-7129-4f60-a63a-04832d33c2da"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Transformer(\n",
            "  (source_embed): EmbeddingLayer(\n",
            "    (embedding): Embedding(1994, 512)\n",
            "  )\n",
            "  (source_pos): PositionalEncoding(\n",
            "    (dropout): Dropout(p=0.1, inplace=False)\n",
            "  )\n",
            "  (encoder): Encoder(\n",
            "    (encoderblocklist): ModuleList(\n",
            "      (0-5): 6 x EncoderBlock(\n",
            "        (multihead_attention): MultiHeadAttention(\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "          (W_q): Linear(in_features=512, out_features=512, bias=False)\n",
            "          (W_k): Linear(in_features=512, out_features=512, bias=False)\n",
            "          (W_v): Linear(in_features=512, out_features=512, bias=False)\n",
            "          (W_o): Linear(in_features=512, out_features=512, bias=False)\n",
            "        )\n",
            "        (feed_forward): FeedForward(\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "          (layer_1): Linear(in_features=512, out_features=2048, bias=True)\n",
            "          (layer_2): Linear(in_features=2048, out_features=512, bias=True)\n",
            "        )\n",
            "        (addnorm_1): AddAndNorm(\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "          (layer_norm): LayerNorm()\n",
            "        )\n",
            "        (addnorm_2): AddAndNorm(\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "          (layer_norm): LayerNorm()\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (layer_norm): LayerNorm()\n",
            "  )\n",
            "  (target_embed): EmbeddingLayer(\n",
            "    (embedding): Embedding(2291, 512)\n",
            "  )\n",
            "  (target_pos): PositionalEncoding(\n",
            "    (dropout): Dropout(p=0.1, inplace=False)\n",
            "  )\n",
            "  (decoder): Decoder(\n",
            "    (decoderblocklist): ModuleList(\n",
            "      (0-5): 6 x DecoderBlock(\n",
            "        (masked_multihead_attention): MultiHeadAttention(\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "          (W_q): Linear(in_features=512, out_features=512, bias=False)\n",
            "          (W_k): Linear(in_features=512, out_features=512, bias=False)\n",
            "          (W_v): Linear(in_features=512, out_features=512, bias=False)\n",
            "          (W_o): Linear(in_features=512, out_features=512, bias=False)\n",
            "        )\n",
            "        (cross_multihead_attention): MultiHeadAttention(\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "          (W_q): Linear(in_features=512, out_features=512, bias=False)\n",
            "          (W_k): Linear(in_features=512, out_features=512, bias=False)\n",
            "          (W_v): Linear(in_features=512, out_features=512, bias=False)\n",
            "          (W_o): Linear(in_features=512, out_features=512, bias=False)\n",
            "        )\n",
            "        (feed_forward): FeedForward(\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "          (layer_1): Linear(in_features=512, out_features=2048, bias=True)\n",
            "          (layer_2): Linear(in_features=2048, out_features=512, bias=True)\n",
            "        )\n",
            "        (addnorm_1): AddAndNorm(\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "          (layer_norm): LayerNorm()\n",
            "        )\n",
            "        (addnorm_2): AddAndNorm(\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "          (layer_norm): LayerNorm()\n",
            "        )\n",
            "        (addnorm_3): AddAndNorm(\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "          (layer_norm): LayerNorm()\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (layer_norm): LayerNorm()\n",
            "  )\n",
            "  (projection_layer): ProjectionLayer(\n",
            "    (projection_layer): Linear(in_features=512, out_features=2291, bias=True)\n",
            "  )\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Validation"
      ],
      "metadata": {
        "id": "DQW533JSN9Vy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def run_validation(model, validation_ds, tokenizer_en, tokenizer_my, max_seq_len, device, print_msg, global_step):\n",
        "  # Change model to only evaluate\n",
        "  model.eval()\n",
        "  count = 0\n",
        "\n",
        "  # Don\"t calculate gradients during evaluation\n",
        "  with torch.no_grad():\n",
        "    for batch in validation_ds:\n",
        "      count += 1\n",
        "\n",
        "      # Get input and mask\n",
        "      encoder_input = batch[\"encoder_input\"].to(device)\n",
        "      encoder_mask = batch[\"encoder_mask\"].to(device)\n",
        "\n",
        "      # Begin and end of sentence tokens\n",
        "      cls_id = tokenizer_my.token_to_id(\"[CLS]\")\n",
        "      sep_id = tokenizer_my.token_to_id(\"[SEP]\")\n",
        "\n",
        "      # Calculate output of the encoder from the val sequence\n",
        "      encoder_output = model.encode(encoder_input, encoder_mask)\n",
        "\n",
        "      # Decoder input first token is the beginning of sentence token\n",
        "      decoder_input = torch.empty(1, 1).fill_(cls_id).type_as(encoder_input).to(device)\n",
        "\n",
        "      # Iteratively add tokens\n",
        "      while True:\n",
        "        # Decoder input is the max length\n",
        "        if decoder_input.size(1) == max_seq_len:\n",
        "          break\n",
        "\n",
        "        # Recreate causal mask for token prediction with a new decoder input\n",
        "        decoder_mask = causal_mask(decoder_input.size(1)).type_as(encoder_mask).to(device)\n",
        "\n",
        "        # Get probabilities for the next token\n",
        "        out = model.decode(encoder_output, encoder_mask, decoder_input, decoder_mask)\n",
        "        prob = model.project(out[:, -1])\n",
        "\n",
        "        # Greedily get the next token with the highest probability\n",
        "        _, next_word = torch.max(prob, dim=1)\n",
        "\n",
        "        # Add predicted token to the decoder input\n",
        "        decoder_input = torch.cat([decoder_input, torch.empty(1, 1).type_as(encoder_input).fill_(next_word.item()).to(device)], dim=1)\n",
        "\n",
        "        # Next token is the end of sentence token\n",
        "        if next_word == sep_id:\n",
        "          break\n",
        "\n",
        "      model_out = decoder_input.squeeze(0)\n",
        "\n",
        "      # Get source text, target text, and predicted text\n",
        "      source_text = batch[\"source_text\"][0]\n",
        "      target_text = batch[\"target_text\"][0]\n",
        "      model_out_text = tokenizer_my.decode(model_out.detach().cpu().numpy())\n",
        "\n",
        "      print_msg(\"-\" * 55)\n",
        "      print_msg(f\"Source Text: {source_text}\")\n",
        "      print_msg(f\"Target Text: {target_text}\")\n",
        "      print_msg(f\"Predicted by MalayGPT: {model_out_text}\")\n",
        "\n",
        "      if count == 2:\n",
        "        break"
      ],
      "metadata": {
        "id": "kBzBcKuON-VV"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training"
      ],
      "metadata": {
        "id": "BmfPR3f3VyZF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(preload_epoch=None):\n",
        "  EPOCHS = 10\n",
        "  initial_epoch = 0\n",
        "  global_step = 0\n",
        "\n",
        "  optimizer = torch.optim.Adam(model.parameters(), lr=1e-4, eps=1e-9)\n",
        "\n",
        "  # Start at preloaded epoch, weights, and optimizer\n",
        "  if preload_epoch is not None:\n",
        "    # Load model\n",
        "    model_filename = f\"./malaygpt/model_{preload_epoch}.pth\"\n",
        "    state = torch.load(model_filename)\n",
        "    model.load_state_dict(state[\"model_state_dict\"])\n",
        "    # Get initial epoch\n",
        "    initial_epoch = state[\"epoch\"] + 1\n",
        "    # Get initial optimizer\n",
        "    optimizer.load_state_dict(state[\"optimizer_state_dict\"])\n",
        "    global_step = state[\"global_step\"]\n",
        "\n",
        "  loss_fn = nn.CrossEntropyLoss(ignore_index=tokenizer_en.token_to_id(\"[PAD]\"), label_smoothing=0.1).to(device)\n",
        "\n",
        "  for epoch in range(initial_epoch, EPOCHS):\n",
        "    # Change model to train\n",
        "    model.train()\n",
        "    # Load dataset batches\n",
        "    batch_iterator = tqdm(train_dataloader, desc=f\"Processing Epoch {epoch:02d}\")\n",
        "    for batch in batch_iterator:\n",
        "      # batch_size x seq_len\n",
        "      encoder_input = batch[\"encoder_input\"].to(device)\n",
        "      # batch_size x seq_len\n",
        "      decoder_input = batch[\"decoder_input\"].to(device)\n",
        "      # batch_size x 1 x 1 x seq_len\n",
        "      encoder_mask = batch[\"encoder_mask\"].to(device)\n",
        "      # batch_size x 1 x seq_len x seq_len\n",
        "      decoder_mask = batch[\"decoder_mask\"].to(device)\n",
        "      # batch_size x seq_len\n",
        "      target_label = batch[\"target_label\"].to(device)\n",
        "\n",
        "      # batch_size x seq_len x d_model\n",
        "      encoder_output = model.encode(encoder_input, encoder_mask)\n",
        "      decoder_output = model.decode(encoder_output, encoder_mask, decoder_input, decoder_mask)\n",
        "      # batch_size x seq_len x vocab_size\n",
        "      projection_output = model.project(decoder_output)\n",
        "\n",
        "      # Calculate loss of the batch\n",
        "      loss = loss_fn(projection_output.view(-1, tokenizer_my.get_vocab_size()), target_label.view(-1))\n",
        "      batch_iterator.set_postfix({\"loss\": f\"{loss.item():6.3f}\"})\n",
        "      loss.backward()\n",
        "\n",
        "      optimizer.step()\n",
        "      optimizer.zero_grad(set_to_none=True)\n",
        "\n",
        "      global_step += 1\n",
        "\n",
        "    # Run validation after every epoch\n",
        "    run_validation(model, val_dataloader, tokenizer_en, tokenizer_my, max_seq_len, device, lambda msg:batch_iterator.write(msg), global_step)\n",
        "\n",
        "    model_filename = f\"./malaygpt/model_{epoch}.pt\"\n",
        "    torch.save({\n",
        "        \"epoch\": epoch,\n",
        "        \"model_state_dict\": model.state_dict(),\n",
        "        \"optimizer_state_dict\": optimizer.state_dict(),\n",
        "        \"global_step\": global_step\n",
        "    }, model_filename)"
      ],
      "metadata": {
        "id": "7wVXGox5Nrdf"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_model(preload_epoch=None)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z0W0tmreV2kt",
        "outputId": "c93237c5-413c-4977-bac4-693e7117139a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing Epoch 00:  86%|████████▌ | 257/300 [20:38<03:18,  4.63s/it, loss=5.523]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # Step3: Prepare dataset and dataloader\n",
        "\n",
        "# # Transform raw dataset to the encoded dataset that can be processed by the model\n",
        "# class EncodeDataset(Dataset):\n",
        "#     def __init__(self, raw_dataset, max_seq_len):\n",
        "#         super().__init__()\n",
        "#         self.raw_dataset = raw_dataset\n",
        "#         self.max_seq_len = max_seq_len\n",
        "\n",
        "#     def __len__(self):\n",
        "#         return len(self.raw_dataset)\n",
        "\n",
        "#     def __getitem__(self, index):\n",
        "\n",
        "#         # fetching the single data for the given index value that consist of both english and malay language.\n",
        "#         raw_text = self.raw_dataset[index]\n",
        "\n",
        "#         # separating text by source and target lanaguage which will be later used for encoding.\n",
        "#         source_text = raw_text['translation']['en']\n",
        "#         target_text = raw_text['translation']['ms']\n",
        "\n",
        "#         # Encoding source text with with english tokenizer and target text with malay tokenizer\n",
        "#         source_text_encoded = tokenizer_en.encode(source_text).ids\n",
        "#         target_text_encoded = tokenizer_my.encode(target_text).ids\n",
        "\n",
        "#         # Convert the CLS, SEP and PAD tokens to their corresponding index id in vocabulary using tokenizer [the id would be same with either tokenizers]\n",
        "#         CLS_ID = torch.tensor([tokenizer_my.token_to_id(\"[CLS]\")], dtype=torch.int64)\n",
        "#         SEP_ID = torch.tensor([tokenizer_my.token_to_id(\"[SEP]\")], dtype=torch.int64)\n",
        "#         PAD_ID = torch.tensor([tokenizer_my.token_to_id(\"[PAD]\")], dtype=torch.int64)\n",
        "\n",
        "#         # To train the model, the sequence lenth of each input should be equal max seq length. Hence additional number of padding will be added to the input sequence if the lenth is not equal to the max seq length.\n",
        "#         num_source_padding = self.max_seq_len - len(source_text_encoded) - 2\n",
        "#         num_target_padding = self.max_seq_len - len(target_text_encoded) - 1\n",
        "\n",
        "#         encoder_padding = torch.tensor([PAD_ID] * num_source_padding, dtype = torch.int64)\n",
        "#         decoder_padding = torch.tensor([PAD_ID] * num_target_padding, dtype = torch.int64)\n",
        "\n",
        "#         # encoder_input has the first token as start of senstence - CLS_ID, followed by source encoding which is then followed by the end of sentence token - SEP.\n",
        "#         # To reach the required max_seq_len, addition PAD token will be added at the end.\n",
        "#         encoder_input = torch.cat([CLS_ID, torch.tensor(source_text_encoded, dtype=torch.int64), SEP_ID, encoder_padding], dim=0)\n",
        "\n",
        "#         # decoder_input has the first token as start of senstence - CLS_ID, followed by target encoding.\n",
        "#         # To reach the required max_seq_len, addition PAD token will be added at the end. There is no end of sentence token - SEP in decoder input.\n",
        "#         decoder_input = torch.cat([CLS_ID, torch.tensor(target_text_encoded, dtype=torch.int64), decoder_padding ], dim=0)\n",
        "\n",
        "#         # target_label is required for the loss calculation during training to compare between the predicted and target label.\n",
        "#         # target_label has the first token as target encoding followed by actual target encoding. There is no start of sentence token - CLS in target label.\n",
        "#         # To reach the required max_seq_len, addition PAD token will be added at the end.\n",
        "#         target_label = torch.cat([torch.tensor(target_text_encoded, dtype=torch.int64),SEP_ID,decoder_padding], dim=0)\n",
        "\n",
        "#         # Since we've added extra padding token with input encoding, we don't want this token to be trained by model.\n",
        "#         # So, we'll use encoder mask to nullify the padding value prior to producing output of self attention in encoder block\n",
        "#         encoder_mask = (encoder_input != PAD_ID).unsqueeze(0).unsqueeze(0).int()\n",
        "\n",
        "#         # We don't want any token to get influence the future token during the decoding stage. Hence, Causal mask is being implemented during masked multihead attention to handle this.\n",
        "#         decoder_mask = (decoder_input != PAD_ID).unsqueeze(0).unsqueeze(0).int() & causal_mask(decoder_input.size(0))\n",
        "\n",
        "#         return {\n",
        "#             'encoder_input': encoder_input,\n",
        "#             'decoder_input': decoder_input,\n",
        "#             'target_label': target_label,\n",
        "#             'encoder_mask': encoder_mask,\n",
        "#             'decoder_mask': decoder_mask,\n",
        "#             'source_text': source_text,\n",
        "#             'target_text': target_text\n",
        "#         }\n",
        "\n",
        "# # Causal mask will make sure any token that comes after the current token will be masked meaning the value will be replaced by -infinity that will be converted to zero or neearly zero after softmax operation. Hence the model will just ignore these value or willn't be able to learn anything.\n",
        "# def causal_mask(size):\n",
        "#         # Creating a square matrix of dimensions 'size x size' filled with ones\n",
        "#         mask = torch.triu(torch.ones(1, size, size), diagonal = 1).type(torch.int)\n",
        "#         return mask == 0\n",
        "\n",
        "# # create a dataloader to use for model training and validation\n",
        "# train_ds = EncodeDataset(raw_train_dataset, max_seq_len)\n",
        "# val_ds = EncodeDataset(raw_validation_dataset, max_seq_len)\n",
        "\n",
        "# train_dataloader = DataLoader(train_ds, batch_size = 5, shuffle = True)\n",
        "# val_dataloader = DataLoader(val_ds, batch_size = 1, shuffle = True)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# class EmbeddingLayer(nn.Module):\n",
        "#     def __init__(self, d_model: int, vocab_size: int):\n",
        "#         super().__init__()\n",
        "#         self.d_model = d_model\n",
        "#         # using pytorch models embedding layer to map token id to embeeding vector which has the shape of (vocab_size, d_model)\n",
        "#         # The vocab_size is the vocabulary size of the training data created by tokenizer in step 2\n",
        "#         self.embedding = nn.Embedding(vocab_size, d_model)\n",
        "\n",
        "#     def forward(self, input):\n",
        "#         # In addition of giving input to the embedding, the extra multiplication by square root of d_model is to normalize the embedding layer output\n",
        "#         embedding_output = self.embedding(input) * math.sqrt(self.d_model)\n",
        "#         return embedding_output\n",
        "\n",
        "# class PositionalEncoding(nn.Module):\n",
        "#     def __init__(self, d_model: int, max_seq_len: int, dropout_rate: float):\n",
        "#         super().__init__()\n",
        "#         self.dropout = nn.Dropout(dropout_rate)\n",
        "#         pe = torch.zeros(max_seq_len, d_model)\n",
        "\n",
        "#         pos = torch.arange(0, max_seq_len, dtype=torch.float).unsqueeze(1)\n",
        "#         div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
        "\n",
        "#         pe[:, 0::2] = torch.sin(pos * div_term)\n",
        "#         pe[:, 1::2] = torch.cos(pos * div_term)\n",
        "\n",
        "#         # since we're expecting the input sentenses in batches so the extra dimension to cater batch number needs to be added in 0 postion\n",
        "#         pe = pe.unsqueeze(0)\n",
        "#         self.register_buffer('pe', pe)\n",
        "\n",
        "#     def forward(self, input_embdding):\n",
        "#         input_embdding = input_embdding + (self.pe[:, :input_embdding.shape[1], :]).requires_grad_(False)   # to prevent from calculating gradient\n",
        "#         return self.dropout(input_embdding)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# # Step 5: Multihead Attention\n",
        "# class MultiHeadAttention(nn.Module):\n",
        "#     def __init__(self, d_model: int, num_heads: int, dropout_rate: float):\n",
        "#         super().__init__()\n",
        "#         # Defining dropout to prevent overfitting\n",
        "#         self.dropout = nn.Dropout(dropout_rate)\n",
        "#         self.num_heads = num_heads\n",
        "#         assert d_model % num_heads == 0, \"d_model must be divisible by number of heads\"\n",
        "\n",
        "#         # d_k is the new dimension of each self attention heads\n",
        "#         self.d_k = d_model // num_heads\n",
        "\n",
        "#         # Weight matrix are defined which are all learnable parameters\n",
        "#         self.W_q = nn.Linear(d_model, d_model, bias=False)\n",
        "#         self.W_k = nn.Linear(d_model, d_model, bias=False)\n",
        "#         self.W_v = nn.Linear(d_model, d_model, bias=False)\n",
        "#         self.W_o = nn.Linear(d_model, d_model, bias=False)\n",
        "\n",
        "#     def forward(self, q, k, v, encoder_mask):\n",
        "\n",
        "#         # Please note that we'll be training our model with not just a single sequence but rather batches of sequence, hence we'll include batch_size in the shape\n",
        "#         # query, Key and value are calculated by matrix multiplication of corresponding weights with the input embeddings\n",
        "#         # Change of shape: q(batch_size, seq_len, d_model) @ W_q(d_model, d_model) => query(batch_size, seq_len, d_model) [same goes to key and value]\n",
        "#         query = self.W_q(q)\n",
        "#         key = self.W_k(k)\n",
        "#         value = self.W_v(v)\n",
        "\n",
        "#         # Dividing query, key and value into number of heads, hence new dimenstion will be d_k.\n",
        "#         # Change of shape: query(batch_size, seq_len, d_model) => query(batch_size, seq_len, num_heads, d_k) -> query(batch_size,num_heads, seq_len,d_k) [same goes to key and value]\n",
        "#         query = query.view(query.shape[0], query.shape[1], self.num_heads ,self.d_k).transpose(1,2)\n",
        "#         key = key.view(key.shape[0], key.shape[1], self.num_heads ,self.d_k).transpose(1,2)\n",
        "#         value = value.view(value.shape[0], value.shape[1], self.num_heads ,self.d_k).transpose(1,2)\n",
        "\n",
        "#         # :: SELF ATTENTION BLOCK STARTS ::\n",
        "\n",
        "#         # Attention score is calculated to find the similarity or relation of query with key of itself and all other embedding in the sequence\n",
        "#         #  Change of shape: query(batch_size,num_heads, seq_len,d_k) @ key(batch_size,num_heads, seq_len,d_k) => attention_score(batch_size,num_heads, seq_len,seq_len)\n",
        "#         attention_score = (query @ key.transpose(-2,-1))/math.sqrt(self.d_k)\n",
        "\n",
        "#         # If mask is provided the attention score needs to modify as per the mask value. Refer to the details in point no 4.\n",
        "#         if encoder_mask is not None:\n",
        "#           attention_score.masked_fill_(encoder_mask==0, -1e9)\n",
        "\n",
        "#         # Softmax operation calculates the probability distribution among all the attention scores. This will determine which embedding is more similar to the given query embedding and assign the attention weight accordingly.\n",
        "#         # Change of shape: same as attention_score\n",
        "#         attention_score = attention_score.softmax(dim=-1)\n",
        "\n",
        "#         if self.dropout is not None:\n",
        "#           attention_score = self.dropout(attention_score)\n",
        "\n",
        "#         # Final step of Self attention block is to matrix multiplication of attention_weight with value embedding.\n",
        "#         # Change of shape: attention_score(batch_size,num_heads, seq_len,seq_len) @  value(batch_size,num_heads, seq_len,d_k) => attention_output(batch_size,num_heads, seq_len,d_k)\n",
        "#         attention_output = attention_score @ value\n",
        "\n",
        "#         # :: SELF ATTENTION BLOCK ENDS ::\n",
        "\n",
        "#         # Now, all the heads will be concated back to for a single head\n",
        "#         # Change of shape:attention_output(batch_size,num_heads, seq_len,d_k) => attention_output(batch_size,seq_len,num_heads,d_k) => attention_output(batch_size,seq_len,d_model)\n",
        "#         attention_output = attention_output.transpose(1,2).contiguous().view(attention_output.shape[0], -1, self.num_heads * self.d_k)\n",
        "\n",
        "#         # Finally attention_output is matrix multiplied with output weight matrix to give the final Multi-Head attention output.\n",
        "#         # The shape of the multihead_output is same as the embedding input\n",
        "#         # Change of shape: attention_output(batch_size,seq_len,d_model) @ W_o(d_model, d_model) => multihead_output(batch_size, seq_len, d_model)\n",
        "#         multihead_output = self.W_o(attention_output)\n",
        "\n",
        "#         return multihead_output\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# # Step 6: Feedfoward Network, Layer Normalization and AddAndNorm\n",
        "\n",
        "# class FeedForward(nn.Module):\n",
        "#     def __init__(self, d_model: int, d_ff: int, dropout_rate: float):\n",
        "#         super().__init__()\n",
        "\n",
        "#         self.dropout = nn.Dropout(dropout_rate)\n",
        "#         self.layer_1 = nn.Linear(d_model, d_ff)\n",
        "#         self.layer_2 = nn.Linear(d_ff, d_model)\n",
        "\n",
        "#     def forward(self, input):\n",
        "#         return self.layer_2(self.dropout(torch.relu(self.layer_1(input))))\n",
        "\n",
        "# class LayerNorm(nn.Module):\n",
        "#     # def __init__(self, features:int=512, eps: float = 1e-5):\n",
        "#     def __init__(self, eps: float = 1e-5):\n",
        "#         super().__init__()\n",
        "#         # epsilon is a very small value and is plays an important role to avoid division by zero problem\n",
        "#         self.eps = eps\n",
        "#         #Extra learning parameters gamma and beta are introduced to scale and shift the embedding value as the network needed.\n",
        "#         self.gamma = nn.Parameter(torch.ones(512))  # 512 = advisable to initialize with same number as d_model\n",
        "#         self.beta = nn.Parameter(torch.zeros(512))\n",
        "\n",
        "#     def forward(self, input):\n",
        "#         mean = input.mean(dim = -1, keepdim=True)\n",
        "#         std = input.std(dim = -1, keepdim=True)\n",
        "#         return self.gamma * (input - mean)/(std + self.eps) + self.beta\n",
        "\n",
        "# class AddAndNorm(nn.Module):\n",
        "#   def __init__(self, dropout_rate: float):\n",
        "#         super().__init__()\n",
        "#         self.dropout = nn.Dropout(dropout_rate)\n",
        "#         self.layer_norm = LayerNorm()\n",
        "\n",
        "#   def forward(self, input, sub_layer):\n",
        "#         return input + self.dropout(sub_layer(self.layer_norm(input)))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# #Step 7: Encoder block and Encoder\n",
        "\n",
        "# class EncoderBlock(nn.Module):\n",
        "#     # def __init__(self, features: int, self_attention_block: MultiHeadAttention, feed_forward_block: FeedForward, dropout_rate: float) -> None:\n",
        "#     def __init__(self, multihead_attention: MultiHeadAttention, feed_forward: FeedForward, dropout_rate: float) -> None:\n",
        "#         super().__init__()\n",
        "#         self.multihead_attention = multihead_attention\n",
        "#         self.feed_forward = feed_forward\n",
        "#         self.addnorm_1 = AddAndNorm(dropout_rate)\n",
        "#         self.addnorm_2 = AddAndNorm(dropout_rate)\n",
        "\n",
        "#     def forward(self, encoder_input, encoder_mask):\n",
        "#         # First AddAndNorm unit taking encoder input from skip connection and adding it with the output of MultiHead attention block\n",
        "#         encoder_input = self.addnorm_1(encoder_input, lambda encoder_input: self.multihead_attention(encoder_input, encoder_input, encoder_input, encoder_mask))\n",
        "#         # Second AddAndNorm unit taking output of MultiHead attention block from skip connection and adding it with the output of Feedforward layer\n",
        "#         encoder_input = self.addnorm_2(encoder_input, self.feed_forward)\n",
        "#         return encoder_input\n",
        "\n",
        "# class Encoder(nn.Module):\n",
        "#     def __init__(self, encoderblocklist: nn.ModuleList) -> None:\n",
        "#         super().__init__()\n",
        "#         # Encoder class initialized by taking encoderblock list\n",
        "#         self.encoderblocklist = encoderblocklist\n",
        "#         self.layer_norm = LayerNorm()\n",
        "\n",
        "#     def forward(self, encoder_input, encoder_mask):\n",
        "#         # Looping through all the encoder block - 6 times\n",
        "#         for encoderblock in self.encoderblocklist:\n",
        "#             encoder_input = encoderblock(encoder_input, encoder_mask)\n",
        "#         # Normalize the final encoder block output and return. This encoder output will be used later on as key and value for the cross attention in decoder block\n",
        "#         encoder_output = self.layer_norm(encoder_input)\n",
        "#         return encoder_output\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# #Step 8: Decoder block and decoder and the projection\n",
        "\n",
        "# class DecoderBlock(nn.Module):\n",
        "#     # def __init__(self, features: int, self_attention_block: MultiHeadAttention, cross_attention_block: MultiHeadAttention, feed_forward_block: FeedForward, dropout_rate: float) -> None:\n",
        "#     def __init__(self, masked_multihead_attention: MultiHeadAttention, cross_multihead_attention: MultiHeadAttention, feed_forward: FeedForward, dropout_rate: float) -> None:\n",
        "#         super().__init__()\n",
        "#         self.masked_multihead_attention = masked_multihead_attention\n",
        "#         self.cross_multihead_attention = cross_multihead_attention\n",
        "#         self.feed_forward = feed_forward\n",
        "#         self.addnorm_1 = AddAndNorm(dropout_rate)\n",
        "#         self.addnorm_2 = AddAndNorm(dropout_rate)\n",
        "#         self.addnorm_3 = AddAndNorm(dropout_rate)\n",
        "\n",
        "#     def forward(self, decoder_input, encoder_output, encoder_mask, decoder_mask):\n",
        "#         # First AddAndNorm unit taking decoder input from skip connection and adding it with the output of Masked Multi-Head attention block\n",
        "#         decoder_input = self.addnorm_1(decoder_input, lambda decoder_input: self.masked_multihead_attention(decoder_input, decoder_input, decoder_input, decoder_mask))\n",
        "#         # Second AddAndNorm unit taking output of Masked Multi-Head attention block from skip connection and adding it with the output of MultiHead attention block\n",
        "#         decoder_input = self.addnorm_2(decoder_input, lambda decoder_input: self.cross_multihead_attention(decoder_input, encoder_output, encoder_output, encoder_mask))\n",
        "#         # Third AddAndNorm unit taking output of MultiHead attention block from skip connection and adding it with the output of Feedforward layer\n",
        "#         decoder_input = self.addnorm_3(decoder_input, self.feed_forward)\n",
        "#         return decoder_input\n",
        "\n",
        "# class Decoder(nn.Module):\n",
        "#     # def __init__(self, features: int, layers: nn.ModuleList) -> None:\n",
        "#     def __init__(self, decoderblocklist: nn.ModuleList) -> None:\n",
        "#         super().__init__()\n",
        "#         self.decoderblocklist = decoderblocklist\n",
        "#         self.layer_norm = LayerNorm()\n",
        "\n",
        "#     def forward(self, decoder_input, encoder_output, encoder_mask, decoder_mask):\n",
        "#         for decoderblock in self.decoderblocklist:\n",
        "#             decoder_input = decoderblock(decoder_input, encoder_output, encoder_mask, decoder_mask)\n",
        "#         decoder_output = self.layer_norm(decoder_input)\n",
        "#         return decoder_output\n",
        "\n",
        "# class ProjectionLayer(nn.Module):\n",
        "#     def __init__(self, d_model, vocab_size) -> None:\n",
        "#         super().__init__()\n",
        "#         self.projection_layer = nn.Linear(d_model, vocab_size)\n",
        "\n",
        "#     def forward(self, decoder_output) -> None:\n",
        "#         # Projection layer first take in decoder output and feed into the linear layer of shape (d_model, vocab_size)\n",
        "#         #Change in shape: decoder_output(batch_size, seq_len, d_model) @ linear_layer(d_model, vocab_size) => output(batch_size, seq_len, vocab_size)\n",
        "#         output = self.projection_layer(decoder_output)\n",
        "#         return output\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# #Step 9: Create and build Transfomer\n",
        "# class Transformer(nn.Module):\n",
        "#     def __init__(self, encoder: Encoder, decoder: Decoder, source_embed: EmbeddingLayer, target_embed: EmbeddingLayer, source_pos: PositionalEncoding, target_pos: PositionalEncoding, projection_layer: ProjectionLayer) -> None:\n",
        "#         super().__init__()\n",
        "\n",
        "#         self.source_embed = source_embed\n",
        "#         self.source_pos = source_pos\n",
        "#         self.encoder = encoder\n",
        "\n",
        "#         self.target_embed = target_embed\n",
        "#         self.target_pos = target_pos\n",
        "#         self.decoder = decoder\n",
        "\n",
        "#         self.projection_layer = projection_layer\n",
        "\n",
        "#     def encode(self, encoder_input, encoder_mask):\n",
        "#         encoder_input = self.source_embed(encoder_input)\n",
        "#         encoder_input = self.source_pos(encoder_input)\n",
        "#         encoder_output = self.encoder(encoder_input, encoder_mask)\n",
        "#         return encoder_output\n",
        "\n",
        "#     def decode(self, encoder_output, encoder_mask, decoder_input, decoder_mask):\n",
        "#         decoder_input = self.target_embed(decoder_input)\n",
        "#         decoder_input = self.target_pos(decoder_input)\n",
        "#         decoder_output = self.decoder(decoder_input, encoder_output, encoder_mask, decoder_mask)\n",
        "#         return decoder_output\n",
        "\n",
        "#     def project(self, decoder_output):\n",
        "#         return self.projection_layer(decoder_output)\n",
        "\n",
        "def build_model(source_vocab_size: int, target_vocab_size: int, source_seq_len: int, target_seq_len: int, d_model: int=512, num_blocks: int=6, num_heads: int=8, dropout_rate: float=0.1, d_ff: int=2048) -> Transformer:\n",
        "    # Create the embedding layers\n",
        "    source_embed = EmbeddingLayer(d_model, source_vocab_size)\n",
        "    target_embed = EmbeddingLayer(d_model, target_vocab_size)\n",
        "\n",
        "    # Create the positional encoding layers\n",
        "    source_pos = PositionalEncoding(d_model, source_seq_len, dropout_rate)\n",
        "    target_pos = PositionalEncoding(d_model, target_seq_len, dropout_rate)\n",
        "\n",
        "    # Create the encoder-block-list\n",
        "    encoderblocklist = []\n",
        "    for _ in range(num_blocks):\n",
        "        multihead_attention = MultiHeadAttention(d_model, num_heads, dropout_rate)\n",
        "        feed_forward = FeedForward(d_model, d_ff, dropout_rate)\n",
        "        encoder_block = EncoderBlock(multihead_attention, feed_forward, dropout_rate)\n",
        "        encoderblocklist.append(encoder_block)\n",
        "    # Create the encoder\n",
        "    encoder = Encoder(nn.ModuleList(encoderblocklist))\n",
        "\n",
        "    # Create the decoder-block-list\n",
        "    decoderblocklist = []\n",
        "    for _ in range(num_blocks):\n",
        "        masked_multihead_attention = MultiHeadAttention(d_model,num_heads, dropout_rate)\n",
        "        cross_multihead_attention = MultiHeadAttention(d_model, num_heads, dropout_rate)\n",
        "        feed_forward = FeedForward(d_model, d_ff, dropout_rate)\n",
        "        decoder_block = DecoderBlock(masked_multihead_attention, cross_multihead_attention, feed_forward, dropout_rate)\n",
        "        decoderblocklist.append(decoder_block)\n",
        "    # Create the decoder\n",
        "    decoder = Decoder(nn.ModuleList(decoderblocklist))\n",
        "\n",
        "    # Create the projection layer\n",
        "    projection_layer = ProjectionLayer(d_model, target_vocab_size)\n",
        "\n",
        "    # Now that we've initialized all the required blocks of transformer, we can now inititiate a model\n",
        "    model = Transformer(encoder, decoder, source_embed, target_embed, source_pos, target_pos, projection_layer)\n",
        "\n",
        "    # For the first time, we'll initialize the model parameters using xavier uniform method. Once training begings the parameters will be updated by the network\n",
        "    for p in model.parameters():\n",
        "        if p.dim() > 1:\n",
        "            nn.init.xavier_uniform_(p)\n",
        "\n",
        "    return model\n",
        "\n",
        "# Let's build the the final model.\n",
        "model = build_model(tokenizer_en.get_vocab_size(), tokenizer_my.get_vocab_size(),max_seq_len, max_seq_len, d_model=512).to(device)\n",
        "\n",
        "# Let's look at the architecture that we've just build ourself\n",
        "print(model)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#Step 10: Training and Validation of malayGPT\n",
        "\n",
        "def run_validation(model, validation_ds, tokenizer_en, tokenizer_my, max_seq_len, device, print_msg, global_step):\n",
        "    model.eval()\n",
        "    count = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in validation_ds:\n",
        "            count += 1\n",
        "            encoder_input = batch[\"encoder_input\"].to(device)\n",
        "            encoder_mask = batch[\"encoder_mask\"].to(device)\n",
        "\n",
        "            cls_id = tokenizer_my.token_to_id('[CLS]')\n",
        "            sep_id = tokenizer_my.token_to_id('[SEP]')\n",
        "\n",
        "            # Computing the output of the encoder for the source sequence\n",
        "            encoder_output = model.encode(encoder_input, encoder_mask)\n",
        "            # for prediction task, the first token that goes in decoder input is the [CLS] token\n",
        "            decoder_input = torch.empty(1, 1).fill_(cls_id).type_as(encoder_input).to(device)\n",
        "            # since we need to keep adding the output back to the input until the [SEP] - end token is received.\n",
        "            while True:\n",
        "                # check if the max length is received\n",
        "                if decoder_input.size(1) == max_seq_len:\n",
        "                    break\n",
        "\n",
        "                # recreate mask each time the new output is added the decoder input for next token prediction\n",
        "                decoder_mask = causal_mask(decoder_input.size(1)).type_as(encoder_mask).to(device)\n",
        "\n",
        "                # apply projection only to the next token\n",
        "                out = model.decode(encoder_output, encoder_mask, decoder_input, decoder_mask)\n",
        "\n",
        "                # apply projection only to the next token\n",
        "                prob = model.project(out[:, -1])\n",
        "\n",
        "                # select the token with highest probablity which is a greedy search implementation\n",
        "                _, next_word = torch.max(prob, dim=1)\n",
        "                decoder_input = torch.cat(\n",
        "                    [decoder_input, torch.empty(1, 1).type_as(encoder_input).fill_(next_word.item()).to(device)], dim=1\n",
        "                )\n",
        "                # check if the new token is the end of token\n",
        "                if next_word == sep_id:\n",
        "                    break\n",
        "            # final output is the concatinated decoder input till the end token is reached\n",
        "            model_out = decoder_input.squeeze(0)\n",
        "\n",
        "            source_text = batch[\"source_text\"][0]\n",
        "            target_text = batch[\"target_text\"][0]\n",
        "            model_out_text = tokenizer_my.decode(model_out.detach().cpu().numpy())\n",
        "\n",
        "            # Print the source, target and model output\n",
        "            print_msg('-'*55)\n",
        "            # print_msg(f\"{f'SOURCE: ':>12}{source_text}\")\n",
        "            # print_msg(f\"{f'TARGET: ':>12}{target_text}\")\n",
        "            # print_msg(f\"{f'PREDICTED: ':>12}{model_out_text}\")\n",
        "            print_msg(f'Source Text: {source_text}')\n",
        "            print_msg(f'Target Text: {target_text}')\n",
        "            print_msg(f'Predicted by MalayGPT: {model_out_text}')\n",
        "\n",
        "            if count == 2:\n",
        "                break\n",
        "\n",
        "def train_model(preload_epoch=None):\n",
        "    # The entire training, validation cycle will run for 20 cycles or epochs.\n",
        "    EPOCHS = 10\n",
        "    initial_epoch = 0\n",
        "    global_step = 0\n",
        "\n",
        "    # Adam is one of the most commonly used optimization algorithms that hold the current state and will update the parameters based on the computed gradients.\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-4, eps=1e-9)\n",
        "\n",
        "    # If the preload_epoch is not none, that means the training will start with the weights, optimizer that has been last saved and start with preload epoch + 1\n",
        "    if preload_epoch is not None:\n",
        "      model_filename = f\"./malaygpt/model_{preload_epoch}.pt\"\n",
        "      state = torch.load(model_filename)\n",
        "      model.load_state_dict(state['model_state_dict'])\n",
        "      initial_epoch = state['epoch'] + 1\n",
        "      optimizer.load_state_dict(state['optimizer_state_dict'])\n",
        "      global_step = state['global_step']\n",
        "\n",
        "    # The CrossEntropyLoss loss function computes the difference between the projection output and target label.\n",
        "    loss_fn = nn.CrossEntropyLoss(ignore_index=tokenizer_en.token_to_id('[PAD]'), label_smoothing=0.1).to(device)\n",
        "\n",
        "    for epoch in range(initial_epoch, EPOCHS):\n",
        "        # torch.cuda.empty_cache()\n",
        "        model.train()\n",
        "        batch_iterator = tqdm(train_dataloader, desc=f\"Processing Epoch {epoch:02d}\")\n",
        "        for batch in batch_iterator:\n",
        "            encoder_input = batch['encoder_input'].to(device) # (b, seq_len)\n",
        "            decoder_input = batch['decoder_input'].to(device) # (B, seq_len)\n",
        "            encoder_mask = batch['encoder_mask'].to(device) # (B, 1, 1, seq_len)\n",
        "            decoder_mask = batch['decoder_mask'].to(device) # (B, 1, seq_len, seq_len)\n",
        "            target_label = batch['target_label'].to(device) # (B, seq_len)\n",
        "\n",
        "            # Run the tensors through the encoder, decoder and the projection layer\n",
        "            encoder_output = model.encode(encoder_input, encoder_mask) # (B, seq_len, d_model)\n",
        "            decoder_output = model.decode(encoder_output, encoder_mask, decoder_input, decoder_mask) # (B, seq_len, d_model)\n",
        "            projection_output = model.project(decoder_output) # (B, seq_len, vocab_size)\n",
        "\n",
        "            # Compute the loss using a simple cross entropy\n",
        "            loss = loss_fn(projection_output.view(-1, tokenizer_my.get_vocab_size()), target_label.view(-1))\n",
        "            batch_iterator.set_postfix({\"loss\": f\"{loss.item():6.3f}\"})\n",
        "\n",
        "            # Backpropagate the loss\n",
        "            loss.backward()\n",
        "\n",
        "            # Update the weights\n",
        "            optimizer.step()\n",
        "            optimizer.zero_grad(set_to_none=True)\n",
        "\n",
        "            global_step += 1\n",
        "\n",
        "        # VALIDATION BLOCK STARTS HERE [Runs every epoch after the training block is complete]\n",
        "        run_validation(model, val_dataloader, tokenizer_en, tokenizer_my, max_seq_len, device, lambda msg: batch_iterator.write(msg), global_step)\n",
        "\n",
        "        # Save the model at the end of every epoch\n",
        "        model_filename = f\"./malaygpt/model_{epoch}.pt\"\n",
        "        torch.save({\n",
        "            'epoch': epoch,\n",
        "            'model_state_dict': model.state_dict(),\n",
        "            'optimizer_state_dict': optimizer.state_dict(),\n",
        "            'global_step': global_step\n",
        "        }, model_filename)\n",
        "\n",
        "# Train our model\n",
        "train_model(preload_epoch=None)"
      ],
      "metadata": {
        "id": "qBF7zyuWk0jg"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "cee35b3f585645db8e6b46fe9bbacd3f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9844b8c1dd454c34a53fa895276f225e",
              "IPY_MODEL_51b11140569e452b8f5e6a38e0a7e863",
              "IPY_MODEL_8d493b21b92e4d2ba3900f05f5ec5ce0"
            ],
            "layout": "IPY_MODEL_17888453970a42fc8d02bc1d2f9f5f64"
          }
        },
        "9844b8c1dd454c34a53fa895276f225e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6ef964c9a58645d7b71843ed6727102a",
            "placeholder": "​",
            "style": "IPY_MODEL_f9d34ec0339045f7896ae968a7160e41",
            "value": "README.md: 100%"
          }
        },
        "51b11140569e452b8f5e6a38e0a7e863": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4a722ea8af0e4af99584fa8698a9b104",
            "max": 65391,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0c866ab26c574c39ac18022a599c6766",
            "value": 65391
          }
        },
        "8d493b21b92e4d2ba3900f05f5ec5ce0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6eb7356b8aac40878592c7fbfbe712f4",
            "placeholder": "​",
            "style": "IPY_MODEL_46f7600025e74f179649b4ddd8cb6dfa",
            "value": " 65.4k/65.4k [00:00&lt;00:00, 1.34MB/s]"
          }
        },
        "17888453970a42fc8d02bc1d2f9f5f64": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6ef964c9a58645d7b71843ed6727102a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f9d34ec0339045f7896ae968a7160e41": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4a722ea8af0e4af99584fa8698a9b104": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0c866ab26c574c39ac18022a599c6766": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6eb7356b8aac40878592c7fbfbe712f4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "46f7600025e74f179649b4ddd8cb6dfa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0aaee2a23f934bc3ac1c1641cc1af1a2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3030da96f177457089fcbf33907b72d0",
              "IPY_MODEL_1a60c2bbde4943c39930dc65f8c1ee1e",
              "IPY_MODEL_924e3fa666784cd1a3793d6d824bf2d5"
            ],
            "layout": "IPY_MODEL_d819d19737e0408e9482e0f24b6aa6ff"
          }
        },
        "3030da96f177457089fcbf33907b72d0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4d693b2c3b094b41acc937f54a7647f3",
            "placeholder": "​",
            "style": "IPY_MODEL_56dac6dc56ea4a1c8d59a55d0d793979",
            "value": "test-00000-of-00001.parquet: 100%"
          }
        },
        "1a60c2bbde4943c39930dc65f8c1ee1e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c1495fb65ed44242b06d4cfa0380ed8a",
            "max": 131945,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_570c11c5d9d8493d88997b52d833257c",
            "value": 131945
          }
        },
        "924e3fa666784cd1a3793d6d824bf2d5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f4a8b717ddb94491868d1c559164e654",
            "placeholder": "​",
            "style": "IPY_MODEL_b702b9f02bb3468895cdb566876b65b4",
            "value": " 132k/132k [00:00&lt;00:00, 1.96MB/s]"
          }
        },
        "d819d19737e0408e9482e0f24b6aa6ff": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4d693b2c3b094b41acc937f54a7647f3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "56dac6dc56ea4a1c8d59a55d0d793979": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c1495fb65ed44242b06d4cfa0380ed8a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "570c11c5d9d8493d88997b52d833257c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f4a8b717ddb94491868d1c559164e654": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b702b9f02bb3468895cdb566876b65b4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e76665d0e9194830b5db2bfb0e583601": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_62f8e6ce09824fcfbae61b7d827d2e9b",
              "IPY_MODEL_eb46dac62f7147258c09145bd386f24f",
              "IPY_MODEL_e468116b30494062867abc343b75ad41"
            ],
            "layout": "IPY_MODEL_aecbfb72c6ea482f9563a297cf7fc5ff"
          }
        },
        "62f8e6ce09824fcfbae61b7d827d2e9b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b3f21c9eb5214bc6bd977ac56c904583",
            "placeholder": "​",
            "style": "IPY_MODEL_62ddc4a0c9014109be0181ebd5de37ab",
            "value": "train-00000-of-00001.parquet: 100%"
          }
        },
        "eb46dac62f7147258c09145bd386f24f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5d2f85f410ad4c45a8d9933d2821cc25",
            "max": 57148882,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_bb3a302c0b304215adb8b46b5554b3cf",
            "value": 57148882
          }
        },
        "e468116b30494062867abc343b75ad41": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_25012e940b56494c8859791b79c4f5c7",
            "placeholder": "​",
            "style": "IPY_MODEL_0e21b65a6a25477798cc9ccb556061d9",
            "value": " 57.1M/57.1M [00:00&lt;00:00, 77.8MB/s]"
          }
        },
        "aecbfb72c6ea482f9563a297cf7fc5ff": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b3f21c9eb5214bc6bd977ac56c904583": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "62ddc4a0c9014109be0181ebd5de37ab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5d2f85f410ad4c45a8d9933d2821cc25": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bb3a302c0b304215adb8b46b5554b3cf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "25012e940b56494c8859791b79c4f5c7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0e21b65a6a25477798cc9ccb556061d9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "21438547c4aa4554aa616e99ada33c7f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f01cb1f3f5da4761aa9f94844db1ecec",
              "IPY_MODEL_20d15494610a47208cf4ddedca775f56",
              "IPY_MODEL_b2ef54daeebe48b08874591594ce8b6a"
            ],
            "layout": "IPY_MODEL_1cf17fbbb57e4fe0bf0b0349fad9b992"
          }
        },
        "f01cb1f3f5da4761aa9f94844db1ecec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_659d4fe6dcdf45d49137a12ef8a4e3e3",
            "placeholder": "​",
            "style": "IPY_MODEL_252530efc4bb4e3289e57c5dd845412c",
            "value": "validation-00000-of-00001.parquet: 100%"
          }
        },
        "20d15494610a47208cf4ddedca775f56": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2dfcaeeed8fd4545be5d1d2de8aab470",
            "max": 132009,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_cb4f3d328d154f8b9706c7d763e03b84",
            "value": 132009
          }
        },
        "b2ef54daeebe48b08874591594ce8b6a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_84326cd447b648faa3e3ec67b6f90160",
            "placeholder": "​",
            "style": "IPY_MODEL_b15d6dd4245647149bf16e59f31cf745",
            "value": " 132k/132k [00:00&lt;00:00, 2.98MB/s]"
          }
        },
        "1cf17fbbb57e4fe0bf0b0349fad9b992": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "659d4fe6dcdf45d49137a12ef8a4e3e3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "252530efc4bb4e3289e57c5dd845412c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2dfcaeeed8fd4545be5d1d2de8aab470": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cb4f3d328d154f8b9706c7d763e03b84": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "84326cd447b648faa3e3ec67b6f90160": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b15d6dd4245647149bf16e59f31cf745": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1daf4485ea7d4f44bd70d0eb772d77f8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_fbefcd2415f54ae4b762fff1c4bd023a",
              "IPY_MODEL_a1f5d60a52df4e56a9c22cdce3f27f6c",
              "IPY_MODEL_ac7a451e9b9c44778d311944035e0c94"
            ],
            "layout": "IPY_MODEL_15a7a7280f2e448f8fc0db52f6c69a5f"
          }
        },
        "fbefcd2415f54ae4b762fff1c4bd023a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bcf5133d7b7644ebbe3699c0b5f7497a",
            "placeholder": "​",
            "style": "IPY_MODEL_8935e1bb8c49461fa812d872ef95119b",
            "value": "Generating test split: 100%"
          }
        },
        "a1f5d60a52df4e56a9c22cdce3f27f6c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_618b4abdea57417d96bbc6f93c2ed8b3",
            "max": 2000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a8cfeb9c9df04cd0ae7f5758a7a2cb42",
            "value": 2000
          }
        },
        "ac7a451e9b9c44778d311944035e0c94": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fc2826d29e8c4d1999690195cc8927c9",
            "placeholder": "​",
            "style": "IPY_MODEL_02d27c22d1b846b59cc40b69c49042d1",
            "value": " 2000/2000 [00:00&lt;00:00, 9628.62 examples/s]"
          }
        },
        "15a7a7280f2e448f8fc0db52f6c69a5f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bcf5133d7b7644ebbe3699c0b5f7497a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8935e1bb8c49461fa812d872ef95119b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "618b4abdea57417d96bbc6f93c2ed8b3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a8cfeb9c9df04cd0ae7f5758a7a2cb42": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "fc2826d29e8c4d1999690195cc8927c9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "02d27c22d1b846b59cc40b69c49042d1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ec49d9756f304c34aeb5730f481f7b13": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_42b585c8d7d44f86bf2471e2a33881d2",
              "IPY_MODEL_b5364f0983814e7282398218477985f2",
              "IPY_MODEL_a7983c63f2c5447bbaa3df5ac2a58d6e"
            ],
            "layout": "IPY_MODEL_5c0f605e938549378a74ee61403f5c93"
          }
        },
        "42b585c8d7d44f86bf2471e2a33881d2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_471c03ea9ff4466993f2e3ef46233e4c",
            "placeholder": "​",
            "style": "IPY_MODEL_3ffb8ecdecb2456980886c90a86da87a",
            "value": "Generating train split: 100%"
          }
        },
        "b5364f0983814e7282398218477985f2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1b5ae82f186c4669b5f5fe2cad904a6e",
            "max": 1000000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_44e03d350e1140d1898a758cc8dd0c9c",
            "value": 1000000
          }
        },
        "a7983c63f2c5447bbaa3df5ac2a58d6e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d947b0bc464a4232933230d332df7ed2",
            "placeholder": "​",
            "style": "IPY_MODEL_60771e332159486397854457778d9aa6",
            "value": " 1000000/1000000 [00:02&lt;00:00, 307992.87 examples/s]"
          }
        },
        "5c0f605e938549378a74ee61403f5c93": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "471c03ea9ff4466993f2e3ef46233e4c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3ffb8ecdecb2456980886c90a86da87a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1b5ae82f186c4669b5f5fe2cad904a6e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "44e03d350e1140d1898a758cc8dd0c9c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d947b0bc464a4232933230d332df7ed2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "60771e332159486397854457778d9aa6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2805fd551743426faf467ca119c6cc80": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e462637d11f9464b99778ed1ffd38a0c",
              "IPY_MODEL_f2186b2abdae4615af9342875cbd1113",
              "IPY_MODEL_88a6e64ff7c84bc1b002d17fc5ce7848"
            ],
            "layout": "IPY_MODEL_a1e75b9cca824997bcfb63c8a0846536"
          }
        },
        "e462637d11f9464b99778ed1ffd38a0c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7b5858c52e0143a98152935128551d40",
            "placeholder": "​",
            "style": "IPY_MODEL_21bab149ed314624814fa5d9f6012d6b",
            "value": "Generating validation split: 100%"
          }
        },
        "f2186b2abdae4615af9342875cbd1113": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c30da8167e164f30955ad40fc07cf282",
            "max": 2000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_dc69c6a09c7a4e2db3ec76f458c2fa61",
            "value": 2000
          }
        },
        "88a6e64ff7c84bc1b002d17fc5ce7848": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_472947bdefba4e0abb22fe846acc02e1",
            "placeholder": "​",
            "style": "IPY_MODEL_0c05effb31014c61b23800268aff5b3e",
            "value": " 2000/2000 [00:00&lt;00:00, 25787.30 examples/s]"
          }
        },
        "a1e75b9cca824997bcfb63c8a0846536": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7b5858c52e0143a98152935128551d40": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "21bab149ed314624814fa5d9f6012d6b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c30da8167e164f30955ad40fc07cf282": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dc69c6a09c7a4e2db3ec76f458c2fa61": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "472947bdefba4e0abb22fe846acc02e1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0c05effb31014c61b23800268aff5b3e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}