{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "m3m5msf5lEx2"
      },
      "outputs": [],
      "source": [
        "# Imports\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.nn import functional as F\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "import time\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "import urllib.request\n",
        "\n",
        "from collections import OrderedDict"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9ydXrYfUA3zJ",
        "outputId": "e8644712-42f5-480b-d6c7-c018f11c4551"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Model parameters\n",
        "MASTER_CONFIG = {\n",
        "    \"vocab_size\": 65,       # Number of unique characters in the dataset\n",
        "    \"batch_size\": 32,       # Number of batches\n",
        "    \"context_window\": 16,   # Number of characters in a batch\n",
        "    \"d_model\": 128,         # Dimension of linear layers\n",
        "    \"epochs\": 10_000,       # Number of training epochs\n",
        "    \"log_interval\": 100,    # Frequency of logging the loss in epochs\n",
        "    \"n_heads\": 8,           # Number of attention heads\n",
        "    \"n_layers\": 4           # Number of Llama layers\n",
        "}"
      ],
      "metadata": {
        "id": "VBCJ9JTTlJbi"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Preprocessing"
      ],
      "metadata": {
        "id": "hDzje7UalLRN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Tiny Shakespeare\n",
        "url = \"https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt\"\n",
        "file_name = \"tinyshakespeare.txt\"\n",
        "urllib.request.urlretrieve(url, file_name)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3n4ItxJ5lMGV",
        "outputId": "b43803f6-2364-41ed-ed98-1cba851a398a"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('tinyshakespeare.txt', <http.client.HTTPMessage at 0x7e635016d1e0>)"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create vocab list of unique chars\n",
        "lines = open(\"tinyshakespeare.txt\", 'r').read()\n",
        "vocab = sorted(list(set(lines)))"
      ],
      "metadata": {
        "id": "Qbb_QEirlPHT"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Int to string\n",
        "itos = {i: ch for i, ch in enumerate(vocab)}\n",
        "\n",
        "# String to int\n",
        "stoi = {ch: i for i, ch in enumerate(vocab)}"
      ],
      "metadata": {
        "id": "fVWOD7M2lQqx"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Encoding and decoding\n",
        "def encode(s):\n",
        "    return [stoi[ch] for ch in s]\n",
        "\n",
        "def decode(l):\n",
        "    return ''.join([itos[i] for i in l])"
      ],
      "metadata": {
        "id": "7xxeMFullSah"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert dataset into a tensor\n",
        "dataset = torch.tensor(encode(lines), dtype=torch.int8, device=device)"
      ],
      "metadata": {
        "id": "GDwuDSKDlWnf"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split dataset into train/val/test batches\n",
        "def get_batches(data, split, batch_size, context_window, config=MASTER_CONFIG):\n",
        "  # Train/val/test split = 0.8/0.1/0.1\n",
        "  train = data[:int(0.8 * len(data))]\n",
        "  val = data[int(0.8 * len(data)):int(0.9 * len(data))]\n",
        "  test = data[int(0.9 * len(data)):]\n",
        "\n",
        "  # Determine which batch to use\n",
        "  batch_data = train\n",
        "  if split == \"val\":\n",
        "    batch_data = val\n",
        "  elif split == \"test\":\n",
        "    batch_data = test\n",
        "\n",
        "  # batch_size number of random starting points in the data\n",
        "  ix = torch.randint(0, batch_data.size(0) - context_window - 1, (batch_size,))\n",
        "\n",
        "  # Input and target sequences\n",
        "  x = torch.stack([batch_data[i:i + context_window] for i in ix]).long()\n",
        "  y = torch.stack([batch_data[i + 1:i + context_window + 1] for i in ix]).long()\n",
        "\n",
        "  return x, y"
      ],
      "metadata": {
        "id": "V9-olP70lYU3"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Loss"
      ],
      "metadata": {
        "id": "jSn1oXjVla5c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Computes the mean loss for 10 batches for train/val\n",
        "@torch.no_grad()\n",
        "def evaluate_loss(model, config=MASTER_CONFIG):\n",
        "  out = {}\n",
        "\n",
        "  # Set the model to evaluation mode\n",
        "  model.eval()\n",
        "\n",
        "  # Iterate through train and val splits\n",
        "  for split in [\"train\", \"val\"]:\n",
        "    losses = []\n",
        "\n",
        "    # Get 10 sample batches\n",
        "    for _ in range(10):\n",
        "      # Input and target sequences\n",
        "      xb, yb = get_batches(dataset, split, config[\"batch_size\"], config[\"context_window\"])\n",
        "      # Run the model and calculate the loss\n",
        "      _, loss = model(xb, yb)\n",
        "      losses.append(loss.item())\n",
        "\n",
        "    out[split] = np.mean(losses)\n",
        "\n",
        "  # Set the model to train mode\n",
        "  model.train()\n",
        "\n",
        "  return out"
      ],
      "metadata": {
        "id": "Z0VujPjxlbdp"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Llama Model"
      ],
      "metadata": {
        "id": "dfuzrPk6ld6r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class RMSNorm(nn.Module):\n",
        "  def __init__(self, layer_shape, eps=1e-8, bias=False):\n",
        "    super(RMSNorm, self).__init__()\n",
        "\n",
        "    # Register a learnable parameter \"scale\" as a part of the module\n",
        "    self.register_parameter(\"scale\", nn.Parameter(torch.ones(layer_shape)))\n",
        "\n",
        "  def forward(self, x):\n",
        "    # x: (batch, seq_len, d_model)\n",
        "\n",
        "    # Calculate Frobenius norm: RMS = 1/sqrt(N) * Frobenius norm\n",
        "    ff_rms = torch.linalg.norm(x, dim=(1, 2)) * x[0].numel() ** -0.5\n",
        "\n",
        "    # Normalize x with respect to RMS\n",
        "    raw = x / ff_rms.unsqueeze(-1).unsqueeze(-1)\n",
        "\n",
        "    # Scale the normalized tensor using the learnable parameter \"scale\"\n",
        "    return self.scale[:x.shape[1], :].unsqueeze(0) * raw"
      ],
      "metadata": {
        "id": "LHEVqscNl0Hq"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_rotary_matrix(context_window, embedding_dim):\n",
        "    R = torch.zeros((context_window, embedding_dim, embedding_dim), requires_grad=False, device=device)\n",
        "\n",
        "    # Loop through each position in the context window\n",
        "    for position in range(context_window):\n",
        "      # Loop through each dimension in the embedding\n",
        "      for i in range(embedding_dim // 2):\n",
        "        # Calculate the rotation angle based on the position and embedding dimension\n",
        "        theta = 10_000 ** (-2 * (i - 1) / embedding_dim)\n",
        "        # Calculate the rotated matrix elements\n",
        "        m_theta = position * theta\n",
        "        R[position, 2 * i, 2 * i] = np.cos(m_theta)\n",
        "        R[position, 2 * i, 2 * i + 1] = -np.sin(m_theta)\n",
        "        R[position, 2 * i + 1, 2 * i] = np.sin(m_theta)\n",
        "        R[position, 2 * i + 1, 2 * i + 1] = np.cos(m_theta)\n",
        "\n",
        "    return R\n",
        "\n",
        "class RoPEMaskedAttentionHead(nn.Module):\n",
        "  def __init__(self, config):\n",
        "    super().__init__()\n",
        "    self.config = config\n",
        "\n",
        "    # Linear transformation for query\n",
        "    self.w_q = nn.Linear(config['d_model'], config['d_model'], bias=False)\n",
        "    # Linear transformation for key\n",
        "    self.w_k = nn.Linear(config['d_model'], config['d_model'], bias=False)\n",
        "    # Linear transformation for value\n",
        "    self.w_v = nn.Linear(config['d_model'], config['d_model'], bias=False)\n",
        "    # Obtain rotary matrix for positional embeddings\n",
        "    self.R = get_rotary_matrix(config['context_window'], config['d_model'])\n",
        "\n",
        "  def forward(self, x, return_attn_weights=False):\n",
        "    # x: (batch, seq_len, d_model)\n",
        "    b, m, d = x.shape\n",
        "\n",
        "    # Linear transformations for Q, K, and V\n",
        "    q = self.w_q(x)\n",
        "    k = self.w_k(x)\n",
        "    v = self.w_v(x)\n",
        "\n",
        "    # Rotate Q and K using the RoPE matrix\n",
        "    q_rotated = (torch.bmm(q.transpose(0, 1), self.R[:m])).transpose(0, 1)\n",
        "    k_rotated = (torch.bmm(k.transpose(0, 1), self.R[:m])).transpose(0, 1)\n",
        "\n",
        "    # Scaled dot-product attention\n",
        "    activations = F.scaled_dot_product_attention(q_rotated, k_rotated, v, dropout_p=0.1, is_causal=True)\n",
        "\n",
        "    # Return the attention weights\n",
        "    if return_attn_weights:\n",
        "      # Create causal attention mask\n",
        "      attn_mask = torch.tril(torch.ones((m, m)), diagonal=0)\n",
        "      # Calculate attention weights and add causal mask\n",
        "      attn_weights = torch.bmm(q_rotated, k_rotated.transpose(1, 2)) / np.sqrt(d) + attn_mask\n",
        "      attn_weights = F.softmax(attn_weights, dim=-1)\n",
        "      return activations, attn_weights\n",
        "\n",
        "    return activations"
      ],
      "metadata": {
        "id": "FOza2XT3rmkV"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class RoPEMaskedMultiheadAttention(nn.Module):\n",
        "  def __init__(self, config):\n",
        "    super().__init__()\n",
        "    self.config = config\n",
        "\n",
        "    # RoPEMaskedAttentionHead instances as attention heads\n",
        "    self.heads = nn.ModuleList([RoPEMaskedAttentionHead(config) for _ in range(config[\"n_heads\"])])\n",
        "    # Linear layer after concatenating the heads\n",
        "    self.linear = nn.Linear(config[\"n_heads\"] * config[\"d_model\"], config[\"d_model\"])\n",
        "    # Dropout layer\n",
        "    self.dropout = nn.Dropout(0.1)\n",
        "\n",
        "  def forward(self, x):\n",
        "    # x: (batch, seq_len, d_model)\n",
        "\n",
        "    # Process each attention head and concatenate the results\n",
        "    heads = [h(x) for h in self.heads]\n",
        "    x = torch.cat(heads, dim=-1)\n",
        "    # Linear layer\n",
        "    x = self.linear(x)\n",
        "    # Dropout layer\n",
        "    x = self.dropout(x)\n",
        "\n",
        "    return x"
      ],
      "metadata": {
        "id": "tw7ob6kHyb3C"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SwiGLU(nn.Module):\n",
        "  def __init__(self, size):\n",
        "    super().__init__()\n",
        "\n",
        "    # Linear transformation for the gate mechanism\n",
        "    self.linear_gate = nn.Linear(size, size)\n",
        "    # Linear transformation for the main branch\n",
        "    self.linear = nn.Linear(size, size)\n",
        "    # Randomly init the beta parameter\n",
        "    self.beta = torch.randn(1, requires_grad=True)\n",
        "\n",
        "    # Register beta as a learnable parameter\n",
        "    self.beta = nn.Parameter(torch.ones(1))\n",
        "    self.register_parameter(\"beta\", self.beta)\n",
        "\n",
        "  def forward(self, x):\n",
        "    # Swish-Gated Linear Unit computation\n",
        "    swish_gate = self.linear_gate(x) * torch.sigmoid(self.beta * self.linear_gate(x))\n",
        "    # Element-wise multiplication between the gate and main branch\n",
        "    out = swish_gate * self.linear(x)\n",
        "\n",
        "    return out"
      ],
      "metadata": {
        "id": "9jRyJHtD2ont"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class LlamaBlock(nn.Module):\n",
        "  def __init__(self, config):\n",
        "    super().__init__()\n",
        "    self.config = config\n",
        "\n",
        "    # RMSNorm layer for pre-normalization\n",
        "    self.rms = RMSNorm((config[\"context_window\"], config[\"d_model\"]))\n",
        "    # RoPEMaskedMultiheadAttention layer\n",
        "    self.attention = RoPEMaskedMultiheadAttention(config)\n",
        "    # Feedforward layer with SwiGLU activation\n",
        "    self.feedforward = nn.Sequential(\n",
        "        nn.Linear(config[\"d_model\"], config[\"d_model\"]),\n",
        "        SwiGLU(config['d_model'])\n",
        "    )\n",
        "\n",
        "  def forward(self, x):\n",
        "    # Attention block\n",
        "    x = self.rms(x)\n",
        "    x = x + self.attention(x)\n",
        "\n",
        "    # Linear block\n",
        "    x = self.rms(x)\n",
        "    x = x + self.feedforward(x)\n",
        "\n",
        "    return x"
      ],
      "metadata": {
        "id": "NnZ99ikd8IPQ"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Llama(nn.Module):\n",
        "  def __init__(self, config=MASTER_CONFIG):\n",
        "    super().__init__()\n",
        "    self.config = config\n",
        "\n",
        "    # Embedding layer to convert character indices to vectors\n",
        "    self.embedding = nn.Embedding(config[\"vocab_size\"], config[\"d_model\"])\n",
        "    # Sequential block of n_layers LlamaBlocks\n",
        "    self.llama_blocks = nn.Sequential(OrderedDict([(f\"llama_{i}\", LlamaBlock(config)) for i in range(config['n_layers'])]))\n",
        "    # Feedforward network for final output\n",
        "    self.ffn = nn.Sequential(\n",
        "        nn.Linear(config['d_model'], config['d_model']),\n",
        "        SwiGLU(config['d_model']),\n",
        "        nn.Linear(config['d_model'], config['vocab_size']),\n",
        "    )\n",
        "\n",
        "    print(\"# of params:\", sum(p.numel() for p in self.parameters()))\n",
        "\n",
        "  def forward(self, idx, targets=None):\n",
        "    # Embedding layer converts character indices to vectors\n",
        "    x = self.embedding(idx)\n",
        "\n",
        "    # Llama blocks\n",
        "    x = self.llama_blocks(x)\n",
        "    # Final feedforward network for output logits\n",
        "    logits = self.ffn(x)\n",
        "\n",
        "    # If there are targets, calculate and return the cross entropy loss\n",
        "    if targets is not None:\n",
        "      loss = F.cross_entropy(logits.view(-1, self.config[\"vocab_size\"]), targets.view(-1))\n",
        "      return logits, loss\n",
        "\n",
        "    return logits"
      ],
      "metadata": {
        "id": "Bisbawb6lfgd"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training loop\n",
        "def train(model, optimizer, scheduler=None, config=MASTER_CONFIG, print_logs=False):\n",
        "  losses = []\n",
        "  start_time = time.time()\n",
        "\n",
        "  # Iterate through epochs\n",
        "  for epoch in range(config[\"epochs\"]):\n",
        "    # Zero out gradients\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    # Get training batches\n",
        "    xs, ys = get_batches(dataset, \"train\", config[\"batch_size\"], config[\"context_window\"])\n",
        "    # Run the model and calculate the loss\n",
        "    logits, loss = model(xs, targets=ys)\n",
        "    # Backpropagate the loss\n",
        "    loss.backward()\n",
        "    # Step the optimizer\n",
        "    optimizer.step()\n",
        "\n",
        "    # If there's a learning rate scheduler, adjust the learning rate\n",
        "    if scheduler:\n",
        "      scheduler.step()\n",
        "\n",
        "    # Log progress\n",
        "    if epoch % config[\"log_interval\"] == 0:\n",
        "      # Calculate batch time\n",
        "      batch_time = time.time() - start_time\n",
        "\n",
        "      # Evaluate loss\n",
        "      x = evaluate_loss(model)\n",
        "      losses += [x]\n",
        "\n",
        "      # Print progress\n",
        "      if print_logs:\n",
        "        print(f\"Epoch: {epoch} | Train loss: {x['train']:0.3f} | Val loss: {x['val']:0.3f} | Batch time: {batch_time:0.3f} | ETA (sec): {batch_time * (config['epochs'] - epoch) / config['log_interval']:0.3f}\")\n",
        "\n",
        "      # Reset timer\n",
        "      start_time = time.time()\n",
        "\n",
        "      # Print learning rate\n",
        "      if scheduler:\n",
        "        print(\"Learning rate:\", scheduler.get_last_lr()[0])\n",
        "\n",
        "  print(\"Val loss:\", losses[-1][\"val\"])\n",
        "\n",
        "  return pd.DataFrame(losses).plot()"
      ],
      "metadata": {
        "id": "AoLKTPIEljau"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Reinit model\n",
        "model = Llama(MASTER_CONFIG).to(device)\n",
        "# Adam optimizer with specific hyperparameters\n",
        "llama_optimizer = torch.optim.Adam(\n",
        "    model.parameters(),\n",
        "    betas=(0.9, 0.95),\n",
        "    weight_decay=0.1,\n",
        "    eps=1e-9,\n",
        "    lr=1e-3\n",
        ")\n",
        "llama_optimizer = torch.optim.AdamW(model.parameters())\n",
        "# Cosine Annealing learning rate scheduler\n",
        "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(llama_optimizer, 300, eta_min=1e-5)\n",
        "scheduler = None\n",
        "\n",
        "# Train model\n",
        "train(model, llama_optimizer, scheduler=scheduler, print_logs=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "qcfSmKcbll9v",
        "outputId": "94c471b5-8952-499b-b9c7-8ecc32d9e5f4"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "# of params: 2370246\n",
            "Epoch: 0 | Train loss: 4.126 | Val loss: 4.129 | Batch time: 1.646 | ETA (sec): 164.608\n",
            "Epoch: 100 | Train loss: 2.388 | Val loss: 2.445 | Batch time: 5.788 | ETA (sec): 573.023\n",
            "Epoch: 200 | Train loss: 2.231 | Val loss: 2.304 | Batch time: 6.782 | ETA (sec): 664.646\n",
            "Epoch: 300 | Train loss: 2.103 | Val loss: 2.200 | Batch time: 8.922 | ETA (sec): 865.459\n",
            "Epoch: 400 | Train loss: 2.029 | Val loss: 2.110 | Batch time: 7.373 | ETA (sec): 707.829\n",
            "Epoch: 500 | Train loss: 2.000 | Val loss: 2.101 | Batch time: 6.041 | ETA (sec): 573.930\n",
            "Epoch: 600 | Train loss: 1.965 | Val loss: 2.103 | Batch time: 5.208 | ETA (sec): 489.554\n",
            "Epoch: 700 | Train loss: 1.944 | Val loss: 2.052 | Batch time: 5.509 | ETA (sec): 512.344\n",
            "Epoch: 800 | Train loss: 1.955 | Val loss: 2.069 | Batch time: 5.083 | ETA (sec): 467.615\n",
            "Epoch: 900 | Train loss: 1.878 | Val loss: 2.033 | Batch time: 5.759 | ETA (sec): 524.066\n",
            "Epoch: 1000 | Train loss: 1.886 | Val loss: 1.974 | Batch time: 5.031 | ETA (sec): 452.829\n",
            "Epoch: 1100 | Train loss: 1.827 | Val loss: 1.983 | Batch time: 5.725 | ETA (sec): 509.564\n",
            "Epoch: 1200 | Train loss: 1.857 | Val loss: 1.950 | Batch time: 5.036 | ETA (sec): 443.195\n",
            "Epoch: 1300 | Train loss: 1.904 | Val loss: 1.967 | Batch time: 5.751 | ETA (sec): 500.298\n",
            "Epoch: 1400 | Train loss: 1.817 | Val loss: 1.944 | Batch time: 5.477 | ETA (sec): 471.035\n",
            "Epoch: 1500 | Train loss: 1.803 | Val loss: 1.931 | Batch time: 6.001 | ETA (sec): 510.110\n",
            "Epoch: 1600 | Train loss: 1.796 | Val loss: 1.924 | Batch time: 5.115 | ETA (sec): 429.689\n",
            "Epoch: 1700 | Train loss: 1.830 | Val loss: 1.909 | Batch time: 5.750 | ETA (sec): 477.214\n",
            "Epoch: 1800 | Train loss: 1.802 | Val loss: 1.938 | Batch time: 5.230 | ETA (sec): 428.875\n",
            "Epoch: 1900 | Train loss: 1.783 | Val loss: 1.842 | Batch time: 5.892 | ETA (sec): 477.246\n",
            "Epoch: 2000 | Train loss: 1.744 | Val loss: 1.867 | Batch time: 5.034 | ETA (sec): 402.729\n",
            "Epoch: 2100 | Train loss: 1.724 | Val loss: 1.911 | Batch time: 5.774 | ETA (sec): 456.175\n",
            "Epoch: 2200 | Train loss: 1.731 | Val loss: 1.868 | Batch time: 4.976 | ETA (sec): 388.150\n",
            "Epoch: 2300 | Train loss: 1.737 | Val loss: 1.854 | Batch time: 5.884 | ETA (sec): 453.106\n",
            "Epoch: 2400 | Train loss: 1.773 | Val loss: 1.832 | Batch time: 5.254 | ETA (sec): 399.341\n",
            "Epoch: 2500 | Train loss: 1.723 | Val loss: 1.856 | Batch time: 5.788 | ETA (sec): 434.117\n",
            "Epoch: 2600 | Train loss: 1.721 | Val loss: 1.839 | Batch time: 5.242 | ETA (sec): 387.906\n",
            "Epoch: 2700 | Train loss: 1.708 | Val loss: 1.815 | Batch time: 5.752 | ETA (sec): 419.901\n",
            "Epoch: 2800 | Train loss: 1.683 | Val loss: 1.859 | Batch time: 5.573 | ETA (sec): 401.278\n",
            "Epoch: 2900 | Train loss: 1.705 | Val loss: 1.813 | Batch time: 5.945 | ETA (sec): 422.086\n",
            "Epoch: 3000 | Train loss: 1.711 | Val loss: 1.810 | Batch time: 5.459 | ETA (sec): 382.116\n",
            "Epoch: 3100 | Train loss: 1.708 | Val loss: 1.790 | Batch time: 5.870 | ETA (sec): 405.042\n",
            "Epoch: 3200 | Train loss: 1.692 | Val loss: 1.787 | Batch time: 5.425 | ETA (sec): 368.895\n",
            "Epoch: 3300 | Train loss: 1.634 | Val loss: 1.780 | Batch time: 5.847 | ETA (sec): 391.776\n",
            "Epoch: 3400 | Train loss: 1.664 | Val loss: 1.697 | Batch time: 5.468 | ETA (sec): 360.885\n",
            "Epoch: 3500 | Train loss: 1.653 | Val loss: 1.791 | Batch time: 6.063 | ETA (sec): 394.075\n",
            "Epoch: 3600 | Train loss: 1.650 | Val loss: 1.781 | Batch time: 6.203 | ETA (sec): 396.968\n",
            "Epoch: 3700 | Train loss: 1.675 | Val loss: 1.745 | Batch time: 5.539 | ETA (sec): 348.962\n",
            "Epoch: 3800 | Train loss: 1.654 | Val loss: 1.790 | Batch time: 5.779 | ETA (sec): 358.291\n",
            "Epoch: 3900 | Train loss: 1.643 | Val loss: 1.708 | Batch time: 5.593 | ETA (sec): 341.171\n",
            "Epoch: 4000 | Train loss: 1.650 | Val loss: 1.778 | Batch time: 5.761 | ETA (sec): 345.659\n",
            "Epoch: 4100 | Train loss: 1.591 | Val loss: 1.766 | Batch time: 5.527 | ETA (sec): 326.076\n",
            "Epoch: 4200 | Train loss: 1.636 | Val loss: 1.710 | Batch time: 5.860 | ETA (sec): 339.861\n",
            "Epoch: 4300 | Train loss: 1.617 | Val loss: 1.754 | Batch time: 5.522 | ETA (sec): 314.726\n",
            "Epoch: 4400 | Train loss: 1.626 | Val loss: 1.788 | Batch time: 5.785 | ETA (sec): 323.956\n",
            "Epoch: 4500 | Train loss: 1.603 | Val loss: 1.701 | Batch time: 5.465 | ETA (sec): 300.570\n",
            "Epoch: 4600 | Train loss: 1.596 | Val loss: 1.691 | Batch time: 5.885 | ETA (sec): 317.774\n",
            "Epoch: 4700 | Train loss: 1.598 | Val loss: 1.700 | Batch time: 5.455 | ETA (sec): 289.111\n",
            "Epoch: 4800 | Train loss: 1.574 | Val loss: 1.715 | Batch time: 5.954 | ETA (sec): 309.615\n",
            "Epoch: 4900 | Train loss: 1.575 | Val loss: 1.654 | Batch time: 5.605 | ETA (sec): 285.876\n",
            "Epoch: 5000 | Train loss: 1.555 | Val loss: 1.704 | Batch time: 5.855 | ETA (sec): 292.734\n",
            "Epoch: 5100 | Train loss: 1.570 | Val loss: 1.661 | Batch time: 5.552 | ETA (sec): 272.065\n",
            "Epoch: 5200 | Train loss: 1.554 | Val loss: 1.723 | Batch time: 5.900 | ETA (sec): 283.198\n",
            "Epoch: 5300 | Train loss: 1.585 | Val loss: 1.641 | Batch time: 5.506 | ETA (sec): 258.778\n",
            "Epoch: 5400 | Train loss: 1.548 | Val loss: 1.684 | Batch time: 5.921 | ETA (sec): 272.356\n",
            "Epoch: 5500 | Train loss: 1.558 | Val loss: 1.685 | Batch time: 5.560 | ETA (sec): 250.222\n",
            "Epoch: 5600 | Train loss: 1.493 | Val loss: 1.733 | Batch time: 5.830 | ETA (sec): 256.541\n",
            "Epoch: 5700 | Train loss: 1.533 | Val loss: 1.661 | Batch time: 5.544 | ETA (sec): 238.383\n",
            "Epoch: 5800 | Train loss: 1.540 | Val loss: 1.674 | Batch time: 5.873 | ETA (sec): 246.651\n",
            "Epoch: 5900 | Train loss: 1.514 | Val loss: 1.651 | Batch time: 5.435 | ETA (sec): 222.854\n",
            "Epoch: 6000 | Train loss: 1.569 | Val loss: 1.647 | Batch time: 5.791 | ETA (sec): 231.660\n",
            "Epoch: 6100 | Train loss: 1.513 | Val loss: 1.701 | Batch time: 5.428 | ETA (sec): 211.709\n",
            "Epoch: 6200 | Train loss: 1.513 | Val loss: 1.661 | Batch time: 5.881 | ETA (sec): 223.475\n",
            "Epoch: 6300 | Train loss: 1.526 | Val loss: 1.670 | Batch time: 5.455 | ETA (sec): 201.841\n",
            "Epoch: 6400 | Train loss: 1.484 | Val loss: 1.611 | Batch time: 5.882 | ETA (sec): 211.737\n",
            "Epoch: 6500 | Train loss: 1.451 | Val loss: 1.598 | Batch time: 5.533 | ETA (sec): 193.641\n",
            "Epoch: 6600 | Train loss: 1.557 | Val loss: 1.661 | Batch time: 6.011 | ETA (sec): 204.359\n",
            "Epoch: 6700 | Train loss: 1.487 | Val loss: 1.621 | Batch time: 5.667 | ETA (sec): 187.014\n",
            "Epoch: 6800 | Train loss: 1.532 | Val loss: 1.554 | Batch time: 5.983 | ETA (sec): 191.446\n",
            "Epoch: 6900 | Train loss: 1.498 | Val loss: 1.647 | Batch time: 5.685 | ETA (sec): 176.233\n",
            "Epoch: 7000 | Train loss: 1.463 | Val loss: 1.563 | Batch time: 5.871 | ETA (sec): 176.124\n",
            "Epoch: 7100 | Train loss: 1.458 | Val loss: 1.582 | Batch time: 5.718 | ETA (sec): 165.810\n",
            "Epoch: 7200 | Train loss: 1.456 | Val loss: 1.562 | Batch time: 5.787 | ETA (sec): 162.026\n",
            "Epoch: 7300 | Train loss: 1.430 | Val loss: 1.598 | Batch time: 5.778 | ETA (sec): 156.000\n",
            "Epoch: 7400 | Train loss: 1.446 | Val loss: 1.538 | Batch time: 5.715 | ETA (sec): 148.590\n",
            "Epoch: 7500 | Train loss: 1.451 | Val loss: 1.585 | Batch time: 5.795 | ETA (sec): 144.884\n",
            "Epoch: 7600 | Train loss: 1.470 | Val loss: 1.642 | Batch time: 5.610 | ETA (sec): 134.639\n",
            "Epoch: 7700 | Train loss: 1.417 | Val loss: 1.544 | Batch time: 5.683 | ETA (sec): 130.710\n",
            "Epoch: 7800 | Train loss: 1.457 | Val loss: 1.578 | Batch time: 5.663 | ETA (sec): 124.592\n",
            "Epoch: 7900 | Train loss: 1.390 | Val loss: 1.517 | Batch time: 5.668 | ETA (sec): 119.021\n",
            "Epoch: 8000 | Train loss: 1.389 | Val loss: 1.496 | Batch time: 5.554 | ETA (sec): 111.084\n",
            "Epoch: 8100 | Train loss: 1.438 | Val loss: 1.491 | Batch time: 5.579 | ETA (sec): 105.992\n",
            "Epoch: 8200 | Train loss: 1.375 | Val loss: 1.507 | Batch time: 5.592 | ETA (sec): 100.665\n",
            "Epoch: 8300 | Train loss: 1.347 | Val loss: 1.500 | Batch time: 5.571 | ETA (sec): 94.708\n",
            "Epoch: 8400 | Train loss: 1.365 | Val loss: 1.485 | Batch time: 5.705 | ETA (sec): 91.280\n",
            "Epoch: 8500 | Train loss: 1.392 | Val loss: 1.543 | Batch time: 5.517 | ETA (sec): 82.762\n",
            "Epoch: 8600 | Train loss: 1.411 | Val loss: 1.482 | Batch time: 5.796 | ETA (sec): 81.151\n",
            "Epoch: 8700 | Train loss: 1.387 | Val loss: 1.425 | Batch time: 5.473 | ETA (sec): 71.151\n",
            "Epoch: 8800 | Train loss: 1.328 | Val loss: 1.471 | Batch time: 5.885 | ETA (sec): 70.618\n",
            "Epoch: 8900 | Train loss: 1.315 | Val loss: 1.479 | Batch time: 5.973 | ETA (sec): 65.702\n",
            "Epoch: 9000 | Train loss: 1.355 | Val loss: 1.499 | Batch time: 5.751 | ETA (sec): 57.513\n",
            "Epoch: 9100 | Train loss: 1.340 | Val loss: 1.448 | Batch time: 6.685 | ETA (sec): 60.166\n",
            "Epoch: 9200 | Train loss: 1.314 | Val loss: 1.453 | Batch time: 5.306 | ETA (sec): 42.449\n",
            "Epoch: 9300 | Train loss: 1.272 | Val loss: 1.445 | Batch time: 5.864 | ETA (sec): 41.045\n",
            "Epoch: 9400 | Train loss: 1.302 | Val loss: 1.441 | Batch time: 5.374 | ETA (sec): 32.245\n",
            "Epoch: 9500 | Train loss: 1.303 | Val loss: 1.387 | Batch time: 5.746 | ETA (sec): 28.728\n",
            "Epoch: 9600 | Train loss: 1.333 | Val loss: 1.422 | Batch time: 5.448 | ETA (sec): 21.793\n",
            "Epoch: 9700 | Train loss: 1.339 | Val loss: 1.404 | Batch time: 5.688 | ETA (sec): 17.064\n",
            "Epoch: 9800 | Train loss: 1.240 | Val loss: 1.344 | Batch time: 5.596 | ETA (sec): 11.192\n",
            "Epoch: 9900 | Train loss: 1.250 | Val loss: 1.396 | Batch time: 5.738 | ETA (sec): 5.738\n",
            "Val loss: 1.395563042163849\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<Axes: >"
            ]
          },
          "metadata": {},
          "execution_count": 18
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the model\n",
        "torch.save(model, 'llama_model.pth')\n",
        "# Save the model params\n",
        "torch.save(model.state_dict(), 'llama_model_params.pth')"
      ],
      "metadata": {
        "id": "b-hKUInB_39U"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Generating Text"
      ],
      "metadata": {
        "id": "HaS9gN6glrXT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate text using the model\n",
        "def generate(model, config=MASTER_CONFIG, num_texts=5, max_new_tokens=30):\n",
        "  # Initialize with zeros = '\\n'\n",
        "  idx = torch.zeros(num_texts, 1, device=device).long()\n",
        "\n",
        "  for _ in range(max_new_tokens):\n",
        "    # Call the model\n",
        "    logits = model(idx[:, -config[\"context_window\"]:])\n",
        "    # Get the newest logits: [all batches, last time step, all logits]\n",
        "    last_time_step_logits = logits[:, -1, :]\n",
        "    # Softmax probabilities\n",
        "    p = F.softmax(last_time_step_logits, dim=-1)\n",
        "    # Get the next token from the probabilities\n",
        "    idx_next = torch.multinomial(p, num_samples=1)\n",
        "    # Append the token\n",
        "    idx = torch.cat([idx, idx_next], dim=-1)\n",
        "\n",
        "  # Return the decoded tokens\n",
        "  return [decode(x) for x in idx.tolist()]"
      ],
      "metadata": {
        "id": "wevzDU4eltrM"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "generate(model, num_texts=1, max_new_tokens=500)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TYExYXQXlu1J",
        "outputId": "5eaae222-0502-4368-e86c-59ed68425a8d"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[\"\\nThe terer therel he tilt pet\\nyou mies east all take that fool my honour Zays it tongue offtash'd offind a say stuge obls fadies\\nit good pilive, that my news, andickled\\nYou Like;\\nA teak's lo, no let\\nI'll nant strath. Would gire your matchs:\\nThat shiles many forth to\\nneighteil pardon on in trath,Bue tor of\\nWith out Richmondings,\\nAnd lady you, it,\\nAncity, lives, I\\nfect see it I tearters to the viatip, spoidesful peck think adammorant;\\nSay matter; have hither inloy his unmoltle fulitowarrangim\\nThese\"]"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.12.6"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}